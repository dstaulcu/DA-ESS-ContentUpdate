[ESCU - Windows Event Log Cleared - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-02-17
action.escu.modification_date = 2017-09-23
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks at the Windows security and system event logs. EventCode 1002 in the security log indicates that the log has been cleared. EventCode 1000 in the security log indicates the event logging service has been shut down. EventCode 104 in the system log indicates the application log has been cleared. If any of these events are found, a notable will be generated.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting Windows event logs from your hosts.
action.escu.full_search_name = ESCU - Windows Event Log Cleared
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Indicator Removal on Host"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 6"], "nist": ["DE.DP", "PR.IP", "PR.AC", "PR.AT", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It is possible that these logs may be legitimately cleared by Administrators.
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Windows Log Manipulation", "Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = host
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = host,EventCode
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for Windows events that indicate one of the Windows event logs has been purged.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = ((sourcetype=wineventlog:security OR sourcetype=XmlWinEventlog:Security) AND (EventCode=1102 OR EventCode=1100)) OR ((sourcetype=wineventlog:system OR sourcetype=XmlWinEventlog:System) AND EventCode=104) | stats count min(_time) as firstTime max(_time) as lastTime by EventCode sourcetype host | `ctime(firstTime)` | `ctime(lastTime)` | rename host as dest

[ESCU - Get Process Information For Port Activity]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-25
action.escu.modification_date = 2017-09-10
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data that associates processes with network events.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Get Process Information For Port Activity
action.escu.search_type = investigative
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.analytic_story = ["Prohibited Traffic Allowed or Protocol Mismatch", "Use of Cleartext Protocols", "Ransomware"]
action.escu.fields_required = ["dest_port", "src"]
action.escu.earliest_time_offset = 7200
action.escu.latest_time_offset = 7200
description = This search will return information about the process associated with observed network traffic to a specific destination port from a specific host.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | from datamodel Application_State.Ports | search dest_port={dest_port} dest={src} | table dest dest_port process process_name

[ESCU - Detect Spike in blocked Outbound Traffic from your AWS - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-26
action.escu.modification_date = 2018-05-07
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search retrieves all of the VPC Flow log entries that have recorded a blocked outbound network connection originating from your AWS environment. Then it kicks off a subsearch, which looks at the same data and performs the following series of steps: <ol><li>Counts the number of blocked outbound connections by each source IP</li><li>Loads the cache file that contains the number of data points, the count from the latest hour, the average blocked connections, and the standard deviation for each source IP.</li><li>Drops the count from the latest hour, since it is not necessary, and merges the rest of the data with the results of the stats command. </li><li>Renames <code>numberOfBlockedConnections</code> as <code>latestCount</code>.</li><li>Calculates the new average value for each source IP with the latest count, weighting the past much more heavily than the current hour. It does the same for the standard deviation, weighting the past more heavily than the current.</li><li>Updates the cache file with the latest results.</li><li>Sets the minimum threshold for the number of data points and sets the number of standard deviations away from the mean it must be to be considered a spike.</li><li>Makes a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.</li><li>Filters out anything that it determines is not a spike and returns the list of source IPs to the main search. </li></ol>The main search subsequently gets the list of all destination IPs for which the traffic was blocked, the network interface ID, the number of unique destination IP, and the total number of blocked connections for each of these source IP addresses. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your VPC Flow logs. You can modify <code>dataPointThreshold</code> and <code>deviationThreshold</code> to better fit your environment. The <code>dataPointThreshold</code> variable is the number of data points required to meet the definition of "spike." The <code>deviationThreshold</code> variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the "Baseline of Blocked Outbound Connection" support search once to create a history of previously seen blocked outbound connections.
action.escu.full_search_name = ESCU - Detect Spike in blocked Outbound Traffic from your AWS
action.escu.mappings = {"mitre_attack": ["Exfiltration", "Command and Control"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "cis20": ["CIS 11"], "nist": ["DE.AE", "DE.CM", "PR.AC"]}
action.escu.kill_chain_phases = ["Actions on Objectives", "Command and Control"]
action.escu.known_false_positives = The false-positive rate may vary based on the values of<code>dataPointThreshold</code> and <code>deviationThreshold</code>. Additionally, false positives may result when AWS administrators roll out policies enforcing network blocks, causing sudden increases in the number of blocked outbound connections.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity", "Suspicious AWS Traffic"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = src_ip
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search will detect spike in blocked outbound network connections originating from within your AWS environment.  It will also update the cache file that factors in the latest data.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudwatchlogs:vpcflow action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  [search  sourcetype=aws:cloudwatchlogs:vpcflow action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  | stats count as numberOfBlockedConnections by src_ip | inputlookup baseline_blocked_outbound_connections append=t | fields - latestCount | stats values(*) as * by src_ip | rename numberOfBlockedConnections as latestCount | eval newAvgBlockedConnections=avgBlockedConnections + (latestCount-avgBlockedConnections)/720 | eval newStdevBlockedConnections=sqrt(((pow(stdevBlockedConnections, 2)*719 + (latestCount-newAvgBlockedConnections)*(latestCount-avgBlockedConnections))/720)) | eval avgBlockedConnections=coalesce(newAvgBlockedConnections, avgBlockedConnections), stdevBlockedConnections=coalesce(newStdevBlockedConnections, stdevBlockedConnections), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections | outputlookup baseline_blocked_outbound_connections | eval dataPointThreshold = 5, deviationThreshold = 3 | eval isSpike=if((latestCount > avgBlockedConnections+deviationThreshold*stdevBlockedConnections) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | table src_ip] | stats values(dest_ip) as "Blocked Destination IPs", values(interface_id) as "resourceId" count as numberOfBlockedConnections, dc(dest_ip) as uniqueDestConnections by src_ip

[ESCU - Reg.exe used to hide files/directories via registry keys - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-10-27
action.escu.modification_date = 2017-10-30
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Reg.exe is a binary native to Windows platform used to edit the registry hives of the system. Attackers can leverage this binary to hide files by passing in arguments that are used to hide the files. In the search, we first gather results with keywords, add, Hidden, and REG_DWORD, that will be in the raw event and filter by process and the command-line. We then leverage regular expressions on the command-line field to look for /d value as 2 which is responsible for hiding a file or directory.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Reg.exe used to hide files/directories via registry keys
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = None at the moment
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "Windows Persistence Techniques"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,cmdline
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = The search looks for command-line arguments used to hide a file or directory using the reg add command.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational add Hidden REG_DWORD | search process=*reg.exe cmdline=*add* cmdline=*Hidden* cmdline=*REG_DWORD* | regex cmdline= "(/d\s+2)" | stats count values(cmdline) min(_time) as firstTime max(_time) as lastTime by dest process | `ctime(firstTime)` |`ctime(lastTime)`

[ESCU - Detect Activity Related to Pass the Hash Attacks - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-18
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = low
action.escu.eli5 = To detect pass the hash activity, we look at all events with event code 4624 or 4625 that specify a logon type 3 (network logons). We are looking for the NtLmSsP account, with a key length set to 0. These indicate lower level protocols that are typically used through Pass the Hash (WMI, SMB, etc.). The search also filters out events with an account name of 'Anonymous' to help reduce false positives.
action.escu.how_to_implement = To successfully implement this search, you must ingest your Windows Security Event logs and leverage the TA for Windows to extract EventCode, Logon_Process, Logon_Type, Key_Length and Account_Name fields from these events.
action.escu.full_search_name = ESCU - Detect Activity Related to Pass the Hash Attacks
action.escu.mappings = {"mitre_attack": ["Lateral Movement", "Pass the Hash"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 16"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Legitimate logon activity by authorized NTLM systems may be detected by this search. Please investigate as appropriate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Lateral Movement"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = ComputerName
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for specific authentication events from the Windows Security Event logs to detect potential attempts at using the Pass-the-Hash technique.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype="WinEventLog:Security" (EventCode=4624 OR EventCode=4625) Logon_Process=NtLmSsp Logon_Type=3 Account_Name !="ANONYMOUS LOGON" Key_Length=0 | table _time Source_Network_Address Account_Name Account_Domain ComputerName Workstation_Name

[ESCU - TOR Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-21
action.escu.modification_date = 2017-09-11
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The search leverages the Enterprise Security Network_Traffic data model to look for network traffic that has been identified as TOR and marked as 'allowed'.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from firewalls or other network control devices that mediate the traffic allowed into an environment. This is necessary so that the search can identify an 'action' taken on the traffic of interest. The search requires the Network_Traffic data model be populated.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - TOR Traffic
action.escu.mappings = {"mitre_attack": ["Command and Control", "Commonly Used Port", "Exfiltration"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 9", "CIS 12"], "nist": ["DE.AE"]}
action.escu.kill_chain_phases = ["Command and Control"]
action.escu.known_false_positives = None at this time
action.escu.search_type = detection
action.escu.providing_technologies = ["Palo Alto Firewall", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for network traffic identified as The Onion Router (TOR), a benign anonymity network which can be abused for a variety of nefarious purposes.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.app=tor AND All_Traffic.action=allowed by All_Traffic.src_ip All_Traffic.dest_ip All_Traffic.dest_port All_Traffic.action | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - Detect Use of cmd.exe to Launch Script Interpreters - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-10-09
action.escu.modification_date = 2017-10-23
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Attackers often leverage various scripting languages to execute their attacks. In a Windows environment, the Windows Script Host is the tool that interprets the scripts and is included in all modern versions of Windows. The Windows Script Host is available as a command-line tool called cscript.exe or wscript.exe. To detect this behavior, the search looks for process creation events for cscript.exe or wscript.exe with a parent process of cmd.exe. The search will return the command-lines of the matching processes.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with both the process name and parent process from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Detect Use of cmd.exe to Launch Script Interpreters
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface"], "kill_chain_phases": ["Exploitation"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Exploitation"]
action.escu.known_false_positives = Some legitimate applications may exhibit this behavior.
action.escu.search_type = detection
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Suspicious Command-Line Executions"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for the execution of cscript.exe or wscript.exe with a parent of cmd.exe. The search will return the full command-lines for these executions, as well as the target system, sorted by time.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational parent_process=*cmd.exe process=cscript.exe OR  process=wscript.exe| stats values(cmdline) AS "Commands "  min(_time) as firstTime max(_time) as lastTime by dest parent_process process | `ctime(firstTime)`|`ctime(lastTime)` | table firstTime lastTime dest parent_process process "Commands executed" 

[ESCU - Monitor Successful Backups]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-12
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search gives you the count and the hostname of all the systems that had a successful backup each day.
action.escu.how_to_implement = To successfully implement this search you must be ingesting your backup logs.
action.escu.full_search_name = ESCU - Monitor Successful Backups
action.escu.search_type = support
action.escu.providing_technologies = ["Netbackup"]
action.escu.analytic_story = ["Monitor Backup Solution", "Ransomware"]
description = This search is intended to give you a feel for how often successful backups are conducted in your environment. Fluctuations in these numbers will allow you to determine when you should investigate.
dispatch.earliest_time = -30d
dispatch.latest_time = now
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype="netbackup_logs" "Disk/Partition backup completed successfully." | bucket _time span=1d | stats dc(COMPUTERNAME) as count values(COMPUTERNAME) as dest by _time, MESSAGE

[ESCU - Get Logon Rights Modifications For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-16
action.escu.modification_date = 2017-09-12
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search you must be ingesting your Windows event logs
action.escu.full_search_name = ESCU - Get Logon Rights Modifications For Endpoint
action.escu.search_type = investigative
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 86400
action.escu.latest_time_offset = 86400
description = This search allows you to retrieve any modifications to logon rights associated with a specific host.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=WinEventLog:Security (EventCode=4718 OR EventCode=4717) dest={dest} | rename user as "Account Modified" | table _time, dest, "Account Modified", Access_Right, signature

[ESCU - Baseline of Security Group Activity by ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-17
action.escu.modification_date = 2018-04-17
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = Use this search to create a baseline for API calls related to security groups by the users who initiated this activity. It returns all logged API calls for all security-group-related activity, pulls out the ARN that initiated each call, and collects the <code>eventNames</code> in one-hour groupings. Next, it calculates the number of API calls made per ARN per hour. For each ARN, it calculates the average and standard deviation of this count on a per-hour basis. It also includes the number of data points for each ARN. This table is stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove API event names for security groups, edit the macro <code>securityGroupAPIs</code>.
action.escu.full_search_name = ESCU - Baseline of Security Group Activity by ARN
action.escu.mappings = {"cis20": ["CIS 16"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
description = This search establishes, on a per-hour basis, the average and the standard deviation for the number of API calls related to security groups made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
dispatch.earliest_time = now
dispatch.latest_time = -90d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail `securityGroupAPIs` | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup security_group_activity_baseline

[ESCU - Unsuccessful Netbackup backups - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-15
action.escu.modification_date = 2017-09-12
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks across the most recent backup events for each host, and returns those messages that indicate there was a backup failure.
action.escu.how_to_implement = To successfully implement this search you need to obtain data from your backup solution, either from the backup logs on your endpoints or from a central server responsible for performing the backups. If you do not use Netbackup, you can modify this search for your specific backup solution.
action.escu.full_search_name = ESCU - Unsuccessful Netbackup backups
action.escu.mappings = {"cis20": ["CIS 10"], "nist": ["PR.IP"]}
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Netbackup"]
action.escu.analytic_story = ["Monitor Backup Solution"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
cron_schedule = 0 7 * * *
description = This search gives you the hosts where a backup was attempted and then failed.
dispatch.earliest_time = -24h@h
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype="netbackup_logs" | stats latest(_time) as latestTime by COMPUTERNAME, MESSAGE | search MESSAGE="An error occurred, failed to backup." | `ctime(latestTime)` | rename COMPUTERNAME as dest, MESSAGE as signature | table latestTime, dest, signature

[ESCU - EC2 Instance Started In Previously Unseen Region - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-02-01
action.escu.modification_date = 2018-02-23
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = In this search, we query CloudTrail logs to look for events that indicate that an instance was started in a particular region. Using the <code>previously_seen_aws_regions.csv</code> lookup file created using the support search, we compare the region where this instance was started to all previously observed regions. The <code>eval</code> and <code>if</code> functions determine that the earliest times seen for this region and instance were within the last day. If a new region is detected, it will alert you with "Instance Started in a New Region". However, this region will be added to the list of <code>previously_seen_aws_regions.csv</code>. Please maintain <code>previously_seen_aws_regions.csv</code>
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen AWS Regions" support search only once to create of baseline of previously seen regions.
action.escu.full_search_name = ESCU - EC2 Instance Started In Previously Unseen Region
action.escu.mappings = {"mitre_attack": ["Defense Evasion"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 12"], "nist": ["DE.DP", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS EC2 Activities", "AWS Cryptomining"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = awsRegion
action.risk.param._risk_object_type = region
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = awsRegion
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for CloudTrail events where an instance is started in a particular region in the last one hour and then compares it to a lookup file of previously seen regions where an instance was started
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail earliest=-1h StartInstances  | stats earliest(_time) as earliest latest(_time) as latest by awsRegion| inputlookup append=t previously_seen_aws_regions.csv | stats min(earliest) as earliest max(latest) as latest by awsRegion | outputlookup previously_seen_aws_regions.csv | eval regionStatus=if(earliest >= relative_time(now(), "-1d@d"), "Instance Started in a New Region","Previously Seen Region") | convert ctime(earliest) ctime(latest) | where regionStatus="Instance Started in a New Region"

[ESCU - Unusually Long Content-Type Length - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-03-14
action.escu.modification_date = 2017-10-13
action.escu.asset_at_risk = Web Server
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This detection search uses HTTP traffic data captured with Splunk Stream.  The search is constructed to use "stream:http" sourcetype and counts of the number of times an HTTP request is received by a destination which the length of the Content-Type header value the client sends the server is greater than 100 characters long. We calculate this content_type_length field and output the results.
action.escu.how_to_implement = This particular search leverages data extracted from Stream:HTTP. You must configure the http stream using the Splunk Stream App on your Splunk Stream deployment server to extract the cs_content_type field.
action.escu.full_search_name = ESCU - Unusually Long Content-Type Length
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 3", "CIS 4", "CIS 18", "CIS 12"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.IP", "DE.AE", "PR.MA", "DE.CM"]}
action.escu.kill_chain_phases = ["Delivery"]
action.escu.known_false_positives = Very few legitimate Content-Type fields will have a length greater than 100 characters.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for unusually long strings in the Content-Type http header that the client sends the server.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=stream:http | eval cs_content_type_length = len(cs_content_type) | where cs_content_type_length > 100 | table endtime src_ip dest_ip cs_content_type_length cs_content_type url

[ESCU - Malicious PowerShell Process - Connect To Internet With Hidden Window - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-18
action.escu.modification_date = 2017-09-07
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for PowerShell processes running with specific command-line arguments that indicate that the process will download a file from the Internet without display anything to the user. The search for "*-Exec*" is to check and see if the default execution policy for PowerShell is being overridden on the command-line. The search for "*-WindowStyle*" and "*hidden*" are to see if the window that would normally be displayed will be hidden from the user instead. Finally, the search for "*New-Object*" and "*System.Net.WebClient*" are there to check to see if a PowerShell object that can be used to download files will be created. This search will return the host, the user the process ran under, the process and it's command-line arguments, the number of times it's seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Connect To Internet With Hidden Window
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 7", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.kill_chain_phases = ["Command and Control", "Actions on Objectives"]
action.escu.known_false_positives = Legitimate process can have this combination of command-line options, but it's not common.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process, dest
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for PowerShell processes started with parameters to modify the execution policy of the run, run in a hidden window, and connect to the Internet. This combination of command-line options is suspicious because it's overriding the default PowerShell execution policy, attempts to hide its activity from the user, and connects to the Internet.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*powershell* cmdline="*-Exec*" cmdline="*-WindowStyle*" cmdline="*hidden*" cmdline="*New-Object*" cmdline="*System.Net.WebClient*" | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Protocol or Port Mismatch - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-18
action.escu.modification_date = 2017-09-11
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for instances in which the protocol observed is not consistent with the port and transport protocol typically used for that protocol. For example, looking for network traffic other than HTTP running over TCP port 80. Such behavior could indicate a misconfiguration or a custom command and control protocol that has been designed to look like ordinary web traffic. The search will also identify if HTTP traffic is observed running on unexpected ports. This can be common in many environments.
action.escu.how_to_implement = Running this search properly requires a technology that can inspect network traffic and identify common protocols. Technologies such as Bro and Palo Alto Networks firewalls are two examples that will identify protocols via inspection, and not just assume a specific protocol based on the transport protocol and ports.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Protocol or Port Mismatch
action.escu.mappings = {"mitre_attack": ["Command and Control", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 9", "CIS 12"], "nist": ["DE.AE", "PR.AC"]}
action.escu.kill_chain_phases = ["Command and Control"]
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Palo Alto Firewall", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Prohibited Traffic Allowed or Protocol Mismatch"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip, dest_port
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for network traffic on common ports where a higher layer protocol does not match the port that is being used. For example, this search should identify cases where protocols other than HTTP are running on TCP port 80. This can be used by attackers to circumvent firewall restrictions, or as an attempt to hide malicious communications over ports and protocols that are typically allowed and not well inspected.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where (All_Traffic.app=dns NOT All_Traffic.dest_port=53) OR ((All_Traffic.app=web-browsing OR All_Traffic.app=http) NOT (All_Traffic.dest_port=80 OR All_Traffic.dest_port=8080 OR All_Traffic.dest_port=8000)) OR (All_Traffic.app=ssl NOT (All_Traffic.dest_port=443 OR All_Traffic.dest_port=8443)) OR (All_Traffic.app=smtp NOT All_Traffic.dest_port=25) by All_Traffic.src_ip, All_Traffic.dest_ip, All_Traffic.app, All_Traffic.dest_port |`ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - Suspicious Changes to File Associations - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-26
action.escu.modification_date = 2018-01-26
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for changes made to the registry that control Windows file associations. It is typical for users to change the file association to open certain types of files with specific applications. However, when these changes are legitimately performed, they are typically done via the processes explorer.exe or openwith.exe. The search looks at Sysmon data with an event code of 13, which specifies setting a value in the registry. It then looks at the object path for these changes for matches to the area responsible for file associations and excludes changes made by the processes noted as typically being legitimate.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting information on registry changes that include the name of the process responsible for the changes from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Suspicious Changes to File Associations
action.escu.mappings = {"mitre_attack": ["Persistence", "Change Default File Association"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 8"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = There may be other processes in your environment that users may legitimately use to modify file associations. If this is the case and you are finding false positives, you can modify the search to add those processes as exceptions.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows File Extension and Association Abuse"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for changes to registry values that control Windows file associations, executed by a process that is not typical for legitimate, routine changes to this area.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) EventCode=13 object_path=*\\Explorer\\FileExts* process!=Explorer.exe AND process!=OpenWith.exe | stats count min(_time) as firstTime max(_time) as lastTime by dest, process, object_path, Details | rename Details as value | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Remote Desktop Process Running On System - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search finds systems that do not commonly use remote desktop. It does this by filtering out all systems that have the "common_rdp_source" category applied to that system.  Categories are applied to systems using the Assets and Identity framework.
action.escu.how_to_implement = This search requires you to identify systems that commonly use remote desktop. You can use the included support search "Identify Systems Using Remote Desktop" to identify these systems. After identifying these systems, you will need to add the "common_rdp_source" category to that system using the Enterprise Security Assets and Identities framework. This can be done by adding an entry in the assets.csv file located in SA-IdentityManagement/lookups.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Remote Desktop Process Running On System
action.escu.mappings = {"mitre_attack": ["Lateral Movement", "Remote Desktop Protocol"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 9", "CIS 16"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Remote Desktop may be used legitimately by users on the network.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Lateral Movement"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for the remote desktop process, mstsc.exe, running on systems it doesn't typically run on. This is accomplished by filtering out all systems that are noted in the common_rdp_source category in the Assets and Identity framework.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Application_State where All_Application_State.process = "*mstsc.exe*" AND All_Application_State.dest_category!=common_rdp_source by All_Application_State.dest All_Application_State.user All_Application_State.process | `ctime(firstTime)`| `ctime(lastTime)` | `drop_dm_object_name("All_Application_State")`

[ESCU - Detect New Local Admin account - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-26
action.escu.modification_date = 2018-03-26
action.escu.asset_at_risk = Windows
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for Windows Event Code 4720 (account creation) and 4732 (account added to a security-enabled local group), where the group name is "Administrators", and determines whether they are generated for the same user's Security ID within three hours of each other.  It will return the user account that was added, the Security ID, the group name to which the user was added, the account name of the user who initiated the action, and the subsequent message returned.
action.escu.how_to_implement = You must be ingesting Windows Security logs. You must also enable the account change auditing (<a href="http://docs.splunk.com/Documentation/Splunk/7.0.2/Data/MonitorWindowseventlogdata">here</a>). Additionally, this search requires you to enable your Group Management Audit Logs in your Local Windows Security Policy and to be ingesting those logs.  More information on how to enable them can be found <a href="http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/">here</a>. Finally, please make sure that the local administrator group name is "Administrators" to be able to look for the right group membership changes.
action.escu.full_search_name = ESCU - Detect New Local Admin account
action.escu.mappings = {"mitre_attack": ["Valid Accounts", "Defense Evasion", "Persistence"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "cis20": ["CIS 16"], "nist": ["PR.AC", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives", "Command and Control"]
action.escu.known_false_positives = The activity may be legitimate. For this reason, it's best to verify the account with an administrator and ask whether there was a valid service request for the account creation. If your local administrator group name is not "Administrators", this search may generate an excessive number of false positives
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
cron_schedule = 0 9 * * *
description = This search looks for newly created accounts that have been elevated to local administrators.
dispatch.earliest_time = -1440m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=wineventlog:security EventCode=4720 OR (EventCode=4732 Group_Name= Administrators) | transaction Security_ID maxspan=180m | search EventCode=4720 EventCode=4732 | table _time user dest EventCode Security_ID Group_Name src_user Message

[ESCU - Detect attackers scanning for vulnerable JBoss servers - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-10-04
action.escu.modification_date = 2017-09-23
action.escu.asset_at_risk = Web Server
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search returns the number of times a URL associated with this type of JexBoss probe is observed.
action.escu.how_to_implement = You must be ingesting data from the web server or network traffic that contains web specific information, and populating the Web data model.
action.escu.data_models = ["Web"]
action.escu.full_search_name = ESCU - Detect attackers scanning for vulnerable JBoss servers
action.escu.mappings = {"mitre_attack": ["Discovery", "System Information Discovery"], "kill_chain_phases": ["Reconnaissance"]}
action.escu.kill_chain_phases = ["Reconnaissance"]
action.escu.known_false_positives = It's possible for legitimate HTTP requests to be made to URLs containing the suspicious paths.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Palo Alto Firewall", "Apache", "Bro"]
action.escu.analytic_story = ["JBoss Vulnerability"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,url
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for specific GET or HEAD requests to web servers that are indicative of reconnaissance attempts to identify vulnerable JBoss servers. JexBoss is described as the exploit tool of choice for this malicious activity.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Web where (Web.http_method="GET" OR Web.http_method="HEAD") AND (Web.url="*/web-console/ServerInfo.jsp*" OR Web.url="*web-console*" OR Web.url="*jmx-console*" OR Web.url = "*invoker*") by Web.http_method, Web.url, Web.src, Web.dest | `drop_dm_object_name("Web")` | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Investigate AWS activities via region name]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-02-09
action.escu.modification_date = 2018-02-09
action.escu.channel = ESCU
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Investigate AWS activities via region name
action.escu.search_type = investigative
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS EC2 Activities"]
action.escu.fields_required = ["awsRegion"]
action.escu.earliest_time_offset = 14400
action.escu.latest_time_offset = 0
description = This search lists all the user activities logged by CloudTrail for a specific region in question and will create a table of the values of parameters requested, the type of the event and the response from the AWS API by each user
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=aws:cloudtrail awsRegion={awsRegion}| rename requestParameters.instancesSet.items{}.instanceId as instanceId| stats values(eventName) by userName instanceId

[ESCU - Get EC2 Instance Details by instanceId]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-02-12
action.escu.modification_date = 2018-02-12
action.escu.channel = ESCU
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
action.escu.full_search_name = ESCU - Get EC2 Instance Details by instanceId
action.escu.search_type = contextual
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Unusual AWS EC2 Modifications", "Suspicious AWS EC2 Activities"]
action.escu.fields_required = ["instanceId"]
action.escu.earliest_time_offset = 86400
action.escu.latest_time_offset = 0
description = This search queries AWS description logs and returns all the information about a specific instance via the instanceId field
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype="aws:description" source="*:ec2_instances"| dedup id sortby -_time | search id={instanceId} | spath output=tags path=tags | eval tags=mvzip(key,value," = "), ip_address=if((ip_address == "null"),private_ip_address,ip_address) | table id, tags.Name, aws_account_id, placement, instance_type, key_name, ip_address, launch_time, state, vpc_id, subnet_id, tags | rename aws_account_id as "Account ID", id as ID, instance_type as Type, ip_address as "IP Address", key_name as "Key Pair", launch_time as "Launch Time", placement as "Availability Zone", state as State, subnet_id as Subnet, "tags.Name" as Name, vpc_id as VPC

[ESCU - AWS Network Access Control List Created with All Open Ports - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-01-08
action.escu.modification_date = 2017-01-10
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = A network access control list (ACL) is a layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets. Network ACLs with all open ports have a larger attack surface. This search looks for events within your CloudTrail logs to check if there were any Network ACLs created with ports ranging from 1024 to 65525. This search will create a table comprised of AWS account id, src src user and all parameters of the request made by the user and the server response.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS, version 4.4.0 or later, and configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - AWS Network Access Control List Created with All Open Ports
action.escu.mappings = {"mitre_attack": ["Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 11"], "nist": ["DE.DP", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It's possible that an admin has created this ACL with all ports open for some legitimate purpose however, this should be scoped and not allowed in production environment.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = The search looks for CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.
dispatch.earliest_time = -1d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=CreateNetworkAclEntry | mvexpand requestParameters | mvexpand responseElements | search requestParameters.portRange.from=1024 requestParameters.portRange.to=65525 requestParameters.ruleAction=allow | rename userIdentity.arn as arn | rename requestParameters.networkAclId as networkAclId | table _time aws_account_id src userName arn networkAclId requestParameters.* responseElements.*

[ESCU - Detect Unauthorized Assets by MAC address - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-11
action.escu.modification_date = 2017-09-13
action.escu.asset_at_risk = Infrastructure
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search requires you to leverage the Enterprise Security Assets and Identity framework to populate assets_by_str.csv. Once the assets_by_str.csv is populated, we then query your DHCP logs to detect unknown systems connecting to your network. More documentation is available at: http://docs.splunk.com/Documentation/ES/4.7.1/Admin/Verifyassetandidentitydata.
action.escu.how_to_implement = This search uses the Network_Sessions data model shipped with Enterprise Security. It leverages the Assets and Identity framework to populate the assets_by_str.csv file which will contain a list of known authorized organizational assets including their MAC addresses. Ensure that all inventoried systems have their MAC address populated.
action.escu.data_models = ["Network_Sessions"]
action.escu.full_search_name = ESCU - Detect Unauthorized Assets by MAC address
action.escu.mappings = {"mitre_attack": ["Defense Evasion"], "kill_chain_phases": ["Reconnaissance", "Delivery", "Actions on Objectives"], "cis20": ["CIS 1"], "nist": ["ID.AM", "PR.DS"]}
action.escu.kill_chain_phases = ["Reconnaissance", "Delivery", "Actions on Objectives"]
action.escu.known_false_positives = This search might be prone to high false positives. Please consider this when conducting analysis or investigations. Authorized devices may be detected as unauthorized. If this is the case, verify the MAC address of the system responsible for the false positive and add it to the Assets and Identity framework with the proper information.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Asset Tracking"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_mac,src_ip
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = By populating the organization's assets within the assets_by_str.csv, we will be able to detect unauthorized devices that are trying to connect with the organization's network by inspecting DHCP request packets, which are issued by devices when they attempt to obtain an IP address from the DHCP server. The MAC address associated with the source of the DHCP request is checked against the list of known devices, and reports on those that are not found.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count from datamodel=Network_Sessions where nodename=All_Sessions.DHCP All_Sessions.signature=DHCPREQUEST by All_Sessions.src_ip All_Sessions.src_mac | dedup All_Sessions.src_mac| search NOT [| inputlookup  | fields + mac]

[ESCU - Spectre and Meltdown Vulnerable Systems - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-07
action.escu.modification_date = 2017-01-07
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks for the three CVEs associated with the Spectre and Meltdown vulnerabilities.
action.escu.how_to_implement = The search requires that you are ingesting your vulnerability-scanner data and that it reports the CVE of the vulnerability identified.
action.escu.data_models = ["Vulnerabilities"]
action.escu.full_search_name = ESCU - Spectre and Meltdown Vulnerable Systems
action.escu.mappings = {"cis20": ["CIS 4"], "nist": ["ID.RA", "RS.MI", "PR.IP", "DE.CM"]}
action.escu.known_false_positives = It is possible that your vulnerability scanner is not detecting that the patches have been applied.
action.escu.search_type = detection
action.escu.providing_technologies = ["Nessus", "Qualys"]
action.escu.analytic_story = ["Spectre And Meltdown Vulnerabilities"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 100
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
cron_schedule = 0 6 * * *
description = The search is used to detect systems that are still vulnerable to the Spectre and Meltdown vulnerabilities.
dispatch.earliest_time = -25h@h
dispatch.latest_time = -1h@h
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` min(_time) as firstTime max(_time) as lastTime from datamodel=Vulnerabilities where Vulnerabilities.cve ="CVE-2017-5753" OR Vulnerabilities.cve ="CVE-2017-5715" OR Vulnerabilities.cve ="CVE-2017-5754" by Vulnerabilities.dest

[ESCU - Get Notable History]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-03-15
action.escu.modification_date = 2017-09-20
action.escu.channel = ESCU
action.escu.how_to_implement = If you are using Enterprise Security you are likely already creating notable events with your correlation rules. No additional configuration is necessary.
action.escu.full_search_name = ESCU - Get Notable History
action.escu.search_type = contextual
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.analytic_story = ["Monitor for Updates", "Router & Infrastructure Security", "Windows Log Manipulation", "Windows Defense Evasion Tactics", "Monitor Backup Solution", "Unusual AWS EC2 Modifications", "Host Redirection", "Windows Privilege Escalation", "Malicious PowerShell", "Lateral Movement", "JBoss Vulnerability", "Asset Tracking", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "Suspicious AWS Login Activities", "DNS Amplification Attacks", "Collection and Staging", "Spectre And Meltdown Vulnerabilities", "DHS Report TA18-074A", "Windows File Extension and Association Abuse", "Suspicious DNS Traffic", "Suspicious Emails", "Windows Persistence Techniques", "Account Monitoring and Controls", "Suspicious AWS EC2 Activities", "Use of Cleartext Protocols", "Disabling Security Tools", "Splunk Enterprise Vulnerability", "SQL Injection", "AWS Network ACL Activity", "Data Protection", "Dynamic DNS", "Suspicious AWS Traffic", "Ransomware", "Brand Monitoring", "Apache Struts Vulnerability", "Suspicious Command-Line Executions", "Suspicious WMI Use", "Netsh Abuse", "Unusual Processes", "AWS User Monitoring", "Windows Service Abuse"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 864000
action.escu.latest_time_offset = 86400
description = This search queries the notable index and returns all the Notable Events for the particular destination host, giving the analyst an overview of the incidents that may have occurred with the host under investigation.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search `notable` | search dest={dest} | table _time, rule_name, owner, priority, severity, status_description

[ESCU - EC2 Instance Started With Previously Unseen AMI - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The subsearch returns the AMI image ID of all successful EC2 instance launches within the last hour and then appends the historical data from the lookup file to those results.  It then recalculates the earliest and latest seen time field for each AMI image ID and returns only those AMI image IDs that have first been seen in the past hour.  This is combined with the main search to return the time, user, and instance id of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 AMIs" support search once to create a history of previously seen AMIs.
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen AMI
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.known_false_positives = After a new AMI is created, the first systems created with that AMI will cause this alert to fire.  Verify that the AMI being used was created by a legitimate user.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for EC2 instances being created with previously unseen AMIs.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=RunInstances [search sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | stats earliest(_time) as earliest latest(_time) as latest by requestParameters.instancesSet.items{}.imageId | rename requestParameters.instancesSet.items{}.imageId as amiID | inputlookup append=t previously_seen_ec2_amis.csv | stats min(earliest) as earliest max(latest) as latest by amiID | outputlookup previously_seen_ec2_amis.csv | eval newAMI=if(earliest >= relative_time(now(), "-1h@h"), 1, 0) | convert ctime(earliest) ctime(latest) | where newAMI=1 | rename amiID as requestParameters.instancesSet.items{}.imageId | table requestParameters.instancesSet.items{}.imageId] | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest, userIdentity.arn as arn, requestParameters.instancesSet.items{}.imageId as amiID | table _time, arn, amiID, dest, instanceType

[ESCU - Processes launching netsh - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-01-08
action.escu.modification_date = 2018-01-04
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for all the parent processes of netsh.exe and returns that process, the command-line used to execute netsh, the host name, and the user context under which it ran.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with the process name, command-line arguments, and parent process from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Processes launching netsh
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface", "Persistence", "Defense Evasion", "Disabling Security Tools"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Some VPN applications are known to launch netsh.exe, otherwise it is unusual for an executable to launch netsh.exe and execute commands.
action.escu.search_type = detection
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Disabling Security Tools", "Netsh Abuse"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, parent_process
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for processes launching netsh.exe. Netsh.exe is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper DLL when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe and executing commands via command-line.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational process_name=netsh.exe | stats count values(cmdline) as cmdline min(_time) as firstTime max(_time) as lastTime by dest user parent_process process | `ctime(firstTime)`|`ctime(lastTime)` | table firstTime lastTime dest parent_process process cmdline count

[ESCU - Web Servers Executing Suspicious Processes - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-03-14
action.escu.modification_date = 2017-09-11
action.escu.asset_at_risk = Web Server
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This detection search uses the Enterprise Security Application State data model. The search uses tstats to search within an accelerated data model to find suspicious applications or processes such as whoami, ping, iptables, wget, service, or curl, running on hosts which are marked as web servers in the Assets and Identity Framework of ES.
action.escu.how_to_implement = To successfully implement this detection search, Splunk needs to ingest data around process activity, such as that generated by endpoint security tools such as Carbon Black or endpoint data sources such as Sysmon, and populate the Application_State data model. In addition, web servers will need to be identified in the Assets and Identity Framework of Enterprise Security.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Web Servers Executing Suspicious Processes
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability", "Execution", "Discovery", "System Information Discovery"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Some of these processes may be used legitimately on web servers during maintenance or other administrative tasks.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for suspicious processes on all systems labeled as web servers.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Application_State where All_Application_State.dest_category="web_server" AND (All_Application_State.process="*whoami*" OR All_Application_State.process="*ping*" OR All_Application_State.process="*iptables*" OR All_Application_State.process="*wget*" OR All_Application_State.process="*service*" OR All_Application_State.process="*curl*") by All_Application_State.process, All_Application_State.dest | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Application_State")`

[ESCU - Schtasks used for forcing a reboot - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-11-03
action.escu.modification_date = 2017-11-03
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate a task is being scheduled that would cause a forced reboot on the host. Schtasks.exe is a native windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or establish persistence. This tactic is leveraged by the Bad Rabbit Ransomware.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Schtasks used for forcing a reboot
action.escu.mappings = {"mitre_attack": ["Persistence", "Execution", "Scheduled Task"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Administrators may create jobs on systems forcing reboots to perform updates, maintenance, etc.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Persistence Techniques", "Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, cmdline
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for flags passed to schtasks.exe on the command-line that indicate that a forced reboot of system is scheduled.
dispatch.earliest_time = -5h@h
dispatch.latest_time = -1h@h
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*schtasks.exe shutdown.exe | search (cmdline=*/r* AND cmdline=*/f*) | stats count values(cmdline) min(_time) as firstTime max(_time) as lastTime by dest process | `ctime(firstTime)`  | `ctime(lastTime)`

[ESCU - Previously Seen EC2 Launches By User]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-15
action.escu.modification_date = 2018-03-15
action.escu.asset_at_risk = EC2 Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = In this support search, we create a table of the earliest and latest times that an ARN has launched a EC2 instance. This table is then outputted to a .csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Previously Seen EC2 Launches By User
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS EC2 Activities", "AWS Cryptomining"]
description = This search builds a table of previously seen ARNs that have launched a EC2 instance.
dispatch.earliest_time = -5m@m
dispatch.latest_time = -90d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | rename userIdentity.arn as arn | stats earliest(_time) as firstTime latest(_time) as lastTime by arn | outputlookup previously_seen_ec2_launches_by_user.csv

[ESCU - Detect Long DNS TXT Record Response - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-18
action.escu.modification_date = 2017-09-18
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search uses the Network_Resolution data model and gathers all the answers to DNS queries for TXT records. The query then looks at the answer section and calculates the length of the answer. The search will then return information for those responses that exceed 100 characters in length.
action.escu.how_to_implement = To successfully implement this search you need to ingest data from your DNS logs, or monitor DNS traffic using Stream, Bro or something similar. Specifically, this query requires that the DNS data model is populated with information regarding the DNS record type that is being returned as well as the data in the answer section of the protocol.
action.escu.data_models = ["Network_Resolution"]
action.escu.full_search_name = ESCU - Detect Long DNS TXT Record Response
action.escu.mappings = {"mitre_attack": ["Command and Control", "Exfiltration", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 8", "CIS 12", "CIS 13"], "nist": ["PR.DS", "PR.PT", "DE.AE", "DE.CM"]}
action.escu.kill_chain_phases = ["Command and Control"]
action.escu.known_false_positives = It's possible that legitimate TXT record responses can be long enough to trigger this search. You can modify the packet threshold for this search to help mitigate false positives.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Suspicious DNS Traffic"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search is used to detect attempts to use DNS tunneling, by calculating the length of responses to DNS TXT queries. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting unusually large volumes of DNS traffic.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Resolution where DNS.message_type=response AND DNS.record_type=TXT by DNS.src DNS.dest DNS.answer DNS.record_type |  `drop_dm_object_name("DNS")` | eval anslen=len(answer) | search anslen>100 | `ctime(firstTime)` | `ctime(lastTime)` | rename src as "Source IP", dest as "Destination IP", answer as "DNS Answer" anslen as "Answer Length" record_type as "DNS Record Type" firstTime as "First Time" lastTime as "Last Time" count as Count | table "Source IP" "Destination IP" "DNS Answer" "DNS Record Type"  "Answer Length" Count "First Time" "Last Time"

[ESCU - Suspicious Reg.exe Process - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-10-11
action.escu.modification_date = 2017-10-23
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for the execution of reg.exe with a parent process of cmd.exe. It then executes a subsearch looking for those cmd.exe processes with a parent that is not explorer.exe. It then joins those two searches to make sure that the reg.exe process is a grandchild of the non explorer.exe process. The search will return the number of such instances and the first and last time this activity has been seen on each endpoint and user.
action.escu.how_to_implement = To successfully implement this search, you need to ingest logs with the process name and command-line, as well as the parent process name from your endpoints. If you are using Sysmon, you will need to have a Splunk Universal Forwarder on each endpoint that you want to collect the data on. You will also need to deploy the Sysmon TA on these endpoints and on your search head. You must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Suspicious Reg.exe Process
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Modify Registry", "Disabling Security Tools"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It's possible for system administrators to write scripts that exhibit this behavior. If this is the case, the search will need to be modified to filter them out.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "DHS Report TA18-074A", "Disabling Security Tools"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for reg.exe being launched from a command prompt not started by the user. When a user launches cmd.exe, the parent process is usually explorer.exe. This search filters out those instances.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = process=reg.exe parent_process=*cmd.exe [search process=cmd.exe parent_process!=*explorer.exe | fields process_id | dedup process_id | rename process_id as parent_process_id] | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Suspicious writes to windows Recycle Bin - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.asset_at_risk = Windows
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search uses data on file writes captured via Sysmon to watch for writes to the Recycle Bin by processes other than explorer.exe. The search looks for event code 11 in the Sysmon events, which indicates a file-creation event. Next, it looks for files created with a path that includes the string "$Recycle.Bin" by processes other than explorer.exe, which is the process responsible for copying files to the Recycle Bin on delete. It will report the system where the activity occurred, the path to which the file was written, the process responsible for the write, and the times it first and last saw this activity.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Suspicious writes to windows Recycle Bin
action.escu.mappings = {"mitre_attack": ["Collection", "Data Staged"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.known_false_positives = Because the Recycle Bin is a hidden folder in modern versions of Windows, it would be unusual for a process other than explorer.exe to write to it. Incidents should be investigated as appropriate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Collection and Staging"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search detects writes to the recycle bin by a process other than explorer.exe.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) EventCode=11 file_path=*$Recycle.Bin* process!=explorer.exe | stats count min(_time) as firstTime max(_time) as lastTime by dest, Image, file_path | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Clients Connecting to Multiple DNS Servers - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-18
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Communications with multiple DNS servers from a single client is unusual and may be indicative of malicious activity. This search works by performing a count by the source of the distinct destinations for the DNS traffic. The search uses the <code>Network_Resolution</code> data model.
action.escu.how_to_implement = This search requires that DNS data is being ingested and populating the <code>Network_Resolution</code> data model. This data can come from DNS logs or from solutions that parse network traffic for this data, such as Splunk Stream or Bro.
action.escu.data_models = ["Network_Resolution"]
action.escu.full_search_name = ESCU - Clients Connecting to Multiple DNS Servers
action.escu.mappings = {"mitre_attack": ["Command and Control", "Exfiltration", "Exfiltration Over Alternative Protocol", "Commonly Used Port", "Standard Application Layer Protocol"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 9", "CIS 12", "CIS 13"], "nist": ["PR.PT", "DE.AE", "PR.DS"]}
action.escu.kill_chain_phases = ["Command and Control"]
action.escu.known_false_positives = It's possible that an enterprise has more than five DNS servers that are configured in a round-robin rotation. Please customize the search, as appropriate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Suspicious DNS Traffic"]
action.notable = 1
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search allows you to identify the endpoints that have connected to more than five DNS servers over the time frame of the search.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count, values(DNS.dest) AS dest dc(DNS.dest) as dest_count from datamodel=Network_Resolution by DNS.src | where dest_count > 5

[ESCU - Monitor Registry Keys for Print Monitors - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-12-01
action.escu.modification_date = 2017-12-01
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = In this search, we look for modifications to registry keys used for adding Print Monitors Entries on Microsoft platforms via the object_category and object_path field in the Change Analysis data model and give you the destination, command used to initiate the change, the user who conducted this activity, the resource affected(object), and the whole path of the object.
action.escu.how_to_implement = To successfully implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or other endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report registry modifications.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Monitor Registry Keys for Print Monitors
action.escu.mappings = {"mitre_attack": ["Persistence", "Privilege Escalation", "Local Port Monitor"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8", "CIS 5"], "nist": ["PR.PT", "DE.CM", "PR.AC"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = You will encounter noise with respect to legitimate print monitor registry entries.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, object_path
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for registry activity associated with modifications made to the registry key <code>HKLM\SYSTEM\CurrentControlSet\Control\Print\Monitors</code>. In this scenario, an attacker can load an arbitrary DLL into the Print Monitor registry by giving the full path name to the DLL and the system will execute the DLL with elevated (SYSTEM) permissions and will also persist on a reboot.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND All_Changes.object_path="*CurrentControlSet\\Control\\Print\\Monitors*" by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `drop_dm_object_name("All_Changes")`

[ESCU - Previously Seen AWS Regions]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = In this support search, we create a table of the first time (earliest) and most recent time (latest) that this region has been seen in our dataset, grouped by the value <code>awsRegion</code>. We only look for those events where an instance has been started. All of these entries will be added to the <code>previously_seen_aws_regions.csv</code> lookup file, which will act like a baseline for detections. Please validate the entries of region names in the lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Previously Seen AWS Regions
action.escu.mappings = {"cis20": ["CIS 12"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS EC2 Activities", "AWS Cryptomining"]
description = This search looks for CloudTrail events where an AWS instance is started and creates a baseline of most recent time (latest) and the first time (earliest) we've seen this region in our dataset grouped by the value awsRegion for the last 30 days
dispatch.earliest_time = now
dispatch.latest_time = -30d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail StartInstances | stats earliest(_time) as earliest latest(_time) as latest by awsRegion | outputlookup previously_seen_aws_regions.csv

[ESCU - Get All AWS Activity From Region]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.channel = ESCU
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Get All AWS Activity From Region
action.escu.search_type = investigative
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.fields_required = ["Region"]
action.escu.earliest_time_offset = 14400
action.escu.latest_time_offset = 0
description = This search retrieves all the activity from a specific geographic region and will create a table containing the time, geographic region, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API callled, and whether or not the API call was successful.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search Region={Region} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, Region, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Get DNS Server History for a host]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-11-09
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search, you must be ingesting your DNS traffic
action.escu.full_search_name = ESCU - Get DNS Server History for a host
action.escu.search_type = investigative
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Host Redirection", "Suspicious DNS Traffic", "Data Protection", "Dynamic DNS", "Brand Monitoring"]
action.escu.fields_required = ["src_ip"]
action.escu.earliest_time_offset = 0
action.escu.latest_time_offset = 86400
description = While investigating any detections it is important to understand which and how many DNS servers a host has connected to in the past. This search uses data that is tagged as DNS and gives you a count and list of DNS servers that a particular host has connected to the previous 24 hours.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search tag=dns src_ip={src_ip} dest_port=53 | streamstats time_window=1d count values(dest_ip) as dcip by src_ip | table date_mday src_ip dcip count | sort -count

[ESCU - Previously Seen EC2 Instance Types]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-08
action.escu.modification_date = 2018-03-08
action.escu.asset_at_risk = EC2 Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = In this support search, we create a table of the earliest and latest time that a specific EC2 instance type has been seen. The instanceType request field is not required and defaults to m1.small, so any time this field is null, the search defaults the field to m1.small. This table is then outputted to a csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Previously Seen EC2 Instance Types
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining"]
description = This search builds a table of previously seen EC2 instance types
dispatch.earliest_time = -5m@m
dispatch.latest_time = -90d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | rename requestParameters.instanceType as instanceType | fillnull value="m1.small" instanceType | stats earliest(_time) as earliest latest(_time) as latest by instanceType | outputlookup previously_seen_ec2_instance_types.csv

[ESCU - Abnormally High AWS Instances Launched by User - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-02-26
action.escu.modification_date = 2018-02-26
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = In this search, we query CloudTrail logs to look for events where an instance is successfully launched by a particular user. Since we want to detect a high number of instances launched within a short period of time, we create event buckets for 10-minute windows. We then calculate the total number of instances launched by a particular user, as well as the average and standard deviation values. Assign a <code>threshold_value</code> in the search. Start with 3 (but it will likely need to be tweaked for your environment). The <code>eval</code> function will set the outlier 1 if the number of instances is greater than the average number of instances terminated, added to the multiplied value of threshold and standard deviation. For your reference, we then keep only the outliers and calculate the number of standard deviations away the value is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. The threshold value should be tuned to your environment.
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Launched by User
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 13"], "nist": ["DE.DP", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS EC2 Activities", "AWS Cryptomining"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = userName
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = userName
alert.suppress.period = 3600s
cron_schedule = */10 * * * *
description = This search looks for CloudTrail events where a user successfully launches an abnormally high number of instances.
dispatch.earliest_time = -30d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | bucket span=10m _time | stats count AS instances_launched by _time userName | eventstats avg(instances_launched) as total_launched_avg, stdev(instances_launched) as total_launched_stdev | eval threshold_value = 4 | eval isOutlier=if(instances_launched > total_launched_avg+(total_launched_stdev * threshold_value), 1, 0) | search isOutlier=1 AND _time >= relative_time(now(), "-10m@m") | eval num_standard_deviations_away = round(abs(instances_launched - total_launched_avg) / total_launched_stdev, 2) | table _time, userName, instances_launched, num_standard_deviations_away, total_launched_avg, total_launched_stdev

[ESCU - Email servers sending high volume traffic to hosts - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-12-20
action.escu.modification_date = 2017-12-20
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search may look complex, but it's a neat representation of how statistics can help you understand your dataset to bubble up events that are not normal compared to its behavior. The search consists of three parts. The first part of the SPL fetches the data you want to work on. In this search, we calculate the sum of bytes sent and bytes_out from systems categorized as email_server to each host. We then calculate the average and standard deviation for the bytes sent to all the hosts combined and on a per-host basis. Then we set threshold values to deviation_threshold and minimum_data_samples using eval statements. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.  We then check for byte transfers that are statistically significantly higher than normal. The search then gives IP address of the host, the time of the increased byte transfer, how much data was transferred, and the average amount of data transfer the email server normally sends to all hosts and to this specific host. Finally, it includes the number of standard deviations away the byte count was from these averages.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.  Your email servers must be categorized as "email_server" for the search to work, as well. You may need to adjust the deviation_threshold and minimum_data_samples values based on the network traffic in your environment. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Email servers sending high volume traffic to hosts
action.escu.mappings = {"mitre_attack": ["Collection", "Email Collection", "Commonly Used Port"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 7"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = The false-positive rate will vary based on how you set the deviation_threshold and data_samples values. Our recommendation is to adjust these values based on your network traffic to and from your email servers.
action.escu.search_type = detection
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["Collection and Staging"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip
alert.suppress.period = 86400s
cron_schedule = 0 0 * * *
description = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
dispatch.earliest_time = -30d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats summariesonly=t allow_old_summaries=t sum(All_Traffic.bytes_out) as bytes_out from datamodel=Network_Traffic where All_Traffic.src_category=email_server by All_Traffic.dest_ip _time span=1d | `drop_dm_object_name("All_Traffic")` | eventstats avg(bytes_out) as avg_bytes_out stdev(bytes_out) as stdev_bytes_out | eventstats count as num_data_samples avg(eval(if(_time < relative_time(now(), "@d"), bytes_out, null))) as per_source_avg_bytes_out stdev(eval(if(_time < relative_time(now(), "@d"), bytes_out, null))) as per_source_stdev_bytes_out by dest_ip | eval minimum_data_samples = 4, deviation_threshold = 3 | where num_data_samples >= minimum_data_samples AND bytes_out > (avg_bytes_out + (deviation_threshold * stdev_bytes_out)) AND bytes_out > (per_source_avg_bytes_out + (deviation_threshold * per_source_stdev_bytes_out)) AND _time >= relative_time(now(), "@d") | eval num_standard_deviations_away_from_server_average = round(abs(bytes_out - avg_bytes_out) / stdev_bytes_out, 2), num_standard_deviations_away_from_client_average = round(abs(bytes_out - per_source_avg_bytes_out) / per_source_stdev_bytes_out, 2) | table dest_ip, _time, bytes_out, avg_bytes_out, per_source_avg_bytes_out, num_standard_deviations_away_from_server_average, num_standard_deviations_away_from_client_average

[ESCU - Excessive DNS Failures - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-18
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks at DNS traffic with a reply code that is NOT indicative of a successful response. A large number of unsuccessful replies may be indicative of DNS protocol tampering or other malicious activity. If more than 50 of these unsuccessful responses are observed over the time frame of the search, a notable event will be generated.
action.escu.how_to_implement = To successfully implement this search you must ensure that DNS data is populating the Network_Resolution data model.
action.escu.data_models = ["Network_Resolution"]
action.escu.full_search_name = ESCU - Excessive DNS Failures
action.escu.mappings = {"mitre_attack": ["Exfiltration", "Exfiltration Over Alternative Protocol", "Command and Control", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 8", "CIS 9", "CIS 12"], "nist": ["PR.PT", "DE.AE", "DE.CM"]}
action.escu.kill_chain_phases = ["Command and Control"]
action.escu.known_false_positives = It is possible legitimate traffic can trigger this rule. Please investigate as appropriate. The threshold for generating an event can also be customized to better suit your environment.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Suspicious DNS Traffic"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src,query
alert.suppress.period = 43200s
cron_schedule = 0 * * * *
description = This search identifies DNS query failures by counting the number of DNS responses that do not indicate success, and trigger on more than 50 occurrences.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count values("DNS.query") as queries from datamodel=Network_Resolution where nodename=DNS "DNS.reply_code"!="No Error" "DNS.reply_code"!="NoError" DNS.reply_code!="unknown" NOT "DNS.query"="*.arpa" "DNS.query"="*.*" by "DNS.src","DNS.query"| `drop_dm_object_name("DNS")`| lookup cim_corporate_web_domain_lookup domain as query OUTPUT domain| where isnull(domain)| lookup update=true alexa_lookup_by_str domain as query OUTPUT rank| where isnull(rank)| stats sum(count) as count mode(queries) as queries by src| `get_asset(src)`| where count>50

[ESCU - DNS Query Length With High Standard Deviation - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-18
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Attackers often use random, long domain names for their attack infrastructure. This search looks at all of the queries observed over the search time frame, and identifies any domains being resolved with names that are greater that 2 times the standard deviation.
action.escu.how_to_implement = To successfully implement this search, you will need to ensure that DNS data is populating the Network_Resolution data model.
action.escu.data_models = ["Network_Resolution"]
action.escu.full_search_name = ESCU - DNS Query Length With High Standard Deviation
action.escu.mappings = {"mitre_attack": ["Command and Control", "Exfiltration", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 8", "CIS 12"], "nist": ["PR.PT", "DE.AE", "DE.CM"]}
action.escu.kill_chain_phases = ["Command and Control"]
action.escu.known_false_positives = It's possible there can be long domain names that are legitimate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Suspicious DNS Traffic"]
action.notable = 1
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = query
alert.suppress.period = 43200s
cron_schedule = 0 * * * *
description = This search allows you to identify DNS requests and compute the standard deviation on the length of the names being resolved, then filter on two times the standard deviation to show you those queries that are unusually large for your environment.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count from datamodel=Network_Resolution by DNS.query DNS.record_type |  `drop_dm_object_name("DNS")` | eval query_length = len(query) | table query query_length record_type count stdev | eventstats stdev(query_length) AS stdev avg(query_length) AS avg p50(query_length) AS p50| where query_length>(stdev*2)

[ESCU - USN Journal Deletion - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-27
action.escu.modification_date = 2017-09-12
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for the execution of fsutil.exe with command-line arguments to delete the USN journal. The search returns the count of the number of times it's seen this process execution with these arguments, the first and last time it's seen this behavior, the hosts it was executed on, and the user context under which it was executed.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - USN Journal Deletion
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Indicator Removal on Host"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 6", "CIS 8", "CIS 10"], "nist": ["DE.CM", "PR.PT", "DE.AE", "DE.DP", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Log Manipulation", "Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = The fsutil.exe application is a legitimate Windows utility used to perform tasks related to the file allocation table (FAT) and NTFS file systems. The update sequence number (USN) change journal provides a log of all changes made to the files on the disk. This search looks for fsutil.exe deleting the USN journal.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*fsutil* cmdline="*deletejournal*" cmdline="*usn*" | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Identify Systems Creating Remote Desktop Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-24
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search counts the numbers of times the system has tried to connect to another system on TCP/3389, the default port used for RDP traffic.
action.escu.how_to_implement = To successfully implement this search, you must ingest network traffic and populate the Network_Traffic data model.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Identify Systems Creating Remote Desktop Traffic
action.escu.mappings = {"mitre_attack": ["Lateral Movement", "Remote Desktop Protocol"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 9", "CIS 16"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.search_type = support
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Lateral Movement"]
description = This search counts the numbers of times the system has generated remote desktop traffic.
dispatch.earliest_time = now
dispatch.latest_time = -30d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=3389 by All_Traffic.src | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Disabling Remote User Account Control - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-10-12
action.escu.modification_date = 2017-10-10
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search checks to see if the registry key SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\System\LocalAccountTokenFilterPolicy was modified.  This registry key can be used to disable remote User Account Control.  The search returns the count, the first time activity was seen, last time activity was seen, the registry path that was modified, the host where the modification took place and the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Disabling Remote User Account Control
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Modify Registry"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = This registry key may be modified via administrators to implement a change in system policy. This type of change should be a very rare occurrence.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Windows Defense Evasion Tactics"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user, object_path
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = The search looks for modifications to registry keys that control the enforcement of Windows User Account Control (UAC).
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND All_Changes.object_path="*Windows\\CurrentVersion\\Policies\\System\\LocalAccountTokenFilterPolicy" by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes")`

[ESCU - AWS Cloud Provisioning From Previously Unseen City - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a <code>GeoIP</code> lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the <code>firstTime</code> and <code>lastTime</code> field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the <code>firstTime</code> and <code>lastTime</code> for each city. It returns only those events from cities that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen City
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.<br/><br/> This search will fire any time a new city is seen in the <b>GeoIP</b> database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your city, there should be few false positives. If you are located in countries where the free version of <b>MaxMind GeoIP</b> that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for AWS provisioning activities from previously unseen cities.  Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search City=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search City=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by City | eval newCity=if(firstTime >= relative_time(now(), "-1h@h"), 1, 0) | where newCity=1 | table City] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, City, eventName, errorCode

[ESCU - System Processes Run From Unexpected Locations - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-08-24
action.escu.modification_date = 2018-04-16
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search returns all the processes that are not executing out of the C:\Windows\System32 or C:\Windows\SysWOW64 directories. It then uses a regular expression to extract the file name of the running process. Next, it takes the filename and looks it up in a table of files that should normally run out of the C:\Windows\System32 or C:\Windows\SysWOW64 directory. Any matches are then returned.
action.escu.how_to_implement = To successfully implement this search you need to ingest details about process execution from your hosts. Specifically, this search requires the process name and the full path to the process executable.
action.escu.full_search_name = ESCU - System Processes Run From Unexpected Locations
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Masquerading"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Suspicious Command-Line Executions", "Unusual Processes"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for system processes that normally run out of C:\Windows\System32\ or C:\Windows\SysWOW64 that are not run from that location.  This can indicate a malicious process that is trying to hide as a legitimate process.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational EventCode=1 NOT Image="C:\\Windows\\System32*" NOT Image="C:\\Windows\\SysWOW64*" | rex field=Image .*\\\(?<filename>\S+)\s?$ | `isWindowsSystemFile` | rename Image as process | table _time, dest, user, process, process_id, parent_process

[ESCU - Common Ransomware Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-21
action.escu.modification_date = 2017-09-10
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks at file modifications across your hosts and identifies files with extensions that are commonly associated with the encrypted files generated by Ransomware.
action.escu.how_to_implement = In order to implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or other endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report file system reads and writes.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Common Ransomware Extensions
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It is possible for a legitimate file with these extensions to be created. If a true Ransomware attack, there will be a large number of files created with these extensions.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = The search looks for file modifications with extensions commonly used by Ransomware
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis where All_Changes.object_category=file by All_Changes.Endpoint_Changes.Filesystem_Changes.file_name All_Changes.Endpoint_Changes.Filesystem_Changes.file_path All_Changes.dest | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes")` | `drop_dm_object_name("Endpoint_Changes.Filesystem_Changes")` | rex field=file_name "(?<file_extension>\.[^\.]+)$" | `ransomware_extensions`

[ESCU - Common Ransomware Notes - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-21
action.escu.modification_date = 2017-09-10
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks at file modifications in the Change Analysis data model. The names of those modified files are then checked against an included lookup file, which contains the names of the 'note' files typically left behind for Ransomware. Any files identified with matching names are then returned. These note files are used to inform the victim how they can pay a ransom to retrieve their files.
action.escu.how_to_implement = In order to implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or other endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report file system reads and writes.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Common Ransomware Notes
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It's possible that a legitimate file could be created with the same name used by ransomware note files.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = The search looks for files created with a name that matches one of those typically used for the 'note' file left behind instructing the victim how to get their data back.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count values(All_Changes.Endpoint_Changes.Filesystem_Changes.file_path) as file_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis where All_Changes.object_category=file by All_Changes.Endpoint_Changes.Filesystem_Changes.file_name All_Changes.dest | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes.Endpoint_Changes.Filesystem_Changes")` | `drop_dm_object_name("All_Changes")` | `ransomware_notes`

[ESCU - Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-18
action.escu.modification_date = 2017-08-23
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for PowerShell processes that have a number of suspicious flags on the command-line. It is looking for flags are passing encoded commands on the command-line. The flags "-EncodedCommand" and "-enc" are two different possible flags that can be used to pass base64 encoded commands to PowerShell. The "*-Exec*" flag looks to see it the default execution policy of PowerShell is being overridden. The "*-NonI*" flag tells the PowerShell process that this will be a noninteractive process, so the user doesn't know about the process. This search will return the host, the user the process ran under, the process and it's command-line arguments, the number of times it's seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Multiple Suspicious Command-Line Arguments
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 7", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.kill_chain_phases = ["Command and Control", "Actions on Objectives"]
action.escu.known_false_positives = Legitimate process can have this combination of command-line options, but it's not common.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, object_path
alert.suppress.period = 14400s
cron_schedule = 50 * * * *
description = This search looks for PowerShell processes started with a base64 encoded command-line passed to it, with parameters to modify the execution policy for the process, and those that prevent the display of an interactive prompt to the user. This combination of command-line options is suspicious because it overrides the default PowerShell execution policy, attempts to hide itself from the user, and passes an encoded script to be run on the command-line.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*powershell* (cmdline="*-EncodedCommand*" OR cmdline="*-enc*") cmdline="*-Exec*" AND cmdline="*-NonI*"| stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Malicious PowerShell Process - Execution Policy Bypass - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for PowerShell processes that were launched using a parameter designed to bypass the local PowerShell execution policy. By default, the policy is set to "Restricted," which disables the execution of PowerShell scripts. In environments that make heavy use of PowerShell, the policy can be set to allow only scripts signed by a trusted publisher. Malicious PowerShell use almost always includes the parameter <code>-ExecutionPolicy bypass</code>. PowerShell is very liberal when it comes to interpreting command-line parameters passed to it. For example, the parameter we look for, <code>-ExecutionPolicy</code>, can be abbreviated to <code>-Execution</code>, <code>-Exec</code>, or even <code>-ex</code>. As such, we look for <code>* -ex*</code>, which should catch all variations of this parameter, followed by the keyword <code>bypass</code>. This search will return the host, the user the process ran under, the process and its command-line arguments, the number of times it has seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon Technology Add-on (TA).
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Execution Policy Bypass
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 7", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.kill_chain_phases = ["Command and Control", "Actions on Objectives"]
action.escu.known_false_positives = There may be legitimate reasons to bypass the PowerShell execution policy. The PowerShell script being run with this parameter should be validated to ensure that it is legitimate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, object_path
alert.suppress.period = 14400s
cron_schedule = 50 * * * *
description = This search looks for PowerShell processes started with parameters used to bypass the local execution policy for scripts. These paramters are often observed in attacks leveraging PowerShell scripts as they override the default PowerShell execution policy.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*powershell* cmdline="* -ex*"  cmdline="* bypass *" | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Get Emails From Specific Sender]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-11-09
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search you must ingest your email logs or capture unencrypted email communications within network traffic, and populate the Email data model.
action.escu.data_models = ["Email"]
action.escu.full_search_name = ESCU - Get Emails From Specific Sender
action.escu.search_type = investigative
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.analytic_story = ["Suspicious Emails", "Brand Monitoring"]
action.escu.fields_required = ["src_user"]
action.escu.earliest_time_offset = 86400
action.escu.latest_time_offset = 86400
description = This search returns all the emails from a specific sender over the last 24 and next hours.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | from datamodel Email.All_Email | search src_user={src_user}

[ESCU - Get Update Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-08-24
action.escu.channel = ESCU
action.escu.how_to_implement = You need to be ingesting the update logs from your various systems.
action.escu.data_models = ["Updates"]
action.escu.full_search_name = ESCU - Get Update Logs For Endpoint
action.escu.search_type = contextual
action.escu.providing_technologies = ["Microsoft Windows", "Linux", "macOS"]
action.escu.analytic_story = ["Ransomware"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 604800
action.escu.latest_time_offset = 0
description = This search will tell you give you the update logs for a specific endpoint for the last week.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | from datamodel Updates.Updates  | search (vendor_product="Microsoft Windows" OR vendor_product="OSX:Update" OR vendor_product="Linux:Update") dest={dest}

[ESCU - Overwriting Accessibility Binaries - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-12-07
action.escu.modification_date = 2017-12-07
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search returns all the different accessibility binaries that have been modified for each Windows host.
action.escu.how_to_implement = To successfully implement this search, you need to ingest logs that collect file modifications from your endpoints. If you are using Sysmon, you will need to have a Splunk Universal Forwarder on each endpoint that you want to collect the data on.  You will also need to have to deploy the Sysmon TA on these endpoints and on your search head.  You must have at least version 6.0.4 of the Sysmon TA.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Overwriting Accessibility Binaries
action.escu.mappings = {"mitre_attack": ["Persistence", "Accessibility Features"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Microsoft may provide updates to these binaries. Verify that these changes do not correspond with your normal software update cycle.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Windows Privilege Escalation"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = Microsoft Windows contains accessibility features that can be launched with a key combination before a user has logged in. An adversary can modify or replace these programs so they can get a command prompt or backdoor without logging in to the system. This search looks for modifications to these binaries.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count values(All_Changes.Endpoint_Changes.Filesystem_Changes.file_path) as file_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis where All_Changes.object_category=file AND (All_Changes.Endpoint_Changes.Filesystem_Changes.file_path=*\Windows\System32\sethc.exe* OR All_Changes.Endpoint_Changes.Filesystem_Changes.file_path=*\Windows\System32\utilman.exe* OR All_Changes.Endpoint_Changes.Filesystem_Changes.file_path=*\Windows\System32\osk.exe* OR All_Changes.Endpoint_Changes.Filesystem_Changes.file_path=*\Windows\System32\Magnify.exe* OR All_Changes.Endpoint_Changes.Filesystem_Changes.file_path=*\Windows\System32\Narrator.exe* OR All_Changes.Endpoint_Changes.Filesystem_Changes.file_path=*\Windows\System32\DisplaySwitch.exe* OR All_Changes.Endpoint_Changes.Filesystem_Changes.file_path=*\Windows\System32\AtBroker.exe*) by All_Changes.Endpoint_Changes.Filesystem_Changes.file_name All_Changes.dest | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes.Endpoint_Changes.Filesystem_Changes")` | `drop_dm_object_name("All_Changes")`

[ESCU - Detect Path Interception By Creation Of program.exe - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-11-16
action.escu.modification_date = 2017-11-17
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search queries the Change Analysis data model under the node All_Changes.Endpoint_Changes.Filesystem_Changes to list out all the values of hosts ("Affected Machines") and values of file hashes ("Hash Values") that have the file "program.exe" in the C: drive.
action.escu.how_to_implement = You need to be populating the Change Analysis data model with logs that reflect File System Changes on the Endpoint specifically file names and full path of the file. Path interception occurs when an executable is placed in a specific path so that it is executed by an application instead of the intended target. In this case, applications vulnerable to path interception because of unquoted service paths with spaces in windows registry allows attackers to execute maliciously crafted program.exe.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Detect Path Interception By Creation Of program.exe
action.escu.mappings = {"mitre_attack": ["Privilege Escalation", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It is unlikely that a normal user may create and place this file in C: drive.  Confirm with the user that this was not taken by them.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, file_path, file_name
alert.suppress.period = 86400s
cron_schedule = 30 * * * *
description = The search is looking for the creation of file C:\program.exe.  The creation of this file in the C:\ drive is driven by a motive to perform path interception. 
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count min(_time) as firstTime max(_time) as lastTime values(All_Changes.dest) as "Affected Machines" values(All_Changes.Endpoint_Changes.Filesystem_Changes.file_hash) as "Hash Values" from datamodel=Change_Analysis where nodename=All_Changes.Endpoint_Changes.Filesystem_Changes  All_Changes.Endpoint_Changes.Filesystem_Changes.file_path="C:\\program.exe" by  All_Changes.Endpoint_Changes.Filesystem_Changes.file_name All_Changes.Endpoint_Changes.Filesystem_Changes.file_path |`ctime(firstTime)` | `ctime(lastTime)`  

[ESCU - First time seen command line argument - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-16
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The subsearch returns all events where <code>cmd.exe</code> was used with a <code>/c</code> parameter in the command-line arguments to execute other commands/programs. It appends the historical data to those results in the lookup file. Next, it recalculates the <code>firstTime</code> and <code>lastTime</code> field for command-line execution and outputs this data to the lookup file to update the local cache. It returns only those events that have first been seen in the past four hours. This is combined with the main search to return the time, user, destination, process, parent process, and value of the command-line argument.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon Technology Add-on (TA). Please make sure you run the support search "Previously seen command line arguments,"&#151;which creates a lookup file called <code>previously_seen_cmd_line_arguments.csv</code>&#151;a historical baseline of all command-line arguments. You must also validate this list.
action.escu.full_search_name = ESCU - First time seen command line argument
action.escu.mappings = {"mitre_attack": ["Execution", "Scripting", "Persistence", "Command-Line Interface"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.kill_chain_phases = ["Command and Control", "Actions on Objectives"]
action.escu.known_false_positives = Legitimate programs can also use command-line arguments to execute. Please verify the command-line arguments to check what command/program is being executed.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Suspicious Command-Line Executions"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process, cmdline
alert.suppress.period = 86400s
cron_schedule = 30 * * * *
description = This search looks for command-line arguments that use a <code>/c</code> parameter to execute a command that has not previously been seen.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational process=cmd.exe cmdline="* /c *"  [ search sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational process=cmd.exe cmdline="* /c *" | stats earliest(_time) as firstTime latest(_time) as lastTime by cmdline | inputlookup append=t previously_seen_cmd_line_arguments  | stats min(firstTime) as firstTime, max(lastTime) as lastTime by cmdline | outputlookup previously_seen_cmd_line_arguments | eval newCmdLineArgument=if(firstTime >= relative_time(now(), "-65m@m"), 1, 0) | where newCmdLineArgument=1 | `ctime(firstTime)`  | `ctime(lastTime)` | table cmdline] | table _time, user,dest, process, parent_process, cmdline

[ESCU - Suspicious Email Attachment Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-20
action.escu.modification_date = 2017-09-19
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks at any email messages with attachments and checks the file names of those attachments against an included lookup file to see if it has a suspicious file extension.
action.escu.how_to_implement = You need to ingest data from emails. Specifically, the sender's address and the file names of any attachments must be mapped to the Email data model.
action.escu.data_models = ["Email"]
action.escu.full_search_name = ESCU - Suspicious Email Attachment Extensions
action.escu.mappings = {"mitre_attack": ["Execution", "Defense Evasion"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 3", "CIS 7", "CIS 12"], "nist": ["DE.AE", "PR.IP"]}
action.escu.kill_chain_phases = ["Delivery"]
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.analytic_story = ["Suspicious Emails"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user,message_id
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for emails that have attachments with suspicious file extensions.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Email where All_Email.file_name="*" by All_Email.src_user, All_Email.file_name All_Email.message_id | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Email")` | `suspicious_email_attachments`

[ESCU - Malicious PowerShell Process With Obfuscation Techniques - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-25
action.escu.modification_date = 2017-08-23
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for PowerShell processes that are passing command-line arguments with unusual characters (backticks and carets) that are PowerShell specific escape characters. Attackers use this obfuscation technique since it does not affect the functionality of PowerShell and it will bypass standard security controls that look for straight up malicious strings and commands. The search counts the occurrence of these obfuscation characters and lists out destination IPs running these PowerShell commands.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Malicious PowerShell Process With Obfuscation Techniques
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 7", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.kill_chain_phases = ["Command and Control", "Actions on Objectives"]
action.escu.known_false_positives = These characters might be legitimately on the command-line, but it is not common.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,cmdline
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for PowerShell processes launched with arguments that have characters indicative of obfuscation on the command-line.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*powershell* | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)` | eval num_obfuscation = (mvcount(split(cmdline, "`"))-1) + (mvcount(split(cmdline, "^"))-1) | search num_obfuscation > 0

[ESCU - Create a list of approved AWS service accounts]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = We first look for all successful CloudTrail API activity caused by types of user accounts and then remove all the events caused by users in the Identity table. This generates a list of accounts&#151;typically service accounts&#151;configured in your AWS environment. We output this list of service accounts to <code>aws_service_accounts.csv</code>.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the service account entires in <code>aws_service_accounts.csv</code>, which is a lookup file created as a result of running this support search. Please remove the entries of service accounts that are not legitimate.
action.escu.full_search_name = ESCU - Create a list of approved AWS service accounts
action.escu.mappings = {"cis20": ["CIS 16"], "nist": ["ID.AM"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
cron_schedule = 0 0 * */1 *
description = This search looks for successful API activity in CloudTrail within the last 30 days, filters out known users from the identity table, and outputs values of users into <code>aws_service_accounts.csv</code> lookup file.
dispatch.earliest_time = -30d@d
dispatch.latest_time = -5m@m
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail errorCode=success | rename userName as identity | search NOT [inputlookup identity_lookup_expanded | fields identity] | stats count by identity | table identity | outputlookup aws_service_accounts.csv

[ESCU - Get All AWS Activity From IP Address]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.channel = ESCU
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Get All AWS Activity From IP Address
action.escu.search_type = investigative
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS Traffic", "AWS Suspicious Provisioning Activities"]
action.escu.fields_required = ["src_ip"]
action.escu.earliest_time_offset = 14400
action.escu.latest_time_offset = 0
description = This search retrieves all the activity from a specific IP address and will create a table containing the time, ARN, username, the type of user, the IP address, the AWS region the activity was in, the API callled, and whether or not the API call was successful.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search sourceIPAddress={src_ip} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - All backup logs for host]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-19
action.escu.modification_date = 2017-09-12
action.escu.channel = ESCU
action.escu.how_to_implement = The successfully implement this search you must first send your backup logs to Splunk.
action.escu.full_search_name = ESCU - All backup logs for host
action.escu.search_type = investigative
action.escu.providing_technologies = ["Netbackup"]
action.escu.analytic_story = ["Monitor Backup Solution"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 1209600
action.escu.latest_time_offset = 0
description = Retrieve the backup logs for the last 2 weeks for a specific host in order to investigate why backups are not completing successfully.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype="netbackup_logs" dest={dest}

[ESCU - Get User Information from Identity Table]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-09-20
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search you must have populated the identity table with information about your users.
action.escu.full_search_name = ESCU - Get User Information from Identity Table
action.escu.search_type = contextual
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.analytic_story = ["Monitor for Updates", "Router & Infrastructure Security", "Windows Log Manipulation", "Windows Defense Evasion Tactics", "Host Redirection", "Windows Privilege Escalation", "Malicious PowerShell", "Lateral Movement", "JBoss Vulnerability", "Asset Tracking", "Monitor for Unauthorized Software", "Suspicious AWS Login Activities", "Collection and Staging", "Spectre And Meltdown Vulnerabilities", "DHS Report TA18-074A", "Windows File Extension and Association Abuse", "Suspicious DNS Traffic", "Suspicious Emails", "Windows Persistence Techniques", "Account Monitoring and Controls", "Suspicious AWS EC2 Activities", "Use of Cleartext Protocols", "Disabling Security Tools", "Splunk Enterprise Vulnerability", "SQL Injection", "AWS Network ACL Activity", "Data Protection", "Dynamic DNS", "Ransomware", "Brand Monitoring", "Apache Struts Vulnerability", "Suspicious Command-Line Executions", "Suspicious WMI Use", "Netsh Abuse", "Unusual Processes", "Windows Service Abuse"]
action.escu.fields_required = ["user"]
action.escu.earliest_time_offset = 864000
action.escu.latest_time_offset = 86400
description = Gather more information about the user identified in the Notable Event.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | `identities` | search identity={user} | table _time, identity, first, last, email, category, watchlist

[ESCU - Get Process responsible for the DNS traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-11-09
action.escu.channel = ESCU
action.escu.how_to_implement = You must be ingesting endpoint data that associates processes with network events. This can come from endpoint protection products such as carbon black, or endpoint data sources such as Sysmon.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Get Process responsible for the DNS traffic
action.escu.search_type = investigative
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Host Redirection", "Suspicious DNS Traffic", "Data Protection", "Dynamic DNS", "Brand Monitoring"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 86400
description = While investigating, an analyst will want to know what process and parent_ process is responsible for generating suspicious DNS traffic. Use the following search and enter the value of src_ip in the search to get specific details on the process responsible for creating the DNS traffic.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true values(All_Application_State.process) as "process" from datamodel=Application_State where nodename=All_Application_State.Ports All_Application_State.Ports.dest_port=53 All_Application_State.dest={dest}

[ESCU - Systems Ready for Spectre-Meltdown Windows Patch]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks to see if a registry key was created at <code>HKLM\Software\Microsoft\Windows\CurrentVersion\QualityCompat</code>. It will tell you when it was created and, if possible, what process created it.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Systems Ready for Spectre-Meltdown Windows Patch
action.escu.mappings = {"cis20": ["CIS 4"], "nist": ["ID.RA", "RS.MI", "PR.IP", "DE.CM"]}
action.escu.search_type = support
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Spectre And Meltdown Vulnerabilities"]
description = Some AV applications can cause the Spectre/Meltdown patch for Windows not to install successfully. This registry key is supposed to be created by the AV engine when it has been patched to be able to handle the Windows patch. If this key has been written, the system can then be patched for Spectre and Meltdown.
dispatch.earliest_time = -1d@d
dispatch.latest_time = now
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="HKLM\Software\Microsoft\Windows\CurrentVersion\QualityCompat*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes")`

[ESCU - Detect hosts connecting to dynamic domain providers - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-11-17
action.escu.modification_date = 2017-11-20
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The search is querying an accelerated Network_Resolution data model to count and list the values of resolved domains for each DNS query and checks that against the list of Dynamic DNS providers (lookup - dynamic_dns_providers) by each host (DNS.src)
action.escu.how_to_implement = First, you'll need to ingest data from your DNS operations. This can be done by ingesting logs from your server or data collected passively by Splunk Stream or similar solutions. Specifically, data that contains the domain that is being queried and the IP of the host originating the request must be populating the Network_Resolution data model. This search also leverages a lookup file, <code>dynamic_dns_providers.csv</code>, which contains a non-exhaustive list of Dynamic DNS providers. Please consider updating the lookup periodically by adding new domains to the list of <code>dynamic_dns_providers.csv</code>.
action.escu.data_models = ["Network_Resolution"]
action.escu.full_search_name = ESCU - Detect hosts connecting to dynamic domain providers
action.escu.mappings = {"mitre_attack": ["Exfiltration", "Exfiltration Over Command and Control Channel", "Defense Evasion", "Commonly Used Port"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 8", "CIS 12", "CIS 13"], "nist": ["PR.DS", "PR.PT", "DE.AE", "DE.CM"]}
action.escu.kill_chain_phases = ["Command and Control", "Actions on Objectives"]
action.escu.known_false_positives = Some users and applications may leverage Dynamic DNS to reach out to some domains on the Internet since dynamic DNS by itself is not malicious, however this activity must be verified.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Prohibited Traffic Allowed or Protocol Mismatch", "Suspicious DNS Traffic", "Data Protection", "Dynamic DNS"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src, query
alert.suppress.period = 86400s
cron_schedule = 10 * * * *
description = Malicious actors often abuse legitimate Dynamic DNS services to host malicious payloads or interactive command and control nodes. Attackers will automate domain resolution changes by routing dynamic domains to countless IP addresses to circumvent firewall blocks, blacklists as well as frustrate a network defenders analytic and investigative processes. This search will look for DNS queries made from within your infrastructure to suspicious dynamic domains. 
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count values(DNS.answer) as "Dynamic DNS Resolutions" min(_time) as firstTime from datamodel=Network_Resolution by DNS.src, DNS.query | `drop_dm_object_name("DNS")` | `ctime(firstTime)` | `dynamic_dns_providers`

[ESCU - Detect Excessive Account Lockouts From Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-17
action.escu.modification_date = 2017-09-23
action.escu.asset_at_risk = Windows
action.escu.channel = ESCU
action.escu.confidence = low
action.escu.eli5 = This search looks for the Windows event code 4740 within your Windows Security Logs, which indicates that an account has been locked out. It then counts the number of times an endpoint has caused an account lockout within a four hour window and displays those hosts with a count greater than or equal to five.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must ingest your Windows security event logs in order for this search to execute successfully.
action.escu.full_search_name = ESCU - Detect Excessive Account Lockouts From Endpoint
action.escu.mappings = {"mitre_attack": ["Valid Accounts"], "cis20": ["CIS 16"], "nist": ["PR.IP"]}
action.escu.known_false_positives = It's possible that a widely used system, such as a kiosk, could cause a large number of account lockouts.
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search identifies endpoints that have caused a relatively high number of account lockouts in a short period.
dispatch.earliest_time = -4h@h
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=WinEventLog:Security EventCode=4740 | stats count min(_time) as firstTime max(_time) as lastTime by dest, signature | `ctime(firstTime)` | `ctime(lastTime)` | search count > 5

[ESCU - Get Vulnerability Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-10
action.escu.channel = ESCU
action.escu.how_to_implement = You need to be ingesting the logs from your vulnerability scanner.
action.escu.data_models = ["Vulnerabilities"]
action.escu.full_search_name = ESCU - Get Vulnerability Logs For Endpoint
action.escu.search_type = contextual
action.escu.providing_technologies = ["Nessus"]
action.escu.analytic_story = ["Ransomware"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 604800
action.escu.latest_time_offset = 0
description = This search will show you any vulnerabilities noted for a specific endpoint for the last week.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | from datamodel Vulnerabilities.Vulnerabilities | search dest={dest}

[ESCU - Detect USB device insertion - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-03
action.escu.modification_date = 2017-11-27
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = low
action.escu.eli5 = USB is a common attack vector for delivering or propagating malicious code, or the exfiltration of data. Your corporation may have a policy of not allowing removable media at all, or may only allow approved media to be used on specific hosts by specific users. By logging USB activity from Windows and other endpoints gathered using the Universal Forwarder, you can gain an understanding of what systems might be vulnerable to attack via removable media, or what users might need additional security training. This search is looking for event_id 4656 for failure and 4663 for successful USB read/write attempts from Windows Security Event logs, which is the event code generated when a files are read from and written to a removable storage device
action.escu.how_to_implement = To successfully implement this search, you must ingest Windows Security Event logs and track event code 4663 and 4656. Ensure that the field from the event logs is being mapped to the result_id field in the Change_Analysis data model. To minimize the alert volume, this search leverages the Assets and Identity framework to filter out events from those assets not marked high priority in the Enterprise Security Assets and Identity Framework.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Detect USB device insertion
action.escu.mappings = {"mitre_attack": ["Exfiltration"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 13"], "nist": ["PR.PT", "PR.DS"]}
action.escu.kill_chain_phases = ["Installation", "Actions on Objectives"]
action.escu.known_false_positives = Legitimate USB activity will also be detected. Please verify and investigate as appropriate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Data Protection"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = The search is used to detect hosts that generate Windows Event ID 4663 for successful attempts to write to or read from a removable storage and Event ID 4656 for failures, which occurs when a USB drive is plugged in. In this scenario we are querying the Change_Analysis data model to look for Windows Event ID 4656 or 4663 where the priority of the affected host is marked as high in the ES Assets and Identity Framework.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats summariesonly=t allow_old_summaries=t count earliest(_time) AS earliest latest(_time) AS latest from datamodel=Change_Analysis where (nodename = All_Changes) All_Changes.result="Removable Storage device" (All_Changes.result_id=4663 OR All_Changes.result_id=4656) (All_Changes.src_priority=high) by All_Changes.dest | `drop_dm_object_name("All_Changes")`| `ctime(earliest)`| `ctime(latest)` 

[ESCU - Shim Database Installation With Suspicious Parameters - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-10-03
action.escu.modification_date = 2017-10-10
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for the execution of sdbinst.exe with command-line arguments of -q and -p.  The -q option performs a silent installation with no visible window, status, or warning information.  The -p option allows the shim database to contain patches.  It will return the count, the first time, and the last time these command-line arguments were seen on each endpoint and by each user.
action.escu.how_to_implement = To successfully implement this search, you need to ingest logs with both the process name and command-line from your endpoints. If you are using Sysmon, you will need to have a Splunk Universal Forwarder on each endpoint that you want to collect the data on.  You will also need to have to deploy the Sysmon TA on these endpoints and on your search head.  You must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Shim Database Installation With Suspicious Parameters
action.escu.mappings = {"mitre_attack": ["Persistence", "Application Shimming"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search detects the process execution and arguments required to silently create a shim database.  The sdbinst.exe application is used to install shim database files (.sdb). A shim is a small library which transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*sdbinst* cmdline="*-p*" cmdline="*-q*" | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Detect malicious requests to exploit JBoss servers - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-10-04
action.escu.modification_date = 2017-09-23
action.escu.asset_at_risk = Web Server
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks for HTTP requests for a URL that has been used to exploit JBoss servers.
action.escu.how_to_implement = You must ingest data from the web server or capture network data that contains web specific information with solutions such as Bro or Splunk Stream, and populating the Web data model
action.escu.data_models = ["Web"]
action.escu.full_search_name = ESCU - Detect malicious requests to exploit JBoss servers
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 12", "CIS 4", "CIS 18"], "nist": ["ID.RA", "PR.PT", "PR.IP", "DE.AE", "PR.MA", "DE.CM"]}
action.escu.kill_chain_phases = ["Delivery"]
action.escu.known_false_positives = No known false positives for this detection.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Palo Alto Firewall", "Apache", "Bro"]
action.escu.analytic_story = ["JBoss Vulnerability"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,url,src
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search is used to detect malicious HTTP requests crafted to exploit jmx-console in JBoss servers. The malicious requests have a long URL length, as the payload is embedded in the URL.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Web where (Web.http_method="GET" OR Web.http_method="HEAD") by Web.http_method, Web.url,Web.url_length Web.src, Web.dest | search Web.url="*jmx-console/HtmlAdaptor?action=invokeOpByName&name=jboss.admin*import*" AND Web.url_length > 200 | `drop_dm_object_name("Web")` | `ctime(firstTime)` | `ctime(lastTime)` | table src, dest_ip, http_method, url, firstTime, lastTime

[ESCU - Detect Excessive User Account Lockouts - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-17
action.escu.modification_date = 2017-09-23
action.escu.asset_at_risk = Windows
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for the Windows event code 4740 within your Windows Security Logs, which indicates that an account locked out. It then counts the numbers of times an account has been locked out in a four hour window and displays those accounts with a count greater than five.
action.escu.how_to_implement = While this search does not require you to adhere to Splunk CIM, you must be ingesting your Windows security event logs in order for this search to execute successfully.
action.escu.full_search_name = ESCU - Detect Excessive User Account Lockouts
action.escu.mappings = {"mitre_attack": ["Valid Accounts"], "cis20": ["CIS 16"], "nist": ["PR.IP"]}
action.escu.known_false_positives = It is possible that a legitimate user is experiencing an issue causing multiple account login failures leading to lockouts.
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search detects accounts that have been locked out a relatively high number of times in a short period.
dispatch.earliest_time = -4h@h
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=WinEventLog:Security EventCode=4740 | stats count min(_time) as firstTime max(_time) as lastTime by user, signature | `ctime(firstTime)` | `ctime(lastTime)` | search count > 5

[ESCU - Detect Spike in AWS API Activity - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-04-09
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search and its corresponding subsearch run through a series of steps, as per the following: <ol><li>Retrieves all of the AWS CloudTrail log entries that have recorded AWS API calls.</li><li>Kicks off a subsearch that retrieves the same data and pulls out the ARN into a more friendly format.</li><li>Counts the number of API calls per ARN.</li><li>Loads the cache file that contains the number of data points, the count from the latest hour, the API call average, and the standard deviation for each ARN.</li><li>Drops the count from the latest hour, since it is not necessary, and merges the rest of the data with the results of the stats command. </li><li>Renames <code>apiCalls</code> as <code>latestCount</code>.</li><li>Calculates the new average value for each ARN with the latest count, weighting the past much more heavily than the current hour. It does the same for the standard deviation&#151;weighting the past more heavily than the current.</li><li>Updates the cache file with the latest results.</li><li>Sets the minimum threshold for the number of data points and sets the number of standard deviations away from the mean it must be to be considered a spike.</li><li>Makes a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.</li><li>Filters out anything that it determines is not a spike and returns the list of ARNs to the main search. </li></ol>The main search subsequently gets the names of all the API calls, the number of unique API calls, and the total number of API calls for each of these ARNs. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify <code>dataPointThreshold</code> and <code>deviationThreshold</code> to better fit your environment. The <code>dataPointThreshold</code> variable is the minimum number of data points required to have a statistically significant amount of data to determine. The <code>deviationThreshold</code> variable is the number of standard deviations away from the mean that the value must be to be considered a spike.
action.escu.full_search_name = ESCU - Detect Spike in AWS API Activity
action.escu.mappings = {"mitre_attack": ["Credential Access", "Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 16"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = 
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search will detect users creating spikes of API activity in your AWS environment.  It will also update the cache file that factors in the latest data.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventType=AwsApiCall [search sourcetype=aws:cloudtrail eventType=AwsApiCall | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup api_call_by_user_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup api_call_by_user_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user

[ESCU - RunDLL Loading DLL By Ordinal - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-08-09
action.escu.modification_date = 2017-09-11
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for rundll32.exe being run, loading a DLL out of a directory or subdirectory of AppData, and specifying the function at ordinal 2 be run.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - RunDLL Loading DLL By Ordinal
action.escu.mappings = {"mitre_attack": ["Execution", "Rundll32"], "kill_chain_phases": ["Installation"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Installation"]
action.escu.known_false_positives = While not common, loading a DLL under %AppData% and calling a function by ordinal is possible by a legitimate process
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Unusual Processes"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for DLLs under %AppData% being loaded by rundll32.exe that are calling the exported function at ordinal 2. Calling exported functions by ordinal is not as common as calling by exported name. There was a bug fixed in IDAPro on 2016-08-08 that would not display functions without names.  Calling functions by ordinal would overcome the lack of name and make it harder for analyst to reverse engineer.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*rundll32.exe* cmdline="*AppData*" cmdline="*,#2" | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Get Notable Info]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-03-15
action.escu.modification_date = 2017-09-20
action.escu.channel = ESCU
action.escu.how_to_implement = If you are using Enterprise Security you are likely already creating notable events with your correlation rules. No additional configuration is necessary.
action.escu.full_search_name = ESCU - Get Notable Info
action.escu.search_type = contextual
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.analytic_story = ["Monitor for Updates", "Router & Infrastructure Security", "Windows Log Manipulation", "Windows Defense Evasion Tactics", "Host Redirection", "Windows Privilege Escalation", "Malicious PowerShell", "Lateral Movement", "JBoss Vulnerability", "Asset Tracking", "Suspicious AWS Login Activities", "DNS Amplification Attacks", "Collection and Staging", "Spectre And Meltdown Vulnerabilities", "DHS Report TA18-074A", "Windows File Extension and Association Abuse", "Suspicious DNS Traffic", "Windows Persistence Techniques", "Account Monitoring and Controls", "Suspicious AWS EC2 Activities", "Use of Cleartext Protocols", "Disabling Security Tools", "Splunk Enterprise Vulnerability", "SQL Injection", "AWS Network ACL Activity", "Data Protection", "Dynamic DNS", "Suspicious AWS Traffic", "Brand Monitoring", "Apache Struts Vulnerability", "Suspicious Command-Line Executions", "Suspicious WMI Use", "AWS User Monitoring", "Windows Service Abuse"]
action.escu.fields_required = ["event_id"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 3600
description = This search queries the notable index to retrieve detailed information captured within the notable. Every notable has a unique ID associated with it, which is used to point us directly to the notable event under investigation.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search `notable_by_id({event_id})` | table time, rule_name, dest, dest_asset_id, dest_owner, priority, severity, owner, status_description

[ESCU - Large Volume of DNS ANY Queries - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-08-24
action.escu.modification_date = 2017-09-20
action.escu.asset_at_risk = DNS Servers
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search counts the number of DNS ANY queries received in 5 minutes, and generates a Notable Event if the count exceeds a predefined threshold. The search returns the count, the first time, and the last time a DNS packet was observed with the ANY flag set.
action.escu.how_to_implement = To successfully implement this search you must ensure that DNS data is populating the Network_Resolution data model.
action.escu.data_models = ["Network_Resolution"]
action.escu.full_search_name = ESCU - Large Volume of DNS ANY Queries
action.escu.mappings = {"kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 11", "CIS 12"], "nist": ["PR.PT", "DE.AE", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Legitimate ANY requests may trigger this search, however it is unusual to see a large volume of them under typical circumstances. You may modify the threshold in the search to better suit your environment.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["DNS Amplification Attacks"]
action.notable = 1
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 7200s
cron_schedule = */5 * * * *
description = The search is used to identify attempts to use your DNS Infrastructure for DDoS purposes via a DNS amplification attack leveraging ANY queries.
dispatch.earliest_time = -10m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count from datamodel=Network_Resolution where nodename=DNS "DNS.message_type"="QUERY" "DNS.record_type"="ANY" by "DNS.dest" | `drop_dm_object_name("DNS")` | where count>200

[ESCU - Windows hosts file modification - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-07
action.escu.modification_date = 2017-09-14
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = The hosts file is a file present on both Windows and Linux endpoints. The purpose of the hosts file is to provide a mapping between hostnames and IP addresses, the same way DNS is used to provide such a mapping. However, the information in the hosts file takes precedence over information received via DNS, and a DNS query will not be issued if the hostname of interest is found in the hosts file. As such, attackers have been observed adding entries to the host file to override any DNS resolution. For this reason, it is useful to monitor for changes to this file, which typically do not occur very often in legitimate cases.
action.escu.how_to_implement = In order to implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or other endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the file system.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Windows hosts file modification
action.escu.mappings = {"mitre_attack": ["Command and Control", "Exfiltration"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 3", "CIS 8", "CIS 12"], "nist": ["PR.IP", "PR.PT", "PR.AC", "DE.AE", "DE.CM"]}
action.escu.kill_chain_phases = ["Command and Control"]
action.escu.known_false_positives = There may be legitimate reasons for System Administrators to add entries to this file
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Host Redirection"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = The search looks for modifications to the hosts file on all Windows endpoints across your environment.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis where nodename=All_Changes.Endpoint_Changes.Filesystem_Changes by All_Changes.Endpoint_Changes.Filesystem_Changes.file_name All_Changes.Endpoint_Changes.Filesystem_Changes.file_path All_Changes.dest | `ctime(lastTime)` | `ctime(firstTime)` | search All_Changes.Endpoint_Changes.Filesystem_Changes.file_name=hosts AND All_Changes.Endpoint_Changes.Filesystem_Changes.file_path=*Windows\System32 | `drop_dm_object_name("All_Changes")` | `drop_dm_object_name("Endpoint_Changes.Filesystem_Changes")`

[ESCU - Get Logon Rights Modifications For User]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-16
action.escu.modification_date = 2017-09-12
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search you must be ingesting your Windows event logs
action.escu.full_search_name = ESCU - Get Logon Rights Modifications For User
action.escu.search_type = investigative
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.escu.fields_required = ["user"]
action.escu.earliest_time_offset = 86400
action.escu.latest_time_offset = 86400
description = This search allows you to retrieve any modifications to logon rights for a specific user account.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=WinEventLog:Security (EventCode=4718 OR EventCode=4717) user={user} | rename user as "Account Modified" | table _time, dest, "Account Modified", Access_Right, signature

[ESCU - Abnormally High AWS Instances Terminated by User - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-02-26
action.escu.modification_date = 2018-02-26
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = In this search, we query CloudTrail logs to look for events where an instance is successfully terminated by a particular user. Since we want to detect a high number of instances terminated within a short period of time, we create event buckets for 10-minute windows. We then calculate the total number of instances terminated by a particular user, as well as the average- and standard-deviation values. Assign a <code>threshold_value</code> in the search. Try starting with 3 (but it will likely need to be tweaked for your environment). The <code>eval</code> function will set the outlier to 1 if the number of instances is greater than the average number of instances terminated, added to the multiplied value of threshold and standard deviation. We then filter out outliers with a value of 1 and show only those instance-termination events that happened within the previous 10 minutes.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Abnormally High AWS Instances Terminated by User
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 13"], "nist": ["DE.DP", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Many service accounts configured with your AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify whether this search alerted on a human user.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS EC2 Activities"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = userName
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = userName
alert.suppress.period = 3600s
cron_schedule = */10 * * * *
description = This search looks for CloudTrail events where an abnormally high number of instances were successfully terminated by a user in a 10-minute window
dispatch.earliest_time = -30d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=TerminateInstances errorCode=success | bucket span=10m _time | stats count AS instances_terminated by _time userName | eventstats avg(instances_terminated) as total_terminations_avg, stdev(instances_terminated) as total_terminations_stdev | eval threshold_value = 4 | eval isOutlier=if(instances_terminated > total_terminations_avg+(total_terminations_stdev * threshold_value), 1, 0) | search isOutlier=1 AND _time >= relative_time(now(), "-10m@m")| eval num_standard_deviations_away = round(abs(instances_terminated - total_terminations_avg) / total_terminations_stdev, 2) |table _time, userName, instances_terminated, num_standard_deviations_away, total_terminations_avg, total_terminations_stdev

[ESCU - Scheduled Task Name Used by Dragonfly Threat Actors - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate that a specific task&#151;"reset," whose name is associated with the Dragonfly threat actor&#151;has been created or deleted. Schtasks.exe is a native Windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or establish persistence.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon Technology Add-on (TA).
action.escu.full_search_name = ESCU - Scheduled Task Name Used by Dragonfly Threat Actors
action.escu.mappings = {"mitre_attack": ["Execution", "Scheduled Task"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = No known false positives
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, cmdline
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for flags passed to schtasks.exe on the command-line that indicate a task name associated with the Dragonfly threat actor was created or deleted.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*schtasks.exe (create OR delete) | search cmdline=*reset* | stats count values(cmdline) min(_time) as firstTime max(_time) as lastTime by dest process | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Get Risk Modifiers For User]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-10-14
action.escu.modification_date = 2017-10-19
action.escu.channel = ESCU
action.escu.how_to_implement = Enable the correlation searches included in Splunk Enterprise Security that include Risk Analysis alert actions by leveraging the Risk Analysis Framework
action.escu.data_models = ["Risk"]
action.escu.full_search_name = ESCU - Get Risk Modifiers For User
action.escu.search_type = contextual
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.analytic_story = ["Monitor for Updates", "Router & Infrastructure Security", "Windows Log Manipulation", "Monitor Backup Solution", "Host Redirection", "Windows Privilege Escalation", "Malicious PowerShell", "Lateral Movement", "JBoss Vulnerability", "Asset Tracking", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "DNS Amplification Attacks", "Collection and Staging", "Spectre And Meltdown Vulnerabilities", "DHS Report TA18-074A", "Windows File Extension and Association Abuse", "Suspicious DNS Traffic", "Suspicious Emails", "Windows Persistence Techniques", "Account Monitoring and Controls", "Use of Cleartext Protocols", "Disabling Security Tools", "Splunk Enterprise Vulnerability", "SQL Injection", "Data Protection", "Dynamic DNS", "Ransomware", "Brand Monitoring", "Apache Struts Vulnerability", "Suspicious WMI Use", "Netsh Abuse", "Unusual Processes", "Windows Service Abuse"]
action.escu.fields_required = ["user"]
action.escu.earliest_time_offset = 604800
action.escu.latest_time_offset = 0
description = For the last 7 days, the search will query the Risk data model in Splunk Enterprise Security and calculate the count, sum of the risk_scores, names of the correlation searches that contributed to create a risk score for a specific user 
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | from datamodel:Risk.All_Risk | search risk_object_type=user risk_object={user} | stats count sum(risk_score) as risk_score values(search_name)  min(_time) as firstTime max(_time) as lastTime by risk_object |`ctime(firstTime)` |`ctime(lastTime)` 

[ESCU - Get Process Info]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-03-15
action.escu.modification_date = 2017-11-09
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data and populating the Application_State data model.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Get Process Info
action.escu.search_type = investigative
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Log Manipulation", "Windows Defense Evasion Tactics", "Windows Privilege Escalation", "Malicious PowerShell", "Lateral Movement", "Monitor for Unauthorized Software", "Collection and Staging", "DHS Report TA18-074A", "Windows File Extension and Association Abuse", "Windows Persistence Techniques", "Disabling Security Tools", "Ransomware", "Suspicious Command-Line Executions", "Suspicious WMI Use", "Netsh Abuse", "Unusual Processes", "Windows Service Abuse"]
action.escu.fields_required = ["process", "dest"]
action.escu.earliest_time_offset = 7200
action.escu.latest_time_offset = 7200
description = This search queries the Application State data model to give you details about the process running on a host which is under investigation. To gather the process info, enter the values for the process name in question and the destination IP address.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | from datamodel Application_State.Processes | search process=*{process}* dest={dest}

[ESCU - Spike in File Writes - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-20
action.escu.modification_date = 2017-09-10
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = low
action.escu.eli5 = This search calculates counts the number of file modification events per hour per host in your environment. It then takes the average and standard deviations of those numbers and displays any hosts with more than 20 events that have over four times the standard deviation more than the average number of file modifications.
action.escu.how_to_implement = In order to implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the file system.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Spike in File Writes
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It is important to understand that if you happen to install any new applications on your hosts or are copying a large number of files, you can expect to see a large increase of file modifications.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 7200s
cron_schedule = 0 * * * *
description = The search looks for a sharp increase in the number of files written to a particular host
dispatch.earliest_time = -7d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count FROM datamodel=Change_Analysis where All_Changes.object_category=file by _time span=1h, All_Changes.dest | `drop_dm_object_name("All_Changes")` | eventstats max(_time) as maxtime | stats count as num_data_samples max(eval(if(_time >= relative_time(maxtime, "-1d@d"), count, null))) as "count" avg(eval(if(_time<relative_time(maxtime, "-1d@d"), count,null))) as avg stdev(eval(if(_time<relative_time(maxtime, "-1d@d"), count, null))) as stdev by "dest" | eval upperBound=(avg+stdev*4), isOutlier=if((count > upperBound) AND num_data_samples >=20, 1, 0) | search isOutlier=1

[ESCU - Detect new API calls from user roles - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-01
action.escu.modification_date = 2018-04-16
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The subsearch will execute first and return the user roles and names of the API calls completed within the last hour, where the type of user identity is <code>AssumedRole</code>. It then appends the historical data to those results in the lookup file. Next, it recalculates the <code>earliest</code> and <code>latest</code> fields for each user role, as well as the name of the API call, and returns only those roles and API calls that have first been seen in the past hour. This is combined with the main search to return the values of API calls, name of the user role, and the earliest and latest time of this activity. It is worth noting that the name of the role of a particular user is parsed as "userName" in the CloudTrail logs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously seen API call per user roles in CloudTrail" support search once to create a history of previously seen user roles.
action.escu.full_search_name = ESCU - Detect new API calls from user roles
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.known_false_positives = It is possible that there are legitimate user roles making new or infrequently used API calls in your infrastructure, causing the search to trigger.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
cron_schedule = 30 * * * *
description = This search detects new API calls that have either never been seen before or that have not been seen in the previous hour, where the identity type is <code>AssumedRole</code>.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventType=AwsApiCall errorCode=success userIdentity.type=AssumedRole [search sourcetype=aws:cloudtrail eventType=AwsApiCall errorCode=success  userIdentity.type=AssumedRole | stats earliest(_time) as earliest latest(_time) as latest by userName eventName |  inputlookup append=t previously_seen_api_calls_from_user_roles | stats min(earliest) as earliest, max(latest) as latest by userName eventName | outputlookup previously_seen_api_calls_from_user_roles| eval newApiCallfromUserRole=if(earliest>=relative_time(now(), "-65m@m"), 1, 0) | where newApiCallfromUserRole=1 | `ctime(earliest)` | `ctime(latest)` | table eventName userName]  |rename userName as user| stats values(eventName) earliest(_time) as earliest latest(_time) as latest by user | `ctime(earliest)` | `ctime(latest)`

[ESCU - Hiding Files And Directories With Attrib.exe - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-10-23
action.escu.modification_date = 2017-10-23
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search is looking to detect command-line execution with of attrib.exe binary with the +h flag set.  The +h flag is used to hide a file.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Hiding Files And Directories With Attrib.exe
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Some applications and users may legitimately use attrib.exe to interact with the files. 
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "Windows Persistence Techniques"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, cmdline
alert.suppress.period = 86400s
cron_schedule = 30 * * * *
description = Attackers leverage an existing Windows binary, attrib.exe, to mark specific as hidden by using specific flags so that the victim does not see the file.  The search looks for specific command-line arguments to detect the use of attrib.exe to hide files.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational process="*attrib.exe" cmdline="*+h*"| stats count values(cmdline) as "Commands Executed" min(_time) as firstTime max(_time) as lastTime by dest process |  `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - SQL Injection with Long URLs - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-19
action.escu.asset_at_risk = Database Server
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks only at your web servers and returns the source, the web server, the URL and its length, and the user agent associated with HTTP GET requests for extremely long URLs or user agent lengths with more than three common SQL commands found within the URL.
action.escu.how_to_implement = To successfully implement this search, you need to be monitoring network communications to your web servers or ingesting your HTTP logs and populating the Web data model. You must also identify your web servers in the Enterprise Security assets table.
action.escu.data_models = ["Web"]
action.escu.full_search_name = ESCU - SQL Injection with Long URLs
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability", "Execution", "Commonly Used Port"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 4", "CIS 13", "CIS 18"], "nist": ["PR.DS", "ID.RA", "PR.PT", "PR.IP", "DE.CM"]}
action.escu.kill_chain_phases = ["Delivery"]
action.escu.known_false_positives = It's possible that legitimate traffic will have long URLs or long user agent strings and that common SQL commands may be found within the URL. Please investigate as appropriate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["SQL Injection"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src,url
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for long URLs that have several SQL commands visible within them.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count from datamodel=Web where Web.dest_category=web_server AND (Web.url_length > 1024 OR Web.http_user_agent_length > 200) by Web.src Web.dest Web.url Web.url_length Web.http_user_agent | `drop_dm_object_name("Web")` | eval num_sql_cmds=mvcount(split(url, "alter%20table")) + mvcount(split(url, "between")) + mvcount(split(url, "create%20table")) + mvcount(split(url, "create%20database")) + mvcount(split(url, "create%20index")) + mvcount(split(url, "create%20view")) + mvcount(split(url, "delete")) + mvcount(split(url, "drop%20database")) + mvcount(split(url, "drop%20index")) + mvcount(split(url, "drop%20table")) + mvcount(split(url, "exists")) + mvcount(split(url, "exec")) + mvcount(split(url, "group%20by")) + mvcount(split(url, "having")) + mvcount(split(url, "insert%20into")) + mvcount(split(url, "inner%20join")) + mvcount(split(url, "left%20join")) + mvcount(split(url, "right%20join")) + mvcount(split(url, "full%20join")) + mvcount(split(url, "select")) + mvcount(split(url, "distinct")) + mvcount(split(url, "select%20top")) + mvcount(split(url, "union")) + mvcount(split(url, "xp_cmdshell")) - 24 | where num_sql_cmds > 3

[ESCU - AWS Cloud Provisioning From Previously Unseen IP Address - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a <code>GeoIP</code> lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the <code>firstTime</code> and <code>lastTime</code> field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the <code>firstTime</code> and <code>lastTime</code> for each city. It returns only those events from IP addresses that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen IP Address
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.<br/><br/> This search will fire any time a new IP address is seen in the <b>GeoIP</b> database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of <b>MaxMind GeoIP</b> that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for AWS provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress | eval newIP=if(firstTime >= relative_time(now(), "-1h@h"), 1, 0) | where newIP=1 | table sourceIPAddress] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, eventName, errorCode

[ESCU - Execution of File With Spaces Before Extension - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-26
action.escu.modification_date = 2018-01-26
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search uses the Application State data model to look for process names that have at least five spaces between the file name and the extension. The search simply looks for five spaces, followed by a period in the process name.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Execution of File With Spaces Before Extension
action.escu.mappings = {"mitre_attack": ["Execution", "Persistence", "Change Default File Association"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 8"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = None identified.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows File Extension and Association Abuse"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,process,object_path
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for processes launched from files that have at least five spaces in the name before the extension. This is typically done to obfuscate the file extension by pushing it outside of the default view.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Application_State where All_Application_State.process = "*     .*" by All_Application_State.dest All_Application_State.user All_Application_State.process | `ctime(firstTime)`| `ctime(lastTime)` | `drop_dm_object_name("All_Application_State")`

[ESCU - Registry Keys Used For Privilege Escalation - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-12-07
action.escu.modification_date = 2017-10-10
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for specific registry paths that malware often uses to elevate privileges. The search returns the count, the first time activity was seen, last time activity was seen, the registry path that was modified, the host where the modification took place and the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Registry Keys Used For Privilege Escalation
action.escu.mappings = {"mitre_attack": ["Privilege Escalation", "Persistence", "Accessibility Features"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = There are many legitimate applications that need to start on system startup and will use these registry keys to accomplish that task.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Windows Privilege Escalation"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user, object_path
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for modifications to registry keys that can be used to elevate privileges. The registry keys under Image File Execution Options are used to intercept calls to an executable, and can be used to attach malicious binaries to benign system binaries.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="*Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes")`

[ESCU - EC2 Instance Modified With Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-09
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The subsearch returns the ARNs of all successful EC2 instance modifications within the last hour and then appends the historical data in the lookup file to those results. The list of APIs that modify a EC2 instance is defined by the macro <code>ec2ModificationAPIs</code>. The search then recalculates the <code>firstTime</code> and <code>lastTime</code> field for each ARN and returns only those ARNs that have first been seen in the past hour.  This is combined with the main search to return the time, user, and instance ID of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Launches By User" support search once to create a history of previously seen ARNs. To add or remove APIs that modify an EC2 instance, edit the macro <code>ec2ModificationAPIs</code>.
action.escu.full_search_name = ESCU - EC2 Instance Modified With Previously Unseen User
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.known_false_positives = It's possible that a new user will start to modify EC2 instances when they haven't before for any number of reasons. Verify with the user that is modifying instances that this is the intended behavior.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Unusual AWS EC2 Modifications"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for EC2 instances being modified by users who have not previously modified them.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail `ec2ModificationAPIs` [search sourcetype=aws:cloudtrail `ec2ModificationAPIs` errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by userIdentity.arn | rename userIdentity.arn as arn | inputlookup append=t previously_seen_ec2_modifications_by_user | stats min(firstTime) as firstTime, max(lastTime) as lastTime by arn | outputlookup [previously_seen_ec2_modifications_by_user | eval newUser=if(firstTime >= relative_time(now(), "-1h@h"), 1, 0) | where newUser=1 | `ctime(firstTime)` | `ctime(lastTime)` | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=dest responseElements.instancesSet.items{}.instanceId | spath output=user userIdentity.arn | table _time, user, dest

[ESCU - Short Lived Windows Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-05
action.escu.modification_date = 2018-01-05
action.escu.asset_at_risk = Windows
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for Windows Event Logs 4720 (account creation) and 4726 (account deletion) and determines if they happen for the same user within 4 hours of each other.  It will report the user and machine that reported the events and the time it first and last saw this activity.
action.escu.how_to_implement = This search requires you to have enabled your Group Management Audit Logs in your Local Windows Security Policy and be ingesting those logs.  More information on how to enable them can be found <a href="http://whatevernetworks.com/auditing-group-membership-changes-in-active-directory/">here</a>.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Short Lived Windows Accounts
action.escu.mappings = {"mitre_attack": ["Valid Accounts"], "cis20": ["CIS 16"], "nist": ["PR.IP"]}
action.escu.known_false_positives = It is possible that an administrator created and deleted an account in a short time period.  Verifying activity with an administrator is advised.
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 86400s
cron_schedule = 0 0,4,8,12,16,20 * * *
description = This search detects accounts that were created and deleted in a short time period.
dispatch.earliest_time = -245m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats summariesonly=t allow_old_summaries=t count min(_time) as firstTime max(_time) as lastTime from datamodel=Change_Analysis where All_Changes.result_id=4720 OR All_Changes.result_id=4726 by All_Changes.result_id All_Changes.user All_Changes.dest | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes")` | transaction user maxspan=240m  | search result_id=4720 result_id=4726

[ESCU - No Windows Updates in Timeframe - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-15
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Keeping your systems up-to-date with the latest patches is an important step in keeping your systems secured. For Windows endpoints, Microsoft typically releases patches on the second Tuesday of every month. These patches contain fixes for vulnerabilities in the system that could potentially be exploited by malicious actors. This search checks for messages regarding Windows updates in the 'Update' data model. If a message indicating a successful update has not been observed in 60 days, a notable event will be generated. These systems should be checked to determine why it has not been updated in that time frame.
action.escu.how_to_implement = To successfully implement this search, it requires that the 'Update' data model is being populated. This can be accomplished by ingesting Windows events or the Windows Update log via a universal forwarder on the Windows endpoints you wish to monitor. The Windows add-on should be also be installed and configured to properly parse Windows events in Splunk. There may be other data sources which can populate this data model, including vulnerability management systems.
action.escu.data_models = ["Updates"]
action.escu.full_search_name = ESCU - No Windows Updates in Timeframe
action.escu.mappings = {"cis20": ["CIS 18"], "nist": ["PR.PT", "PR.MA"]}
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Monitor for Updates"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for Windows endpoints that have not generated an event indicating a successful Windows update in the last 60 days. Windows updates are typically released monthly and applied shortly thereafter. An endpoint that has not successfully applied an update in this time frame indicates the endpoint is not regularly being patched for some reason.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats summariesonly=true allow_old_summaries=true latest(_time) as latestTime from datamodel=Updates where Updates.status=Installed Updates.vendor_product="Microsoft Windows" by Updates.dest Updates.status Updates.vendor_product | rename Updates.dest as Host | rename Updates.status as "Update Status" | rename Updates.vendor_product as Product | eval isOutlier=if(latestTime <= relative_time(now(), "-60d@d"), 1, 0)  | `ctime(latestTime)`  | search isOutlier=1 | rename latestTime as "Last Update Time", | table Host, "Update Status", Product, "Last Update Time"

[ESCU - AWS Cloud Provisioning From Previously Unseen Region - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a <code>GeoIP</code> lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the <code>firstTime</code> and <code>lastTime</code> field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the <code>firstTime</code> and <code>lastTime</code> for each city. It returns only those events from regions that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen Region
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.<br/><br/> This search will fire any time a new region is seen in the <b>GeoIP</b> database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your region, there should be few false positives. If you are located in regions where the free version of <b>MaxMind GeoIP</b> that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for AWS provisioning activities from previously unseen regions. Region in this context is similar to a state in the United States. Provisioning activities are defined broadly as any event that begins with "Run" or "Create."
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Region=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Region=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by Region | eval newRegion=if(firstTime >= relative_time(now(), "-1h@h"), 1, 0) | where newRegion=1 | table Region] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, Region, eventName, errorCode

[ESCU - Detect New Login Attempts to Routers - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-07-18
action.escu.modification_date = 2017-09-12
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Attackers will often attempt to compromise network devices such as routers for a variety of nefarious purposes, including modifying VPN settings or re-routing network traffic. Typically, only a relatively small number of user accounts log into these devices on a regular basis. This search identifies 'new' connections to your routers by checking to see if a similar login was made in the last 30 days. Routers are identified by checking the IP address against those categorized as a "router" in the ES assets and identity framework.
action.escu.how_to_implement = To successfully implement this search, you must ensure the network router devices are categorized as "router" in the Assets and identity table. You must also populate the Authentication data model with logs related to users authenticating to routing infrastructure.
action.escu.data_models = ["Authentication"]
action.escu.full_search_name = ESCU - Detect New Login Attempts to Routers
action.escu.mappings = {"kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 11"], "nist": ["PR.PT", "PR.AC", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Legitimate router connections may appear as new connections
action.escu.search_type = detection
action.escu.providing_technologies = ["Active Directory", "Palo Alto Firewall"]
action.escu.analytic_story = ["Router & Infrastructure Security"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
cron_schedule = 0 0 * * *
description = The search queries the authentication logs for assets that are categorized as routers in the ES Assets and Identity Framework, to identify connections that have not been seen before in the last 30 days.
dispatch.earliest_time = -30d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats summariesonly=t count earliest(_time) as earliest latest(_time) as latest from datamodel=Authentication where Authentication.dest_category=router by Authentication.dest Authentication.user| eval isOutlier=if(earliest >= relative_time(now(), "-30d@d"), 1, 0) | where isOutlier=1| `ctime(earliest)`| `ctime(latest)` | `drop_dm_object_name("Authentication")`

[ESCU - Detect new user AWS Console Login - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-02-26
action.escu.modification_date = 2018-02-26
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = In this search, we query CloudTrail logs to look for events that indicate that a user has attempted to log in to the AWS console and group the events using ARN value. Using the <code>previously_seen_users_console_logins.csv</code> lookup file created using the support search, we compare the ARN to all of the previously seen users logging into the AWS console. The <code>eval</code> and <code>if</code> functions determine whether the earliest time we see this user ARN was seen within the last hour. The alert will be fired only when a user is seen for first time in the last hour.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Run the "Previously seen users in CloudTrail" support search only once to create a baseline of previously seen IAM users within the last 30 days
action.escu.full_search_name = ESCU - Detect new user AWS Console Login
action.escu.mappings = {"mitre_attack": ["Credential Access"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 16"], "nist": ["DE.DP", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = arn
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = arn
alert.suppress.period = 86400s
cron_schedule = 5 * * * *
description = This search looks for CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=ConsoleLogin | rename userIdentity.arn as arn  |stats earliest(_time) as earliest latest(_time) as latest by arn | inputlookup append=t previously_seen_users_console_logins.csv  | stats min(earliest) as earliest max(latest) as latest by arn | outputlookup previously_seen_users_console_logins.csv | eval userStatus=if(earliest >= relative_time(now(), "-1h@h"), "First Time Logging into AWS Console","Previously Seen User") | convert ctime(earliest) ctime(latest) | where userStatus ="First Time Logging into AWS Console" 

[ESCU - EC2 Instance Started With Previously Unseen User - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-15
action.escu.modification_date = 2018-03-12
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The subsearch returns the ARNs of all successful EC2 instance launches within the last hour and then appends the historical data in the lookup file to those results.  It then recalculates the <code>firstTime</code> and <code>lastTime</code> field for each ARN and returns only those ARNs that have first been seen in the past hour.  This is combined with the main search to return the time, user, and instance id of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Launches By User" support search once to create a history of previously seen ARNs.
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen User
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.known_false_positives = It's possible that a user will start to create EC2 instances when they haven't before for any number of reasons. Verify with the user that is launching instances that this is the intended behavior.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS EC2 Activities", "AWS Cryptomining"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user, dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for EC2 instances being created by users who have not created them before.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=RunInstances [search sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | stats earliest(_time) as firstTime latest(_time) as lastTime by userIdentity.arn | rename userIdentity.arn as arn | inputlookup append=t previously_seen_ec2_launches_by_user.csv | stats min(firstTime) as firstTime, max(lastTime) as lastTime by arn | outputlookup previously_seen_ec2_launches_by_user.csv | eval newUser=if(firstTime >= relative_time(now(), "-1h@h"), 1, 0) | where newUser=1 | `ctime(firstTime)` | `ctime(lastTime)` | rename arn as userIdentity.arn | table userIdentity.arn] | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest, userIdentity.arn as user | table _time, user, dest, instanceType

[ESCU - Identify Systems Using Remote Desktop]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-18
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system. It does this by looking for the process in the Application_State data model.
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data that records process activity.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Identify Systems Using Remote Desktop
action.escu.mappings = {"mitre_attack": ["Lateral Movement", "Remote Desktop Protocol"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 9", "CIS 16"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.search_type = support
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Lateral Movement"]
description = This search counts the numbers of times the remote desktop process, mstsc.exe, has run on each system.
dispatch.earliest_time = now
dispatch.latest_time = -30d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count from datamodel=Application_State where All_Application_State.process="*mstsc.exe*" by All_Application_State.dest All_Application_State.process | `drop_dm_object_name("All_Application_State")` | sort - count

[ESCU - Previously seen command line arguments]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-09
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = In this support search, we look for command-line arguments using the parameter <code>/c</code> to execute processes and create an initial baseline cache for the previous 30 days. This will include the earliest and latest times a particular command-line argument is seen in our dataset, grouped by the command-line value.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon Technology Add-on (TA).
action.escu.full_search_name = ESCU - Previously seen command line arguments
action.escu.mappings = {"cis20": ["CIS 8"], "nist": ["PR.DS"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Suspicious Command-Line Executions"]
description = This search looks for command-line arguments where <code>cmd.exe /c</code> is used to execute a program, then creates a baseline of the earliest and latest times we have encountered this command-line argument in our dataset within the last 30 days.
dispatch.earliest_time = -30d@d
dispatch.latest_time = -5m@m
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational process=cmd.exe cmdline="* /c *" | stats earliest(_time) as firstTime latest(_time) as lastTime by cmdline | outputlookup previously_seen_cmd_line_arguments

[ESCU - Remote WMI Command Attempt - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-01-13
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Many a times, attackers leverage native Windows utilities that are designed to help administrators better manage their systems, infrastructure, and auditing, but are instead leveraged for malicious purposes. In this case, we are looking for instances of wmic.exe being run with various parameters that are not typically used by administrators.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Remote WMI Command Attempt
action.escu.mappings = {"mitre_attack": ["Execution", "Windows Management Instrumentation"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Administrators may use this legitimately to gather info from remote systems.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Suspicious WMI Use"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,cmdline
alert.suppress.period = 28800s
cron_schedule = 50 * * * *
description = This search looks for wmic.exe being launched with parameters to operate on remote systems.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*wmic* cmdline="*/node*" | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - AWS Network Access Control List Deleted - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-01-08
action.escu.modification_date = 2017-01-10
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The search looks for CloudTrail events to detect whether any network ACLs have been deleted and gives you values of error messages and error codes (if any), user details, user source IP, the user who initiated this request, and the name of the event.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - AWS Network Access Control List Deleted
action.escu.mappings = {"mitre_attack": ["Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 11"], "nist": ["DE.DP", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It's possible that a user has legitimately deleted a network ACL.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the CloudTrail logs to detect users deleting network ACLs.
dispatch.earliest_time = -1d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=DeleteNetworkAcl|rename userIdentity.arn as arn  | stats count min(_time) as firstTime max(_time) as lastTime values(errorMessage) values(errorCode) values(userAgent) values(userIdentity.*) by src userName arn eventName | `ctime(lastTime)` | `ctime(firstTime)`

[ESCU - Get All AWS Activity From Country]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.channel = ESCU
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Get All AWS Activity From Country
action.escu.search_type = investigative
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.fields_required = ["Country"]
action.escu.earliest_time_offset = 14400
action.escu.latest_time_offset = 0
description = This search retrieves all the activity from a specific country and will create a table containing the time, country, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API callled, and whether or not the API call was successful.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search Country={Country} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, Country, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Detect AWS API Activities From Unapproved Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-13
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = In this search, we are looking for successful API calls via CloudTrail. We filter out events triggered by known users that are listed in the <code>identity_lookup_expanded</code> lookup file and the service accounts. Once filtered out, we output a table with the values of event names, count, first time, and last time a specific user or service is detected
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You must also populate the identity_lookup_expanded lookup shipped with the Asset and Identity framework to be able to look up users in your identity table in Enterprise Security (ES). Leverage the support search <code>Create a list of approved AWS service accounts</code>: run it once every 30 days to create a list of service accounts and validate them.
action.escu.full_search_name = ESCU - Detect AWS API Activities From Unapproved Accounts
action.escu.mappings = {"mitre_attack": ["Credential Access", "Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 16"], "nist": ["DE.DP", "DE.CM", "PR.AC", "ID.AM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It's likely that you'll find activity detected by users/service accounts that are not listed in the <code>identity_lookup_expanded</code> or <code> aws_service_accounts.csv</code> file. If the user is a legitimate service account, please update the <code>aws_service_accounts.csv</code> table with that entry.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search will look for successful CloudTrail activity by user accounts that are not listed in the identity table or <code>aws_service_accounts.csv</code> and will return the count, the first time, the last time, and the values of the event names grouped by users.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail errorCode=success | rename userName as identity | search NOT [| inputlookup identity_lookup_expanded | fields identity] | search NOT [| inputlookup aws_service_accounts.csv | fields identity] | rename identity as user | stats count min(_time) as firstTime max(_time) as lastTime values(eventName) by user | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Schtasks scheduling job on remote system - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate a task is being scheduled on a remote host. Schtasks.exe is a native windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or malicious executables on remote systems.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Schtasks scheduling job on remote system
action.escu.mappings = {"mitre_attack": ["Persistence", "Lateral Movement", "Execution", "Scheduled Task", "Remote Services"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Administrators may create jobs on remote systems, but this activity is usually limited to a small set of hosts or users. It is important to validate and investigate as appropriate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Lateral Movement"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,cmdline
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for flags passed to schtasks.exe on the command-line that indicate a job is being scheduled on a remote system.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*schtasks.exe* cmdline="*/create*" cmdline="* /s *" | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Suspicious wevtutil Usage - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-02-17
action.escu.modification_date = 2017-09-12
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for execution of wevtutil.exe with command-line arguments that indicate that it has been used to delete the setup, application, security, or system event logs. The search returns the number of times the behavior was observed, the first and last time it was seen, the host exhibiting the behavior and the user context of the process execution.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Suspicious wevtutil Usage
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Indicator Removal on Host"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 6"], "nist": ["DE.DP", "PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = The wevtutil.exe application is a legitimate Windows event log utility. Administrators may use it to manage Windows event logs.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Log Manipulation", "Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,cmdline
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = The wevtutil.exe application is the windows event log utility. This searches for wevtutil.exe with parameters for clearing the application, security, setup, or system event logs.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*wevtutil.exe* cmdline="*cl*" (cmdline="*System**" OR cmdline="*Security*" OR cmdline="*Setup*" OR cmdline="*Application*") | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Previously Seen EC2 AMIs]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.asset_at_risk = EC2 Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = In this support search, we create a table of the earliest and latest time that a specific AMI ID has been seen. This table is then outputted to a .csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Previously Seen EC2 AMIs
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining"]
description = This search builds a table of previously seen AMIs used to launch EC2 instances
dispatch.earliest_time = -5m@m
dispatch.latest_time = -90d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | rename requestParameters.instancesSet.items{}.imageId as amiID | stats earliest(_time) as earliest latest(_time) as latest by amiID | outputlookup previously_seen_ec2_amis.csv

[ESCU - Detect Rare Executables - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-08-09
action.escu.modification_date = 2018-04-16
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search counts all of your processes to determine how rare each one is. It then filters out processes that are included on a whitelist and outputs those that make up less than three percent of total processes.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting data that records process activity from your hosts. The macro <code>filter_rare_process_whitelist</code> searches two lookup files to whitelist your processes.  These consist of <code>rare_process_whitelist_default.csv</code> and <code>rare_process_whitelist_local.csv</code>. To add your own processes to the whitelist, add them to <code>rare_process_whitelist_local.csv</code>. If you wish to remove an entry from the default lookup file, you will have to modify the macro itself to set the whitelist value for that process to false.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Detect Rare Executables
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "cis20": ["CIS 2", "CIS 8"], "nist": ["ID.AM", "PR.PT", "PR.DS", "DE.CM"]}
action.escu.kill_chain_phases = ["Installation", "Command and Control", "Actions on Objectives"]
action.escu.known_false_positives = Some legitimate processes may be only rarely executed in your environment. As these are identified, update <code>rare_process_whitelist_local.csv</code> to remove them from your search results.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Unusual Processes"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 86400s
cron_schedule = 10 * * * *
description = This search will create a table of rare processes and the names of the systems running them.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count from datamodel=Application_State.All_Application_State where nodename=All_Application_State.Processes by All_Application_State.process All_Application_State.dest | `drop_dm_object_name("All_Application_State")` | rare process by dest | `filter_rare_process_whitelist` | where percent < 3

[ESCU - AWS Network Interface details via resourceId]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-05-07
action.escu.modification_date = 2018-05-07
action.escu.channel = ESCU
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS configuration inputs
action.escu.full_search_name = ESCU - AWS Network Interface details via resourceId
action.escu.search_type = contextual
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity", "Suspicious AWS Traffic"]
action.escu.fields_required = ["resourceId"]
action.escu.earliest_time_offset = 86400
action.escu.latest_time_offset = 0
description = This search queries AWS configuration logs and returns the information about a specific network interface via network interface ID. The information will include the ARN of the network interface, its relationships with other AWS resources, the public and the private IP associated with the network interface.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=aws:config resourceId={resourceId} | table _time ARN relationships{}.resourceType relationships{}.name relationships{}.resourceId  configuration.privateIpAddresses{}.privateIpAddress configuration.privateIpAddresses{}.association.publicIp

[ESCU - Monitor Web Traffic For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2017-09-23
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks at all the URLs an endpoint is connecting to and then checks the URL against a list of faux domains that could be indicative of brand abuse.
action.escu.how_to_implement = You need to ingest data from your web traffic. This can be accomplished by indexing data from a web proxy, or using a network traffic analysis tool, such as Bro or Splunk Stream. You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.data_models = ["Web"]
action.escu.full_search_name = ESCU - Monitor Web Traffic For Brand Abuse
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 7"], "nist": ["PR.IP"]}
action.escu.kill_chain_phases = ["Delivery"]
action.escu.known_false_positives = None at this time
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.analytic_story = ["Brand Monitoring"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for Web requests to faux domains similar to the one that you want to have monitored for abuse.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` values(Web.url) as urls min(_time) as firstTime from datamodel=Web by Web.src | `drop_dm_object_name("Web")` | `ctime(firstTime)` | `brand_abuse_web`

[ESCU - Identify Systems Receiving Remote Desktop Traffic]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-24
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search counts the numbers of times the system has received a connection to TCP/ 3389, the default port used for RDP traffic.
action.escu.how_to_implement = To successfully implement this search you must ingest network traffic and populate the Network_Traffic data model. If a system receives a lot of remote desktop traffic, you can apply the category common_rdp_destination to it.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Identify Systems Receiving Remote Desktop Traffic
action.escu.mappings = {"mitre_attack": ["Lateral Movement", "Remote Desktop Protocol"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 9", "CIS 16"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.search_type = support
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Lateral Movement"]
description = This search counts the numbers of times the system has created remote desktop traffic
dispatch.earliest_time = now
dispatch.latest_time = -30d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=3389 by All_Traffic.dest | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - Sc.exe Manipulating Windows Services - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-11-03
action.escu.modification_date = 2017-11-03
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for the execution of sc.exe with parameters that indicate the utility is being used to create a new Windows service, or modify an existing one. Attackers often create a new service to host their malicious code, or they may take a non-critical service or one that is disabled, and modify it to point to their malware and enable the service if necessary. It is unusual for a service to be created or modified using the sc.exe utility.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Sc.exe Manipulating Windows Services
action.escu.mappings = {"mitre_attack": ["Persistence", "Privilege Escalation", "New Service", "Modify Existing Service", "Defense Evasion", "Disabling Security Tools"], "kill_chain_phases": ["Installation"], "cis20": ["CIS 3", "CIS 5", "CIS 8"], "nist": ["PR.IP", "PR.PT", "PR.AC", "PR.AT", "DE.CM"]}
action.escu.kill_chain_phases = ["Installation"]
action.escu.known_false_positives = Using sc.exe to manipulate Windows services is uncommon. However, there may be legitimate instances of this behavior. It is important to validate and investigate as appropriate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Windows Persistence Techniques", "Disabling Security Tools", "Windows Service Abuse"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, cmdline
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for arguments to sc.exe indicating the creation or modification of a Windows service.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*sc.exe* AND (cmdline="* create *" OR cmdline="* config *") | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - DNS Query Requests Resolved by Unauthorized DNS Servers - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-07-08
action.escu.modification_date = 2017-09-18
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Clients should be resolving their DNS requests via a trusted DNS server. This search will identify DNS queries being sent to unauthorized DNS servers by comparing the destination and source of the traffic with assets marked as DNS servers.
action.escu.how_to_implement = To successfully implement this search you will need to ensure that DNS data is populating the Network_Resolution data model. It also requires that your DNS servers are identified correctly in the Assets and Identity table of Enterprise Security.
action.escu.data_models = ["Network_Resolution"]
action.escu.full_search_name = ESCU - DNS Query Requests Resolved by Unauthorized DNS Servers
action.escu.mappings = {"mitre_attack": ["Exfiltration", "Command and Control", "Defense Evasion", "Commonly Used Port"], "kill_chain_phases": ["Command and Control"], "cis20": ["CIS 1", "CIS 3", "CIS 8", "CIS 12"], "nist": ["ID.AM", "PR.DS", "PR.IP", "DE.AE", "DE.CM"]}
action.escu.kill_chain_phases = ["Command and Control"]
action.escu.known_false_positives = Legitimate DNS activity can be detected in this search. Investigate, verify and update the list of authorized DNS servers as appropriate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Suspicious DNS Traffic"]
action.notable = 1
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search will detect DNS requests resolved by unauthorized DNS servers. Legitimate DNS servers should be identified in the Enterprise Security Assets and Identity Framework.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count from datamodel=Network_Resolution where DNS.dest_category != dns_server AND DNS.src_category != dns_server by DNS.src DNS.dest | `drop_dm_object_name("DNS")`

[ESCU - Deleting Shadow Copies - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-02-17
action.escu.modification_date = 2017-09-12
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for execution of vssadmin or wmic with both the "delete" and "shadows" parameters passed on the command-line. The two arguments are searched for separately because we can't predict the number of spaces between the words on the command-line. The search will return the number of times this activity was observed, and the times of the first and last event.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Deleting Shadow Copies
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8", "CIS 10"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = vssadmin.exe and wmic.exe are standard applications shipped with modern versions of windows. They may be used by administrators to legitimately delete old backup copies, although this is typically rare.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Log Manipulation", "Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = The vssadmin.exe utility is used to interact with the Volume Shadow Copy Service.  Wmic is an interface to the Windows Management Instrumentation.  This search looks for either of these tools being used to delete shadow copies.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) (process=*vssadmin* OR process=*wmic*) cmdline=*delete* cmdline=*shadow* | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Investigate Suspicious Strings in HTTP Header]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-26
action.escu.modification_date = 2017-10-20
action.escu.channel = ESCU
action.escu.how_to_implement = This particular search leverages data extracted from Stream:HTTP. You must configure the http stream using the Splunk Stream App on your Splunk Stream deployment server to extract the cs_content_type field.
action.escu.full_search_name = ESCU - Investigate Suspicious Strings in HTTP Header
action.escu.search_type = investigative
action.escu.providing_technologies = ["Splunk Stream"]
action.escu.analytic_story = ["Apache Struts Vulnerability"]
action.escu.fields_required = ["src_ip", "dest_ip"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 3600
description = This search helps an analyst investigate a notable event related to a potential Apache Struts exploitation. To investigate, we will want to isolate and analyze the "payload" or the commands that were passed to the vulnerable hosts by creating a few regular expressions to carve out the commands focusing on common keywords from the payload, such as cmd.exe, /bin/bash and whois. The search returns these suspicious strings found in the HTTP logs of the system of interest.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=stream:http src_ip="{src_ip}" dest_ip="{dest_ip}" | eval cs_content_type_length = len(cs_content_type) | search cs_content_type_length > 100 | rex field="cs_content_type" (?<suspicious_strings>cmd.exe) | eval suspicious_strings_found=if(match(cs_content_type, "application"), "True", "False")  | rename suspicious_strings_found AS "Suspicious Content-Type Found" | fields "Suspicious Content-Type Found", dest_ip, src_ip, suspicious_strings, cs_content_type, cs_content_type_length, url

[ESCU - AWS Investigate User Activities By ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-22
action.escu.modification_date = 2018-02-25
action.escu.channel = ESCU
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - AWS Investigate User Activities By ARN
action.escu.search_type = investigative
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Unusual AWS EC2 Modifications", "Suspicious AWS Login Activities", "Suspicious AWS EC2 Activities", "AWS Network ACL Activity"]
action.escu.fields_required = ["arn"]
action.escu.earliest_time_offset = 14400
action.escu.latest_time_offset = 0
description = This search lists all the logged CloudTrail activities by a specific user ARN and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and all the user's identity information.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=aws:cloudtrail userIdentity.arn={arn} | table _time userIdentity.type userIdentity.userName userIdentity.arn aws_account_id src awsRegion eventName eventType 

[ESCU - Shim Database File Creation - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-10-03
action.escu.modification_date = 2017-10-10
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks files being created in Windows\AppPatch\Custom and Windows\AppPatch\Custom64, the location where shim databases are installed to. It will return all the files created and the time of the first and last file creation of those files for each endpoint.
action.escu.how_to_implement = To successfully implement this search, you need to ingest logs with both the process name and command-line from your endpoints. If you are using Sysmon, you will need to have a Splunk Universal Forwarder on each endpoint that you want to collect the data on.  You will also need to have to deploy the Sysmon TA on these endpoints and on your search head.  You must have at least version 6.0.4 of the Sysmon TA.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Shim Database File Creation
action.escu.mappings = {"mitre_attack": ["Persistence", "Application Shimming"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Legitimate shim files are created and used all the time. This event in itself is not suspicious, however if there are other events that can be correlated in addition to notable event, further investigation may be warranted.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for shim database files being written to default directories. The sdbinst.exe application is used to install shim database files (.sdb). According to Microsoft, a shim is a small library which transparently intercepts an API, changes the parameters passed, handles the operation itself, or redirects the operation elsewhere.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count values(All_Changes.Endpoint_Changes.Filesystem_Changes.file_path) as file_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis where All_Changes.object_category=file AND All_Changes.Endpoint_Changes.Filesystem_Changes.file_path=*Windows\AppPatch\Custom* by All_Changes.Endpoint_Changes.Filesystem_Changes.file_name All_Changes.dest | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes.Endpoint_Changes.Filesystem_Changes")` | `drop_dm_object_name("All_Changes")`

[ESCU - Count of assets by category]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-11
action.escu.modification_date = 2017-09-13
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search gives you the number and the names of the hosts of each host in your environment by category. It will then sort them by the count.
action.escu.how_to_implement = To successfully implement this search you must first leverage the Assets and Identity framework in Enterprise Security to populate your assets_by_str.csv file which should then be mapped to the Identity_Management data model. The Identity_Management data model will contain a list of known authorized company assets. Ensure that all inventoried systems are constantly vetted and updated.
action.escu.data_models = ["Identity_Management"]
action.escu.full_search_name = ESCU - Count of assets by category
action.escu.search_type = support
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.analytic_story = ["Asset Tracking"]
description = This search shows you every asset category you have and the assets that belong to those categories.
dispatch.earliest_time = -30d
dispatch.latest_time = now
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | from datamodel Identity_Management.All_Assets | stats count values(nt_host) by category | sort -count

[ESCU - Get Email Info]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-11-09
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search you must be ingesting your email logs or capturing unencrypted network traffic which contains email communications.
action.escu.data_models = ["Email"]
action.escu.full_search_name = ESCU - Get Email Info
action.escu.search_type = investigative
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.analytic_story = ["Suspicious Emails", "Brand Monitoring"]
action.escu.fields_required = ["message_id"]
action.escu.earliest_time_offset = 0
action.escu.latest_time_offset = 7200
description = This search returns all the information Splunk might have collected a specific email message over the last 2 hours.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | from datamodel Email.All_Email | search message_id={message_id}

[ESCU - Monitor Unsuccessful Backups]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-12
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search gives you the count and hostname of all the systems that had a backup failure each day
action.escu.how_to_implement = To successfully implement this search you must be ingesting your backup logs.
action.escu.full_search_name = ESCU - Monitor Unsuccessful Backups
action.escu.search_type = support
action.escu.providing_technologies = ["Netbackup"]
action.escu.analytic_story = ["Monitor Backup Solution", "Ransomware"]
description = This search is intended to give you a feel for how often backup failures happen in your environments.  Fluctuations in these numbers will allow you to determine when you should investigate.
dispatch.earliest_time = -30d
dispatch.latest_time = now
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype="netbackup_logs" "An error occurred, failed to backup." | bucket _time span=1d | stats dc(COMPUTERNAME) as count values(COMPUTERNAME) as dest by _time, MESSAGE

[ESCU - Previously Seen AWS Provisioning Activity Sources]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.asset_at_risk = AWS Infrastructure
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search includes any event name that begins with "run" or "create," and then determines the first and last time these events were seen for each IP address that initiated the action. The search then consults a <b>GeoIP</b> database to determine the physical location of this IP address. This table outputs to a .csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Previously Seen AWS Provisioning Activity Sources
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
description = This search builds a table of the first and last times seen for every IP address (along with its physical location) previously associated with cloud-provisioning activity. This is broadly defined as any event that runs or creates something.
dispatch.earliest_time = -5m@m
dispatch.latest_time = -90d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv

[ESCU - AWS Network ACL Details from ID]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-18
action.escu.modification_date = 2017-01-22
action.escu.channel = ESCU
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
action.escu.full_search_name = ESCU - AWS Network ACL Details from ID
action.escu.search_type = contextual
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity"]
action.escu.fields_required = ["networkAclId"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 0
description = This search queries AWS description logs and returns all the information about a specific network ACL via network ACL ID
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=aws:description id={networkAclId} | table id account_id vpc_id network_acl_entries{}.*

[ESCU - Detect PsExec With accepteula Flag - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-28
action.escu.modification_date = 2018-03-28
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = In this search, we are looking for the PsExec process with <code>accepteula</code> on the command line.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with the process name, command-line arguments, and parent process from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon Technology Add-on (TA).
action.escu.full_search_name = ESCU - Detect PsExec With accepteula Flag
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Administrators can leverage PsExec for accessing remote systems and might pass <code>accepteula</code> as an argument if they are running this tool for the first time. However, it is not likely that you'd see multiple occurrences of this event on a machine
action.escu.search_type = detection
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 75
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, parent_process
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for events where <code>PsExec.exe</code> is run with the <code>accepteula</code> flag in the command line. PsExec is a built-in Windows utility that enables you to execute processes on other systems. It is fully interactive for console applications. This tool is widely used for launching interactive command prompts on remote systems. Threat actors leverage this extensively for executing code on compromised systems. If an attacker is running PsExec for the first time, they will be prompted to accept the end-user license agreement (EULA), which can be passed as the argument <code>accepteula</code> within the command line.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=xmlwineventlog:microsoft-windows-sysmon/operational process=PsExec.exe accepteula  | search cmdline=*accepteula* | stats count values(cmdline) as cmdlines, min(_time) as firstTime, max(_time) as lastTime by dest, user, parent_process | `ctime(firstTime)`| `ctime(lastTime)` | table firstTime, lastTime, count, dest, user, parent_process, cmdlines

[ESCU - Scheduled tasks used in BadRabbit ransomware - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-11-03
action.escu.modification_date = 2017-11-03
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The search looks for execution of schtasks.exe with parameters that indicate that specific task names related to the Bad Rabbit ransomware were created or deleted. The specific task name used are rhaegal, drogon and viserion_. Schtasks.exe is a native windows program that is used to schedule tasks on local or remote systems. Attackers often leverage this capability to schedule the execution of commands or establish persistence.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Scheduled tasks used in BadRabbit ransomware
action.escu.mappings = {"mitre_attack": ["Persistence", "Lateral Movement", "Execution", "Scheduled Task"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3"], "nist": ["PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = No known false positives
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, cmdline
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for flags passed to schtasks.exe on the command-line that indicate that task names related to the execution of Bad Rabbit ransomware were created or deleted.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*schtasks.exe (create OR delete) | search (cmdline=*rhaegal* OR cmdline=*drogon* OR *viserion_*) | stats count values(cmdline) min(_time) as firstTime max(_time) as lastTime by dest process | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - AWS Cloud Provisioning From Previously Unseen Country - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-16
action.escu.modification_date = 2018-03-16
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The subsearch returns all events with event names that start with "Run" or "Create," and then does a <code>GeoIP</code> lookup on the IP address that initiated the action within the last hour. It appends the historical data to those results in the lookup file. Next, it recalculates the <code>firstTime</code> and <code>lastTime</code> field for each country, region, city, and IP address and outputs this data to the lookup file to update the local cache. It then calculates the <code>firstTime</code> and <code>lastTime</code> for each country. It returns only those events from countries that have first been seen in the past hour. This is combined with the main search to return the time, user, IP address, city, event name, and error code from the action.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen AWS Provisioning Activity Sources" support search once to create a history of previously seen locations that have provisioned AWS resources.
action.escu.full_search_name = ESCU - AWS Cloud Provisioning From Previously Unseen Country
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.known_false_positives = This is a strictly behavioral search, so we define "false positive" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching over plus what is stored in the cache feature. But while there are really no "false positives" in a traditional sense, there is definitely lots of noise.<br></br> This search will fire any time a new country is seen in the <b>GeoIP</b> database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of <b>MaxMind GeoIP</b> that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for AWS provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that begins with "Run" or "Create." 
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* [search sourcetype=aws:cloudtrail (eventName=Run* OR eventName=Create*) | iplocation sourceIPAddress | search Country=* | stats earliest(_time) as firstTime, latest(_time) as lastTime by sourceIPAddress, City, Region, Country | inputlookup append=t previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by sourceIPAddress, City, Region, Country | outputlookup previously_seen_provisioning_activity_src.csv | stats min(firstTime) as firstTime max(lastTime) as lastTime by Country | eval newCountry=if(firstTime >= relative_time(now(), "-1h@h"), 1, 0) | where newCountry=1 | table Country] | spath output=user userIdentity.arn | rename sourceIPAddress as src_ip | table _time, user, src_ip, Country, eventName, errorCode

[ESCU - Investigate Web Activity From Host]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-11-09
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search you must be ingesting your web traffic and populating the Web data model.
action.escu.data_models = ["Web"]
action.escu.full_search_name = ESCU - Investigate Web Activity From Host
action.escu.search_type = investigative
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Bluecoat", "Palo Alto Firewall"]
action.escu.analytic_story = ["Host Redirection", "Monitor for Unauthorized Software", "Suspicious Emails", "Ransomware", "Brand Monitoring", "Suspicious Command-Line Executions", "Netsh Abuse", "Unusual Processes"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 3600
action.escu.latest_time_offset = 3600
description = This search allows you to find all the web activity from a specific host. During an investigation, it is important to profile web activity to characterize user or host activity.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | from datamodel Web.Web | search src={dest}

[ESCU - Get All AWS Activity From City]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-19
action.escu.modification_date = 2018-03-19
action.escu.channel = ESCU
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Get All AWS Activity From City
action.escu.search_type = investigative
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Suspicious Provisioning Activities"]
action.escu.fields_required = ["City"]
action.escu.earliest_time_offset = 14400
action.escu.latest_time_offset = 0
description = This search retrieves all the activity from a specific city and will create a table containing the time, city, ARN, username, the type of user, the source IP address, the AWS region the activity was in, the API callled, and whether or not the API call was successful.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=aws:cloudtrail | iplocation sourceIPAddress | search City={City} | spath output=user path=userIdentity.arn | spath output=awsUserName path=userIdentity.userName | spath output=userType path=userIdentity.type | rename sourceIPAddress as src_ip | table _time, City, user, userName, userType, src_ip, awsRegion, eventName, errorCode

[ESCU - Monitor Email For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2018-01-05
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks at the sender address in email headers, and identifies those with a sender address using a domain name that matches the list of permutations generated for the domain you want to monitor.
action.escu.how_to_implement = You need to ingest email header data. Specifically the sender's address (src_user) must be populated.  You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.data_models = ["Email"]
action.escu.full_search_name = ESCU - Monitor Email For Brand Abuse
action.escu.mappings = {"kill_chain_phases": ["Delivery"], "cis20": ["CIS 7"], "nist": ["PR.IP"]}
action.escu.kill_chain_phases = ["Delivery"]
action.escu.known_false_positives = None at this time
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Exchange", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Brand Monitoring"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = message_id, src_user
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for emails claiming to be sent from a domain similar to one that you want to have monitored for abuse.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` values(All_Email.recipient) as recipients, min(_time) as firstTime, max(_time) as lastTime from datamodel=Email by All_Email.src_user, All_Email.message_id | `drop_dm_object_name("All_Email")` | `ctime(firstTime)` | `ctime(lastTime)` | eval temp=split(src_user, "@") | eval email_domain=mvindex(temp, 1) | lookup update=true brandMonitoring_lookup domain as email_domain OUTPUT domain_abuse | search domain_abuse=true | table message_id, src_user, email_domain, recipients, firstTime, lastTime

[ESCU - Windows Updates Install Failures]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-14
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search gives you the count of the number of systems that attempted and failed to install a Windows update each day.
action.escu.how_to_implement = You must be ingesting your Windows Update Logs
action.escu.data_models = ["Updates"]
action.escu.full_search_name = ESCU - Windows Updates Install Failures
action.escu.search_type = support
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Ransomware"]
description = This search is intended to give you a feel for how often Windows updates fail to install in your environment. Fluctuations in these numbers will allow you to determine when you should be concerned.
dispatch.earliest_time = -30d
dispatch.latest_time = now
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` dc(Updates.dest) as count FROM datamodel=Updates where Updates.vendor_product="Microsoft Windows" AND Updates.status=failure by _time span=1d

[ESCU - Get Authentication Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-11-01
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search you need to be ingesting authentication logs from your various systems and populating the Authentication data model.
action.escu.data_models = ["Authentication"]
action.escu.full_search_name = ESCU - Get Authentication Logs For Endpoint
action.escu.search_type = contextual
action.escu.providing_technologies = ["Microsoft Windows", "Linux", "macOS"]
action.escu.analytic_story = ["Monitor for Updates", "Router & Infrastructure Security", "Windows Log Manipulation", "Windows Defense Evasion Tactics", "Host Redirection", "Windows Privilege Escalation", "Malicious PowerShell", "Lateral Movement", "JBoss Vulnerability", "Asset Tracking", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "Collection and Staging", "Spectre And Meltdown Vulnerabilities", "DHS Report TA18-074A", "Windows File Extension and Association Abuse", "Suspicious DNS Traffic", "Suspicious Emails", "Windows Persistence Techniques", "Account Monitoring and Controls", "Disabling Security Tools", "Splunk Enterprise Vulnerability", "SQL Injection", "Data Protection", "Dynamic DNS", "Ransomware", "Brand Monitoring", "Apache Struts Vulnerability", "Suspicious Command-Line Executions", "Suspicious WMI Use", "Netsh Abuse", "Unusual Processes", "Windows Service Abuse"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 43200
action.escu.latest_time_offset = 1
description = This search returns all users that have attempted to access a particular endpoint.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats count from datamodel=Authentication where Authentication.dest={dest} by _time, Authentication.dest, Authentication.user, Authentication.app, Authentication.action | `drop_dm_object_name("Authentication")`

[ESCU - Single Letter Process On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-22
action.escu.modification_date = 2018-03-22
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search returns all the processes for each endpoint and user and filters out any process that isn't 5 characters long and ends with .exe.
action.escu.how_to_implement = To successfully implement this search, you must ingest information on process activity from your endpoints into Splunk. This can be done using various endpoint-detection and response solutions, endpoint data sources (such as Sysmon), or via Windows event logs, after enabling process tracking in your Windows audit settings.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Single Letter Process On Endpoint
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 2"], "nist": ["ID.AM", "PR.DS"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Single-letter executables are not always malicious. Investigate this activity with your normal incident-response process.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for process names that consist only of a single letter.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats count, latest(_time) as lastTime, earliest(_time) as firstTime from datamodel=Application_State by All_Application_State.dest, All_Application_State.user, All_Application_State.process, All_Application_State.process_name | `drop_dm_object_name("All_Application_State")` | `ctime(lastTime)` | `ctime(firstTime)` | eval process_name_length = len(process_name), endExe = if(substr(process_name, -4) == ".exe", 1, 0) | search process_name_length=5 AND endExe=1 | table count, firstTime, lastTime, dest, user, process, process_name

[ESCU - Protocols passing authentication in cleartext - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-03
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search is checking for traffic on well-known ports that are associated with protocols that pass authentication in cleartext.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic, and populating the Network_Traffic data model.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Protocols passing authentication in cleartext
action.escu.mappings = {"mitre_attack": ["Credential Access", "Lateral Movement", "Collection"], "kill_chain_phases": ["Reconnaissance", "Actions on Objectives"], "cis20": ["CIS 9", "CIS 14"], "nist": ["PR.PT", "DE.AE", "PR.AC", "PR.DS"]}
action.escu.kill_chain_phases = ["Reconnaissance", "Actions on Objectives"]
action.escu.known_false_positives = Some networks may use kerberized FTP or telnet servers, however, this is rare.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Use of Cleartext Protocols"]
action.notable = 1
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for cleartext protocols at risk of leaking credentials. Currently, this consists of legacy protocols such as telnet, POP3, IMAP, and non-anonymous FTP sessions. While some of these protocols can be used over SSL, they typically run on different assigned ports in those cases.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.protocol="tcp" AND (All_Traffic.dest_port="23" OR All_Traffic.dest_port="143" OR All_Traffic.dest_port="110" OR (All_Traffic.dest_port="21" AND All_Traffic.user != "anonymous")) groupby All_Traffic.user All_Traffic.src All_Traffic.dest All_Traffic.dest_port | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - Processes created by netsh - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-04
action.escu.modification_date = 2018-01-04
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for all processes that have a parent process of "C:\Windows\System32\netsh.exe and returns the process, the command-line used to execute it, the host name, and the user context under which it ran.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with the process name, command-line arguments and parent process from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Processes created by netsh
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = It is unusual for netsh.exe to have any child processes in most environments. Please investigate the child process and verify if the process spawned is legitimate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Netsh Abuse"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for processes launching netsh.exe to execute various commands via the netsh command-line utility. Netsh.exe is a command-line scripting utility that allows you to, either locally or remotely, display or modify the network configuration of a computer that is currently running. Netsh can be used as a persistence proxy technique to execute a helper DLL when netsh.exe is executed. In this search, we are looking for processes spawned by netsh.exe and executing commands via command-line.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational parent_process="C:\Windows\System32\netsh.exe" | stats count values(cmdline) AS cmdline  min(_time) as firstTime max(_time) as lastTime by dest user parent_process process | `ctime(firstTime)`|`ctime(lastTime)` | table firstTime lastTime count dest parent_process process cmdline

[ESCU - Add Prohibited Processes to Enterprise Security]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-27
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search outputs the interesting processes lookup table and filters out all processes in the table that haven't already been inserted by ESCU. It then appends to those results all the processes currently identified by ESCU that should be prohibited. Next, it fills in the required fields with processes identified by ESCU, and then writes the results back to the interesting process lookup table. This is done so any new processes identified that should be prohibited will be added to the lookup table without creating any duplicate entries.
action.escu.how_to_implement = This search should be run on each new install of ESCU.
action.escu.data_models = []
action.escu.full_search_name = ESCU - Add Prohibited Processes to Enterprise Security
action.escu.mappings = {"cis20": ["CIS 2"]}
action.escu.search_type = support
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.analytic_story = ["Monitor for Unauthorized Software"]
description = This search takes the existing interesting process table from ES, filters out any existing additions added by ESCU and then updates the table with processes identified by ESCU that should be prohibited on your endpoints.
dispatch.earliest_time = now
dispatch.latest_time = -30d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | inputlookup interesting_processes_lookup | search note!=ESCU* | inputlookup append=T prohibitedProcesses_lookup | fillnull value=* dest dest_pci_domain | fillnull value=false is_required is_secure | fillnull value=true is_prohibited | outputlookup interesting_processes_lookup

[ESCU - Monitor DNS For Brand Abuse - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2017-09-23
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search gathers all the answers to each system's DNS query, then filters out all queries that do not appear on the list of faux "look-a-like" domains that have been generated from the brand abuse domains you are monitoring.
action.escu.how_to_implement = You need to ingest data from your DNS logs. Specifically you must ingest the domain that is being queried and the IP of the host originating the request. Ideally, you should also be ingesting the answer to the query and the query type. This approach allows you to also create your own localized passive DNS capability which can aid you in future investigations. You also need to have run the search "ESCU - DNSTwist Domain Names", which creates the permutations of the domain that will be checked for.
action.escu.data_models = ["Network_Resolution"]
action.escu.full_search_name = ESCU - Monitor DNS For Brand Abuse
action.escu.mappings = {"kill_chain_phases": ["Delivery", "Actions on Objectives"]}
action.escu.kill_chain_phases = ["Delivery", "Actions on Objectives"]
action.escu.known_false_positives = None at this time
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Brand Monitoring"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src,query
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for DNS requests for faux domains similar to the domains that you want to have monitored for abuse.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` values(DNS.answer) as IPs min(_time) as firstTime from datamodel=Network_Resolution by DNS.src, DNS.query | `drop_dm_object_name("DNS")` | `ctime(firstTime)`| `brand_abuse_dns`

[ESCU - Remote Desktop Network Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search finds systems that do not commonly communicate use remote desktop.  It does this by filtering out all systems that have the "common_rdp_source" or "common_rdp_destination" category applied to that system.  Categories are applied to systems using the Assets and Identity framework.
action.escu.how_to_implement = To successfully implement this search you need to identify systems that commonly originate remote desktop traffic and that commonly receive remote desktop traffic. You can use the included support search "Identify Systems Creating Remote Desktop Traffic" to identify systems that originate the traffic and the search "Identify Systems Receiving Remote Desktop Traffic" to identify systems that receive a lot of remote desktop traffic. After identifying these systems, you will need to add the "common_rdp_source" or "common_rdp_destination" category to that system depending on the usage, using the Enterprise Security Assets and Identities framework.  This can be done by adding an entry in the assets.csv file located in SA-IdentityManagement/lookups.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Remote Desktop Network Traffic
action.escu.mappings = {"mitre_attack": ["Lateral Movement", "Remote Desktop Protocol", "Commonly Used Port"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 9", "CIS 16"], "nist": ["DE.AE", "PR.AC", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Remote Desktop may be used legitimately by users on the network.
action.escu.search_type = detection
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["Lateral Movement"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,src
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for network traffic on TCP/3389, the default port used by remote desktop. While remote desktop traffic is not uncommon on a network, it is usually associated with known hosts. This search allows for whitelisting both source and destination hosts to remove them from the output of the search so you can focus on the uncommon uses of remote desktop on your network.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.dest_port=3389 AND All_Traffic.dest_category!=common_rdp_destination AND All_Traffic.src_category!=common_rdp_source by All_Traffic.src All_Traffic.dest All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Create local admin accounts using net.exe - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-28
action.escu.modification_date = 2018-03-28
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Net.exe is an built-in command-line tool on Windows that can be used to add, display, or modify user accounts. Though this tool is used by Microsoft administrators to manage user groups, threat actors often leverage it to create local admin accounts to maintain persistence. In this search, we are looking for the execution of process net.exe with command-line parameters like <code>localgroup</code>, <code>add</code>, or <code>user</code> that may correspond to the creation of local admin accounts or setting user/group properties.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with the process name, command-line arguments, and parent process from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon Technology Add-On (TA).
action.escu.full_search_name = ESCU - Create local admin accounts using net.exe
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface", "Persistence"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Administrators often leverage net.exe to create admin accounts on system.
action.escu.search_type = detection
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
cron_schedule = 0 8 * * *
description = This search looks for the creation of local administrator accounts using net.exe.
dispatch.earliest_time = -1440m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational process=net.exe (localgroup OR /add OR user) | search cmdline=*localgroup* OR cmdline=*/add* OR cmdline=*user* | stats count values(cmdline) as cmdlines, min(_time) as firstTime, max(_time) as lastTime by dest, user, parent_process | `ctime(firstTime)`| `ctime(lastTime)` | table firstTime, lastTime, count, dest, user, parent_process, cmdlines

[ESCU - Previously Seen EC2 Modifications By User]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-05
action.escu.modification_date = 2018-04-05
action.escu.asset_at_risk = EC2 Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = In this support search, we create a table of the earliest and latest times that an ARN has modified a EC2 instance. The list of APIs that modify an EC2 are defined in the <code>ec2ModificationAPIs</code> macro for ease of use. This table is then outputted to a .csv file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs. To add or remove APIs that modify an EC2 instance, edit the macro <code>ec2ModificationAPIs</code>.
action.escu.full_search_name = ESCU - Previously Seen EC2 Modifications By User
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Unusual AWS EC2 Modifications"]
description = This search builds a table of previously seen ARNs that have launched a EC2 instance.
dispatch.earliest_time = -5m@m
dispatch.latest_time = -90d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail `ec2ModificationAPIs` errorCode=success | spath output=arn userIdentity.arn | stats earliest(_time) as firstTime latest(_time) as lastTime by arn | outputlookup previously_seen_ec2_modifications_by_user

[ESCU - Investigate AWS User Activities by user field]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.channel = ESCU
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Investigate AWS User Activities by user field
action.escu.search_type = investigative
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
action.escu.fields_required = ["user"]
action.escu.earliest_time_offset = 14400
action.escu.latest_time_offset = 0
description = This search lists all the logged CloudTrail activities by a specific user and will create a table containing the source of the user, the region of the activity, the name and type of the event, the action taken, and the user's identity information.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=aws:cloudtrail user={user} | table _time userIdentity.type userIdentity.userName userIdentity.arn aws_account_id src awsRegion eventName eventType 

[ESCU - Malicious PowerShell Process - Encoded Command - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-18
action.escu.modification_date = 2017-08-23
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for PowerShell processes that are passing encoded commands on the command-line. The flags "-EncodedCommand" and "-enc" are two different possible flags that can be used to pass base64 encoded commands to PowerShell.  This search will return the host, the user the process ran under, the process and it's command-line arguments, the number of times it's seen this process, and the first and last times it saw this process.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Malicious PowerShell Process - Encoded Command
action.escu.mappings = {"mitre_attack": ["Execution", "PowerShell", "Scripting"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 7", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.kill_chain_phases = ["Command and Control", "Actions on Objectives"]
action.escu.known_false_positives = System administrators may use this option, but it's not common.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Malicious PowerShell"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,cmdline
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for PowerShell processes that have encoded the script within the command-line. Malware has been seen using this parameter, as it obfuscates the code and makes it relatively easy to pass a script on the command-line.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*powershell* (cmdline="*-EncodedCommand*" OR cmdline="*-enc*") | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Get EC2 Launch Details]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.channel = ESCU
action.escu.how_to_implement = In order to implement this search, you must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS(version 4.4.0 or later) and configure your AWS description inputs.
action.escu.full_search_name = ESCU - Get EC2 Launch Details
action.escu.search_type = contextual
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 7200
action.escu.latest_time_offset = 0
description = This search returns some of the launch details for a EC2 instance.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=aws:cloudtrail responseElements.instancesSet.items{}.instanceId={dest} |rename userIdentity.arn as arn, responseElements.instancesSet.items{}.instanceId as instanceId, responseElements.instancesSet.items{}.privateIpAddress as privateIpAddress, responseElements.instancesSet.items{}.imageId as amiID, responseElements.instancesSet.items{}.architecture as architecture, responseElements.instancesSet.items{}.keyName as keyName | table arn, awsRegion, instanceId, architecture, privateIpAddress, amiID, keyName

[ESCU - Attempt To Add Certificate To Untrusted Store - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-09
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = Attackers will often attempt to disable security tools in order to evade detection. It is also possible for end users to attempt to disable anti-virus or other security tools to circumvent restrictions they encounter while trying to execute other programs. One way malware may accomplish this is by adding the legitimate certificate used to sign the security software to the untrusted certificate store. This will cause the system to no longer trust the software signed with this certificate and disallow it from executing. This search simply looks for the execution of <b>certutil.exe</b> with the parameters <code>-addcert</code> and <code>disallowed</code>, which add a certification to the "untrusted" certificate store.
action.escu.how_to_implement = You must be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon Technology Add-on (TA).
action.escu.full_search_name = ESCU - Attempt To Add Certificate To Untrusted Store
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Disabling Security Tools"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.kill_chain_phases = ["Installation", "Actions on Objectives"]
action.escu.known_false_positives = There may be legitimate reasons for administrators to add a certificate to the untrusted certificate store. In such cases, this will typically be done on a large number of systems.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Disabling Security Tools"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = process, dest
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = Attempt to add a certificate to the untrusted certificate store
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=certutil.exe cmdline=*-addstore* cmdline=*disallowed* | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Get Backup Logs For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-14
action.escu.channel = ESCU
action.escu.how_to_implement = You must be ingesting your backup logs.
action.escu.full_search_name = ESCU - Get Backup Logs For Endpoint
action.escu.search_type = contextual
action.escu.providing_technologies = ["Netbackup"]
action.escu.analytic_story = ["Ransomware"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 604800
action.escu.latest_time_offset = 0
description = This search will tell you the backup status from your netbackup_logs of a specific endpoint for the last week.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype="netbackup_logs" COMPUTERNAME={dest} | rename COMPUTERNAME as dest, MESSAGE as signature | table _time, dest, signature

[ESCU - Email Attachments With Lots Of Spaces - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-21
action.escu.modification_date = 2017-09-19
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks at any emails with file attachment names that contain many spaces relative to the length of the file name. Specifically, it checks if spaces make up more than 10% of the number of characters in the file name. This percentage can be tuned for each environment.
action.escu.how_to_implement = You need to ingest data from emails. Specifically, the sender's address and the file names of any attachments must be mapped to the Email data model. The threshold ratio is set to 10%, but this value can be configured to suit each environment.
action.escu.data_models = ["Email"]
action.escu.full_search_name = ESCU - Email Attachments With Lots Of Spaces
action.escu.mappings = {"mitre_attack": [], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 7"], "nist": ["PR.IP"]}
action.escu.kill_chain_phases = ["Delivery"]
action.escu.known_false_positives = None at this time
action.escu.search_type = detection
action.escu.providing_technologies = ["Microsoft Exchange"]
action.escu.analytic_story = ["Suspicious Emails"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_user
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = Attackers often use spaces as a means to obfuscate an attachment's file extension. This search looks for messages with email attachments that have many spaces within the filename.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Email where All_Email.file_name="*" by All_Email.src_user, All_Email.file_name All_Email.message_id | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Email")` | eval space_ratio = (mvcount(split(file_name," "))-1)/len(file_name) | search space_ratio >= 0.1

[ESCU - Previously seen users in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-02-23
action.escu.modification_date = 2018-02-23
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = In this support search, we look for console login events by a particular user and create an initial baseline cache for the previous seven days, including the earliest and latest times a particular user ARN is seen in our dataset, grouped by the ARN value.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user name entries in <code>previously_seen_users_console_logins.csv</code>, which is a lookup file created as a result of running this support search.
action.escu.full_search_name = ESCU - Previously seen users in CloudTrail
action.escu.mappings = {"cis20": ["CIS 16"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["Suspicious AWS Login Activities"]
description = This search looks for CloudTrail events where a user logs into the console, then creates a baseline of the latest and earliest times we have encountered this user in our dataset, grouped by ARN, within the last 30 days.
dispatch.earliest_time = -30d@d
dispatch.latest_time = -5m@m
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=ConsoleLogin | rename userIdentity.arn as arn | stats earliest(_time) as earliest latest(_time) as latest by arn | outputlookup previously_seen_users_console_logins.csv

[ESCU - Prohibited Network Traffic Allowed - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-18
action.escu.modification_date = 2017-09-11
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The search looks for traffic marked 'is_prohibited' in the Enterprise Security lookup table 'interesting_ports_lookup', and then determines if any network devices have an associated 'allow' action on that traffic by checking the Network_Traffic data model.
action.escu.how_to_implement = In order to properly run this search, Splunk needs to ingest data from firewalls or other network control devices that mediate the traffic allowed into an environment. This is necessary so that the search can identify an 'action' taken on the traffic of interest. The search requires the Network_Traffic data model be populated.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Prohibited Network Traffic Allowed
action.escu.mappings = {"mitre_attack": ["Command and Control", "Commonly Used Port", "Exfiltration", "Exfiltration Over Alternative Protocol"], "kill_chain_phases": ["Delivery", "Command and Control"], "cis20": ["CIS 9", "CIS 12"], "nist": ["DE.AE", "PR.AC"]}
action.escu.kill_chain_phases = ["Delivery", "Command and Control"]
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Palo Alto Firewall", "Bro", "Splunk Stream"]
action.escu.analytic_story = ["Prohibited Traffic Allowed or Protocol Mismatch", "Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest_ip,src_ip
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for network traffic defined by port and transport layer protocol in the Enterprise Security lookup table "lookup_interesting_ports", that is marked as prohibited, and has an associated 'allow' action in the Network_Traffic data model. This could be indicative of a misconfigured network device.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Traffic where All_Traffic.action = allowed by All_Traffic.src_ip All_Traffic.dest_ip All_Traffic.dest_port All_Traffic.action | lookup update=true interesting_ports_lookup dest_port as All_Traffic.dest_port OUTPUT app is_prohibited note transport | search is_prohibited=true | `ctime(firstTime)` | `ctime(lastTime)` | `drop_dm_object_name("All_Traffic")`

[ESCU - Get DNS traffic ratio]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-04-10
action.escu.modification_date = 2017-11-09
action.escu.channel = ESCU
action.escu.how_to_implement = You must be ingesting your network traffic
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Get DNS traffic ratio
action.escu.search_type = investigative
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Suspicious DNS Traffic", "Dynamic DNS"]
action.escu.fields_required = ["src_ip", "dest_ip"]
action.escu.earliest_time_offset = 0
action.escu.latest_time_offset = 86400
description = This search calculates the ratio of DNS traffic originating and coming from a host to a list of DNS servers over the last 24 hours. A high value of this ratio could be very useful to quickly understand if a src_ip (host) is sending a high volume of data out via port 53, could be an indicator of data exfiltration via DNS.  
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true sum(All_Traffic.bytes_out) as "bytes_out" sum(All_Traffic.bytes_in) as "bytes_in" from datamodel=Network_Traffic where nodename=All_Traffic All_Traffic.dest_port=53 All_Traffic.src={src_ip} All_Traffic.dest={dest_ip} | eval ratio = (bytes_out/bytes_in) | table ratio

[ESCU - Prohibited Software On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-26
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search returns the number of times, as well as the first and last time, it has seen every process run for each endpoint and user, and then displays only those processes that you have marked as prohibited in the Enterprise Security 'interesting processes' table.
action.escu.how_to_implement = To successfully implement this search, you must ingest information on process activity from your endpoints into Splunk. This can be done using various endpoint detection and response solutions, endpoint data sources such as Sysmon, or via Windows event logs after enabling process tracking in your Windows audit settings. In addition, you must also have processes marked as prohibited in the Enterprise Security <code>interesting processes</code> table. To include the processes marked as prohibited include with ES Content Updates, run the included search <code>Support - Add Prohibited Processes to ES</code>.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Prohibited Software On Endpoint
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Installation", "Command and Control", "Actions on Objectives"], "cis20": ["CIS 2"], "nist": ["ID.AM", "PR.DS"]}
action.escu.kill_chain_phases = ["Installation", "Command and Control", "Actions on Objectives"]
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Monitor for Unauthorized Software"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for applications on the endpoint that you have marked as prohibited.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Application_State by All_Application_State.dest All_Application_State.user All_Application_State.process | `ctime(firstTime)`| `ctime(lastTime)` | `drop_dm_object_name("All_Application_State")` | `prohibited_softwares`

[ESCU - Detect Outbound SMB Traffic - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-20
action.escu.modification_date = 2018-03-20
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = In this search, we are looking for the network connections that were not blocked by the firewall and are destined for destination port 139 or 445. We then filter out events that have Classless Inter-Domain Routing (CIDR) blocks categorized as internal in the <code>assets_by_cidr.csv</code> lookup file which is located in <code>$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/</code>. Since we are only looking for outbound traffic from the hosts made to the Internet, we filter out traffic whose destination IP address is private.
action.escu.how_to_implement = In order to run this search effectively, we highly recommend that you leverage the Assets and Identity framework. It is important that you have good understanding of how your network segments are designed, and be able to distinguish internal from external address space. Add a category named <code>internal</code> to the CIDRs that host the company's assets in <code>assets_by_cidr.csv</code> lookup file, which is located in <code>$SPLUNK_HOME/etc/apps/SA-IdentityManagement/lookups/</code>. More information on updating this lookup can be found <a href="https://docs.splunk.com/Documentation/ES/5.0.0/Admin/Addassetandidentitydata">here</a>. This search also requires you to be ingesting your network traffic and populating the Network_Traffic data model
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Detect Outbound SMB Traffic
action.escu.mappings = {"mitre_attack": ["Commonly Used Port", "Credential Access", "Lateral Movement"], "kill_chain_phases": ["Actions on Objectives", "Command and Control"], "cis20": ["CIS 12"], "nist": ["DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives", "Command and Control"]
action.escu.known_false_positives = It is likely that the outbound SMB traffic is legitimate if the company's internal networks are not well defined in the Assets and Identity Framework. Categorize the internal CIDR blocks as <code>internal</code> in the lookup file to avoid creating notables for traffic destined to those CIDR blocks. Any other network connection that is going out to the Internet should be investigated and blocked. Best practices suggest preventing external communications of all SMB versions and related protocols at the network boundary.
action.escu.search_type = detection
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["DHS Report TA18-074A"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for outbound SMB connections made by hosts within your network to the internet. Server Message Block (SMB) traffic is used for Windows file-sharing activity. One of the techniques often used by attackers involves retrieving the credential hash using an SMB request made to a compromised server controlled by the threat actor.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count earliest(_time) as earliest latest(_time) as latest values(All_Traffic.action) from datamodel=Network_Traffic where All_Traffic.action !=blocked All_Traffic.dest_category !=internal (All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb) by All_Traffic.src_ip All_Traffic.dest_ip | `drop_dm_object_name("All_Traffic")` | search ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | convert ctime(earliest) ctime(latest)

[ESCU - Detect Spike in Security Group Activity - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-17
action.escu.modification_date = 2018-04-18
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search and its corresponding subsearch run through the following series of steps: <ol><li>Retrieves all of the AWS CloudTrail log entries that have recorded AWS API calls specifically for security groups.</li><li>Kicks off a subsearch that retrieves the same data and pulls out the ARN into a more friendly format.</li><li>Counts the number of API calls per ARN.</li><li>Loads the cache file that contains the number of data points, the count from the latest hour, the API call average, and the standard deviation for each ARN.</li><li>Drops the count from the latest hour, since it is not necessary, and merges the rest of the data with the results of the stats command. </li><li>Renames <code>apiCalls</code> as <code>latestCount</code>.</li><li>Calculates the new average value for each ARN with the latest count, weighting the past much more heavily than the current hour. It does the same for the standard deviation&#151;weighting the past more heavily than the current.</li><li>Updates the cache file with the latest results.</li><li>Sets the minimum threshold for the number of data points and sets the number of standard deviations away from the mean it must be to be considered a spike.</li><li>Makes a determination regarding whether or not the current count is a spike by checking to see if the minimum data-point threshold has been met and the count is a sufficient number of standard deviations away from the average.</li><li>Filters out anything that it determines is not a spike and returns the list of ARNs to the main search. </li></ol>The main search subsequently gets the names of all the API calls, the number of unique API calls, and the total number of API calls for each of these ARNs. Finally, it looks up the average and standard deviation and returns both the average and the number of standard deviations the spike is from the average.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. You can modify <code>dataPointThreshold</code> and <code>deviationThreshold</code> to better fit your environment. The <code>dataPointThreshold</code> variable is the minimum number of data points required to have a statistically significant amount of data to determine. The <code>deviationThreshold</code> variable is the number of standard deviations away from the mean that the value must be to be considered a spike.This search works best when you run the "Baseline of Security Group Activity by ARN" support search once to create a history of previously seen Security Group Activity. To add or remove API event names for security groups, edit the macro <code>securityGroupAPIs</code>.
action.escu.full_search_name = ESCU - Detect Spike in Security Group Activity
action.escu.mappings = {"mitre_attack": ["Credential Access", "Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 16"], "nist": ["DE.DP", "DE.CM", "PR.AC"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Based on the values of<code>dataPointThreshold</code> and <code>deviationThreshold</code>, the false positive rate may vary. Please modify this according the your environment.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = user
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = user
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search will detect users creating spikes in API activity related to security groups in your AWS environment.  It will also update the cache file that factors in the latest data.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail `securityGroupAPIs` [search sourcetype=aws:cloudtrail `securityGroupAPIs` | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup security_group_activity_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup security_group_activity_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | stats values(eventName) as eventNames, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user

[ESCU - Open Redirect in Splunk Web - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2016-09-13
action.escu.modification_date = 2017-09-19
action.escu.asset_at_risk = Splunk Server
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks within Splunk's internal logs for evidence of CVE-2016-4859 open redirect exploitation attempts.
action.escu.how_to_implement = No extra steps needed to implement this search.
action.escu.data_models = []
action.escu.full_search_name = ESCU - Open Redirect in Splunk Web
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Exploitation of Vulnerability"], "kill_chain_phases": ["Delivery"], "cis20": ["CIS 3", "CIS 4", "CIS 18"], "nist": ["ID.RA", "RS.MI", "PR.PT", "PR.AC", "PR.IP", "DE.CM"]}
action.escu.kill_chain_phases = ["Delivery"]
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Enterprise"]
action.escu.analytic_story = ["Splunk Enterprise Vulnerability"]
action.notable = 1
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = host
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search allows you to look for evidence of exploitation for CVE-2016-4859, the Splunk Open Redirect Vulnerability.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = index=_internal sourcetype=splunk_web_access return_to="/%09/*"

[ESCU - Suspicious writes to System Volume Information - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-08
action.escu.modification_date = 2018-01-08
action.escu.asset_at_risk = Windows
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search uses data on file writes captured via Sysmon to watch for writes to the "System Volume Information" folder by processes other than the system process. The search looks for event code 11 in the Sysmon events, which indicates a file-creation event. It then looks for a file created with a path that includes "System Volume Information" and a process ID (PID) other than 4. PID 4 is assigned to the System process on Windows systems. Excluding these writes allows us to filter out legitimate activity. It will report the system where the activity occurred, the path to which the file was written, the process responsible for the write, and the times it first and last saw this activity.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Suspicious writes to System Volume Information
action.escu.mappings = {"mitre_attack": ["Collection", "Data Staged"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.known_false_positives = It is possible that other utilities or system processes may legitimately write to this folder. Investigate and modify the search to include exceptions as appropriate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Collection and Staging"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search detects writes to the 'System Volume Information' folder by something other than the System process.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) EventCode=11 process_id!=4 file_path=*System\ Volume\ Information* | stats count min(_time) as firstTime max(_time) as lastTime by dest, Image, file_path | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Registry Keys Used For Persistence - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-23
action.escu.modification_date = 2017-10-10
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search looks for specific registry paths that malware often uses to ensure survivability and persistence on system startup. The search returns the count, the first time activity was seen, last time activity was seen, the registry path that was modified, the host where the modification took place and the user that performed the modification.
action.escu.how_to_implement = To successfully implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Registry Keys Used For Persistence
action.escu.mappings = {"mitre_attack": ["Persistence", "Registry Run Keys / Start Folder", "AppInit DLLs", "Authentication Package"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = There are many legitimate applications that need to start on system startup and will use these registry keys to accomplish that task.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Windows Persistence Techniques", "Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,object_path
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = The search looks for modifications to registry keys that can be used to launch an application or service at system start.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="*currentversion\\run*" OR All_Changes.object_path="*currentVersion\\Windows\\Appinit_Dlls*" OR All_Changes.object_path="*CurrentVersion\\Winlogon\\Shell*" OR All_Changes.object_path="*CurrentVersion\\Winlogon\\Userinit*" OR All_Changes.object_path="*CurrentVersion\\Winlogon\\VmApplet*" OR All_Changes.object_path="*currentversion\\policies\\explorer\\run*" OR All_Changes.object_path="*currentversion\\runservices*" OR All_Changes.object_path="*\\CurrentControlSet\\Control\\Lsa\\*" OR All_Changes.object_path="*Microsoft\\Windows NT\\CurrentVersion\\Image File Execution Options*" OR All_Changes.object_path="HKLM\\SOFTWARE\\Microsoft\\Netsh\\*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes")`

[ESCU - SMB Traffic Spike - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-20
action.escu.modification_date = 2017-09-10
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = SMB traffic is used for Windows file sharing activity. The WannaCry ransomware leveraged a vulnerability in the SMB protocol to propagate to other systems. A spike in SMB traffic could indicate an infected host attempting to spread ransomware to other hosts in your environment. This search could also be effective for other situations where SMB is used to automate the spread of ransomware or malware throughout an environment. If there is a large spike in SMB traffic, you may want to investigate the source and analyze the cause for the abnormal traffic.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - SMB Traffic Spike
action.escu.mappings = {"mitre_attack": ["Commonly Used Port"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = A file server could experience high demand loads that could cause this analytic to trigger.
action.escu.search_type = detection
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["DHS Report TA18-074A", "Ransomware"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for spike in the number of Server Message Block (SMB) traffic connections
dispatch.earliest_time = -7d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count from datamodel=Network_Traffic where All_Traffic.dest_port=139 OR All_Traffic.dest_port=445 OR All_Traffic.app=smb by _time span=1h, All_Traffic.src | `drop_dm_object_name("All_Traffic")` | eventstats max(_time) as maxtime | stats count as num_data_samples max(eval(if(_time >= relative_time(maxtime, "-1h@h"), count, null))) as count avg(eval(if(_time<relative_time(maxtime, "-1h@h"), count, null))) as avg stdev(eval(if(_time<relative_time(maxtime, "-1h@h"), count, null))) as stdev by src | eval upperBound=(avg+stdev*2), isOutlier=if(count > upperBound AND num_data_samples >=50, 1, 0) | where isOutlier=1 | table src count

[ESCU - Email files written outside of the Outlook directory - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-12-13
action.escu.modification_date = 2017-12-19
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = In this search, we are trying to detect activities that adversaries are known to perform with respect to collecting email data from local machines. The search will detect email files, files with .pst or .ost extensions, that are created in directories other than the standard Outlook directory which is C:\Users\username\My Documents\Outlook Files\.
action.escu.how_to_implement = In order to implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection-and-response products&#151;such as Carbon Black&#151;or other endpoint data sources, such as Sysmon. The data used for this search is typically generated via logs that report file system reads and writes.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Email files written outside of the Outlook directory
action.escu.mappings = {"mitre_attack": ["Collection", "Email Collection"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Administrators and users sometimes prefer backing up their email data by moving the email files into a different folder. These attempts will be detected by the search.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Collection and Staging"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, file_path
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = The search looks at the Change Analysis data model and detects email files that are created outside the normal Outlook directory.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count values(All_Changes.Endpoint_Changes.Filesystem_Changes.file_path) as file_path min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis where (All_Changes.Endpoint_Changes.Filesystem_Changes.file_name=*.pst OR All_Changes.Endpoint_Changes.Filesystem_Changes.file_name=*.ost) All_Changes.Endpoint_Changes.Filesystem_Changes.file_path != "C:\\Users\\*\\My Documents\\Outlook Files\\*" by All_Changes.action All_Changes.Endpoint_Changes.Filesystem_Changes.file_name All_Changes.dest | `ctime(lastTime)` | `ctime(firstTime)` | `drop_dm_object_name("All_Changes")` | `drop_dm_object_name("Endpoint_Changes.Filesystem_Changes")`

[ESCU - Identify New User Accounts - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-05
action.escu.modification_date = 2017-09-12
action.escu.asset_at_risk = Domain Server
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Adversaries will often seek to create new user accounts as a means of maintaining access to a target environment. Using this search, we identify accounts created in the last week by comparing the start date in the Identity_Management data model against the current time.
action.escu.how_to_implement = To successfully implement this search, you need to be populating the Enterprise Security Identity_Management data model in the assets and identity framework.
action.escu.data_models = ["Identity_Management"]
action.escu.full_search_name = ESCU - Identify New User Accounts
action.escu.mappings = {"mitre_attack": ["Valid Accounts"], "cis20": ["CIS 16"], "nist": ["PR.IP"]}
action.escu.known_false_positives = If the Identity_Management data model is not updated regularly, this search could give you false positive alerts. Please consider this and investigate appropriately.
action.escu.search_type = detection
action.escu.providing_technologies = ["Active Directory"]
action.escu.analytic_story = ["Account Monitoring and Controls"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = user
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 40
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = identity
alert.suppress.period = 86400s
cron_schedule = 0 0 * * *
description = This detection search will help profile user accounts in your environment by identifying newly created accounts that have been added to your network in the past week.
dispatch.earliest_time = -24h@h
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | from datamodel Identity_Management.All_Identities  | eval empStatus=case((now()-startDate)<604800, "Accounts created in last week") | search empStatus="Accounts created in last week"| `ctime(endDate)` | `ctime(startDate)`| table identity empStatus endDate startDate

[ESCU - Attempt To Stop Security Service - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search looks for the processes <b>net.exe</b> and <b>sc.exe</b> with a parameter of <code>"stop"</code>. It then searches a list of security-related services included in a lookup file for matches on the command line. Results are subsequently returned in table format. The included lookup file can be modified to update the services to monitor.
action.escu.how_to_implement = You must be ingesting logs with both the process name and command line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA. The search is shipped with a lookup file, <code>security_services.csv</code>, that can be edited to update the list of services to monitor. This lookup file can be edited directly where it lives in <code>$SPLUNK_HOME/etc/apps/DA-ESS-ContentUpdate/lookups</code>, or via the Splunk console. You should add the names of services an attacker might use on the command line and surround with asterisks (<b>*</b>), so that they work properly when searching the command line. The file should be updated with the names of any services you would like to monitor for attempts to stop the service.,
action.escu.full_search_name = ESCU - Attempt To Stop Security Service
action.escu.mappings = {"mitre_attack": ["Defense Evasion", "Disabling Security Tools"], "kill_chain_phases": ["Installation", "Actions on Objectives"], "cis20": ["CIS 3", "CIS 5", "CIS 8"], "nist": ["PR.PT", "DE.CM", "PR.IP"]}
action.escu.kill_chain_phases = ["Installation", "Actions on Objectives"]
action.escu.known_false_positives = None identified. Attempts to disable security-related services should be identified and understood.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Disabling Security Tools"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for attempts to stop security-related services on the endpoint.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational (process=net.exe OR process=sc.exe) cmdline="* stop *" | lookup security_services_lookup service as cmdline OUTPUTNEW category, description | search category=security | table _time, dest, user, parent_process, cmdline, description

[ESCU - Extended Period Without Succesful Netbackup Backups - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-15
action.escu.modification_date = 2017-09-12
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search finds all the successful backup messages in your logs, and then looks for the most recent backup time for each system. It then identifies those systems where the the most recent successful backup time is over a week ago, and reports on them.
action.escu.how_to_implement = To successfully implement this search you need to first obtain data from your backup solution, either from the backup logs on your hosts, or from a central server responsible for performing the backups. If you do not use Netbackup, you can modify this search for your backup solution. Depending on how often you backup your systems, you may want to modify how far in the past to look for a successful backup, other than the default of seven days.
action.escu.full_search_name = ESCU - Extended Period Without Succesful Netbackup Backups
action.escu.mappings = {"cis20": ["CIS 10"], "nist": ["PR.IP"]}
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Netbackup"]
action.escu.analytic_story = ["Monitor Backup Solution"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 10
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 86400s
cron_schedule = 0 0 1 * *
description = This search returns a list of hosts that have not successfully completed a backup in over a week.
dispatch.earliest_time = -7d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype="netbackup_logs" MESSAGE="Disk/Partition backup completed successfully." | stats latest(_time) as latestTime by COMPUTERNAME | `ctime(latestTime)` | rename COMPUTERNAME as dest | eval isOutlier=if(latestTime <= relative_time(now(), "-7d@d"), 1, 0) | search isOutlier=1 | table latestTime, dest

[ESCU - Previously seen API call per user roles in CloudTrail]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-01
action.escu.modification_date = 2018-04-16
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = In this support search, we are looking for successful API calls made by user roles within your AWS infrastructure. The intent is to create an initial baseline cache of names of the API calls per security role for the previous 30 days&#151;including the earliest and latest times seen in our dataset&#151;grouped by the value of user role and the name of the API call. It is also worth noting that the role of a particular user is parsed as "userName" in the CloudTrail logs.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. Please validate the user role entries in <code>previously_seen_api_calls_from_user_roles.csv</code>, which is a lookup file created as a result of running this support search.
action.escu.full_search_name = ESCU - Previously seen API call per user roles in CloudTrail
action.escu.mappings = {"cis20": ["CIS 16"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
description = This search looks for successful API calls made by different user roles, then creates a baseline of the earliest and latest times we have encountered this user role. It also returns the name of the API call in our dataset&#151;grouped by user role and name of the API call&#151;that occurred within the last 30 days. In this support search, we are only looking for events where the user identity is Assumed Role.
dispatch.earliest_time = -30d@d
dispatch.latest_time = -5m@m
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventType=AwsApiCall errorCode=success userIdentity.type=AssumedRole | stats earliest(_time) as earliest latest(_time) as latest by userName eventName | outputlookup previously_seen_api_calls_from_user_roles

[ESCU - Uncommon Processes On Endpoint - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-12-08
action.escu.modification_date = 2018-04-16
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search returns the number of times, as well as the first and last time, it has seen every process run for each endpoint and user, and then displays only those processes that you have marked as prohibited in the Enterprise Security 'interesting processes' table.
action.escu.how_to_implement = To successfully implement this search, you must ingest information on process activity from your endpoints into Splunk. This can be done using various endpoint detection and response solutions, endpoint data sources such as Sysmon, or via Windows event logs after enabling process tracking in your Windows audit settings.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Uncommon Processes On Endpoint
action.escu.mappings = {"mitre_attack": ["Execution", "Accessibility Features"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 2"], "nist": ["ID.AM", "PR.DS"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = None identified
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Privilege Escalation", "Unusual Processes"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, user
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for applications on the endpoint that you have marked as prohibited.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Application_State by All_Application_State.dest All_Application_State.user All_Application_State.process | `ctime(firstTime)`| `ctime(lastTime)` | `drop_dm_object_name("All_Application_State")` | `uncommon_processes`

[ESCU - Registry Keys for Creating SHIM Databases - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-27
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = In this search, we look for modifications to registry keys used for shim databases on Microsoft platforms via the object_category and object_path field in the Change_Analysis data model and give you the destination, command used to initiate the change, the user who conducted this activity, the resource affected(object), and the whole path of the object. An application compatibility shim is a small library that transparently intercepts an API (via hooking), changes the parameters passed, handles the operation itself, or redirects the operation elsewhere, such as additional code stored on a system. This capability can be also leveraged by attackers to create and store malicious files in a shim database as observed in CARBANAK backdoor.
action.escu.how_to_implement = To successfully implement this search, you must populate the Change_Analysis data model. This is typically populated via endpoint detection and response products, such as Carbon Black or other endpoint data sources such as Sysmon. The data used for this search is typically generated via logs that report reads and writes to the registry.
action.escu.data_models = ["Change_Analysis"]
action.escu.full_search_name = ESCU - Registry Keys for Creating SHIM Databases
action.escu.mappings = {"mitre_attack": ["Persistence", "Application Shimming"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = There are many legitimate applications that leverage shim databases for compatibility purposes for legacy applications
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon"]
action.escu.analytic_story = ["Windows Persistence Techniques"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,object_path
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for registry activity associated with application compatibility shims, which can be leveraged by attackers for various nefarious purposes.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime FROM datamodel=Change_Analysis.All_Changes where All_Changes.object_category=registry AND (All_Changes.object_path="*CurrentVersion\\AppCompatFlags\\Custom*" OR All_Changes.object_path="*CurrentVersion\\AppCompatFlags\\InstalledSDB*") by All_Changes.dest, All_Changes.command, All_Changes.user, All_Changes.object, All_Changes.object_path | `drop_dm_object_name("All_Changes")`

[ESCU - Detect Prohibited Applications Spawning cmd.exe - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-10-07
action.escu.modification_date = 2017-10-23
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Obtaining access to the Command-Line Interface (CLI) is typically a primary attacker goal. Once an attacker has obtained the ability to execute code on a target system, they will often further manipulate the system via commands passed to the CLI. It is also unusual for many applications to spawn a command shell during normal operation, while it is often observed if an application has been compromised in some way. As such, it is often beneficial to look for cmd.exe being executed by processes that are often targeted for exploitation, or that would not spawn cmd.exe in any other circumstances. A lookup file is provided to easily modify the processes that are being watched for execution of cmd.exe.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with both the process name and parent process from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA. This search includes a lookup file, <code>prohibited_apps_launching_cmd.csv</code>, that contains a list of processes which should not be spawning cmd.exe. You can modify this lookup to better suit your environment.
action.escu.full_search_name = ESCU - Detect Prohibited Applications Spawning cmd.exe
action.escu.mappings = {"mitre_attack": ["Execution", "Command-Line Interface"], "kill_chain_phases": ["Exploitation"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Exploitation"]
action.escu.known_false_positives = There are circumstances where an application may legitimately execute and interact with the Windows CLI. Investigate and modify the lookup file as appropriate.
action.escu.search_type = detection
action.escu.providing_technologies = ["Sysmon"]
action.escu.analytic_story = ["Suspicious Command-Line Executions"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 80
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, parent_process
alert.suppress.period = 86400s
cron_schedule = 0 * * * *
description = This search looks for executions of cmd.exe spawned by a process that is often abused by attackers and does not typically launch cmd.exe.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational signature_id=1 process=*cmd.exe [`prohibited_apps_launching_cmd`] | rename parent_process as "Potentially Malicious Parent Process" | rename cmdline as "Commands executed" | table _time dest process "Potentially Malicious Parent Process" "Commands executed"

[ESCU - Remote Process Instantiation via WMI - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-01-13
action.escu.modification_date = 2017-09-15
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = Attackers are increasingly abusing native Windows utilities such as wmic.exe as a means to "live off the land", and avoid introducing new executables to the target system. In this search, we are looking for instances of wmic.exe being run with various parameters that are not typically used by administrators.
action.escu.how_to_implement = To successfully implement this search you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Remote Process Instantiation via WMI
action.escu.mappings = {"mitre_attack": ["Execution", "Windows Management Instrumentation"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 5"], "nist": ["PR.PT", "PR.AT", "PR.AC", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = The wmic.exe utility is a benign Windows application. It may be used legitimately by Administrators with these parameters for remote system administration, but it's relatively uncommon.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Suspicious WMI Use"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 70
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for wmic.exe being launched with parameters to spawn a process on a remote system.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) process=*wmic* cmdline="*/node*" cmdline="*process*" cmdline="*call*" cmdline="*create*" | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)`

[ESCU - Windows Updates Install Successes]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-24
action.escu.modification_date = 2017-09-14
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search gives you the count and name of all the systems that had a successful update applied each day
action.escu.how_to_implement = You must be ingesting your Windows Update Logs
action.escu.data_models = ["Updates"]
action.escu.full_search_name = ESCU - Windows Updates Install Successes
action.escu.search_type = support
action.escu.providing_technologies = ["Microsoft Windows"]
action.escu.analytic_story = ["Ransomware"]
description = This search is intended to give you a feel for how often successful Windows updates are applied in your environments. Fluctuations in these numbers will allow you to determine when you should be concerned.
dispatch.earliest_time = -30d
dispatch.latest_time = now
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` dc(Updates.dest) as count FROM datamodel=Updates where Updates.vendor_product="Microsoft Windows" AND Updates.status=installed by _time span=1d

[ESCU - Execution of File with Multiple Extensions - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-01-26
action.escu.modification_date = 2018-01-26
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search uses the Application State data model to look for process names that have specific combinations of double extensions. The search is relatively straightforward and simply looks for string matches in the process field that match what we're looking for.
action.escu.how_to_implement = To successfully implement this search, you need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.data_models = ["Application_State"]
action.escu.full_search_name = ESCU - Execution of File with Multiple Extensions
action.escu.mappings = {"mitre_attack": ["Execution", "Persistence", "Change Default File Association"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 3", "CIS 8"], "nist": ["DE.CM", "PR.PT", "PR.IP"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = None identified.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows File Extension and Association Abuse"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 60
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest, process, object_path
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = This search looks for processes launched from files that have 2 extensions in the file name. This is typically done to obscure the "real" file extension and make it appear as though the file being accessed is a data file as opposed to executable content.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Application_State where All_Application_State.process = "*.doc.exe" OR All_Application_State.process = "*.htm.exe" OR All_Application_State.process = "*.html.exe" OR All_Application_State.process = "*.txt.exe" OR All_Application_State.process = "*.pdf.exe" OR All_Application_State.process = "*.doc.exe" by All_Application_State.dest All_Application_State.user All_Application_State.process | `ctime(firstTime)`| `ctime(lastTime)` | `drop_dm_object_name("All_Application_State")`

[ESCU - Get Parent Process Info]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-22
action.escu.modification_date = 2017-09-10
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search you must be ingesting endpoint data via Microsoft-Windows-Sysmon and extract the Image and Parent Image field.
action.escu.full_search_name = ESCU - Get Parent Process Info
action.escu.search_type = investigative
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Windows Defense Evasion Tactics", "Windows Privilege Escalation", "Collection and Staging", "DHS Report TA18-074A", "Windows File Extension and Association Abuse", "Windows Persistence Techniques", "Disabling Security Tools", "Ransomware", "Suspicious Command-Line Executions", "Netsh Abuse", "Windows Service Abuse"]
action.escu.fields_required = ["process", "dest"]
action.escu.earliest_time_offset = 0
action.escu.latest_time_offset = 86400
description = This search queries the Application State data model to give you details about the parent process of a process running on a host which is under investigation. Enter the values of the process name in question and the dest_ip
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | search sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational process={process} dest={dest} | table parent_process parent_process_id

[ESCU - DNSTwist Domain Names]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-01
action.escu.modification_date = 2017-09-20
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search starts with the dnstwist command that takes the domains specified in the files  cim_corporate_email_domains.csv and cim_corporate_web_domains.csv from Splunk_SA_CIM and creates permutations of these domains. You can also add other domains to a file called domains.csv in the DA-ESS-SOC/lookups directory. This search then adds a domain_abuse=true term to each permutation and stores all that information into a lookup file that is used in the associated detection search.
action.escu.how_to_implement = To successfully implement this search you need to update the files cim_corporate_email_domains.csv and cim_corporate_web_domains.csv from Splunk_SA_CIM, as well as the file domains.csv from the DA-ESS-ContentUpdate lookup directory to include the domains you would like to monitor. Each domain only needs to appear once across all the files. Beginner's tip: To avoid using the command-line interface (CLI) user the Lookup File Editor.
action.escu.data_models = []
action.escu.full_search_name = ESCU - DNSTwist Domain Names
action.escu.search_type = support
action.escu.providing_technologies = ["Splunk Enterprise"]
action.escu.analytic_story = ["Brand Monitoring", "Brand Monitoring"]
description = This search creates permutations of your existing domains and stores them in a specified lookup file so they can be checked for in the associated detection searches.
dispatch.earliest_time = now
dispatch.latest_time = -30d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | dnstwist domainlist=domains.csv | eval domain_abuse="true" | table domain, domain_abuse | outputlookup brandMonitoring_lookup

[ESCU - Detection of DNS Tunnels - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-07-19
action.escu.modification_date = 2017-09-18
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = low
action.escu.eli5 = The search will calculate the distinct count and sum of the length of DNS queries made and DNS answers received by a particular host to alert the analyst if the combined length is greater than 10000, which is not typical behavior.
action.escu.how_to_implement = To successfully implement this search, we must ensure that DNS data is being ingested and mapped to the appropriate fields in the Network_Resolution data model. Fields like src_category are automatically provided by the Assets and Identity Framework shipped with Splunk Enterprise Security. You will need to ensure you are using the Assets and Identity Framework and populating the src_category field. You will also need to enable the `cim_corporate_web_domain_search()` macro which will essentially filter out the DNS queries made to the corporate web domains to reduce alert fatigue.
action.escu.data_models = ["Network_Resolution"]
action.escu.full_search_name = ESCU - Detection of DNS Tunnels
action.escu.mappings = {"mitre_attack": ["Command and Control", "Exfiltration", "Commonly Used Port"], "kill_chain_phases": ["Command and Control", "Actions on Objectives"], "cis20": ["CIS 13"], "nist": ["PR.PT", "PR.DS"]}
action.escu.kill_chain_phases = ["Command and Control", "Actions on Objectives"]
action.escu.known_false_positives = It's possible that normal DNS traffic will exhibit this behavior. If an alert is generated, please investigate and validate as appropriate. The threshold can also be modified to better suit your environment.
action.escu.search_type = detection
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Suspicious DNS Traffic", "Data Protection"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = 
action.risk.param._risk_object_type = 
action.risk.param._risk_score = 20
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src,query
alert.suppress.period = 43200s
cron_schedule = 0 * * * *
description = This search is used to detect DNS tunneling, by calculating the sum of the length of DNS queries and DNS answers. The search also filters out potential false positives by filtering out queries made to internal systems and the queries originating from internal DNS, Web, and Email servers. Endpoints using DNS as a method of transmission for data exfiltration, command and control, or evasion of security controls can often be detected by noting an unusually large volume of DNS traffic.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true dc("DNS.query") as count  from datamodel=Network_Resolution  where nodename=DNS "DNS.message_type"="QUERY" NOT (`cim_corporate_web_domain_search("DNS.query")`) NOT "DNS.query"="*.in-addr.arpa" NOT ("DNS.src_category"="svc_infra_dns" OR "DNS.src_category"="svc_infra_webproxy" OR "DNS.src_category"="svc_infra_email*"   ) by "DNS.src","DNS.query" | rename "DNS.src" as src  "DNS.query" as message | eval length=len(message) | stats sum(length) as length by src | append [ tstats allow_old_summaries=true dc("DNS.answer") as count  from datamodel=Network_Resolution  where nodename=DNS "DNS.message_type"="QUERY" NOT (`cim_corporate_web_domain_search("DNS.query")`) NOT "DNS.query"="*.in-addr.arpa" NOT ("DNS.src_category"="svc_infra_dns" OR "DNS.src_category"="svc_infra_webproxy" OR "DNS.src_category"="svc_infra_email*"   ) by "DNS.src","DNS.answer" | rename "DNS.src" as src  "DNS.answer" as message | eval message=if(message=="unknown","", message) | eval length=len(message) | stats sum(length) as length by src ] | stats sum(length) as length by src | where length > 10000

[ESCU - Baseline of API Calls per User ARN]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-09
action.escu.modification_date = 2018-04-09
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = This search returns all log events that are API calls, pulls out the ARN that initiated each call, and collects them in one-hour groupings. Next, it calculates the number of API calls made per ARN per hour. For each ARN, it calculates the average and standard deviation of this count on a per-hour basis.  It also includes the number of data points each ARN had. This table is then stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your CloudTrail inputs.
action.escu.full_search_name = ESCU - Baseline of API Calls per User ARN
action.escu.mappings = {"cis20": ["CIS 16"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS User Monitoring"]
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of API calls made by each user. Also recorded is the number of data points for each user. This table is then outputted to a lookup file to allow the detection search to operate quickly.
dispatch.earliest_time = now
dispatch.latest_time = -90d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventType=AwsApiCall | spath output=arn path=userIdentity.arn | bucket _time span=1h | stats count as apiCalls by _time, arn | stats count(apiCalls) as numDataPoints, latest(apiCalls) as latestCount, avg(apiCalls) as avgApiCalls, stdev(apiCalls) as stdevApiCalls by arn | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup api_call_by_user_baseline

[ESCU - Unusually Long Command Line - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-08-23
action.escu.modification_date = 2017-09-10
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search calculates the average and standard deviation for the length of the command-lines on each of your endpoints and alerts when a command-line is found with a length over 10 times the standard deviation larger than the average command-line.
action.escu.how_to_implement = You need to be ingesting logs with both the process name and command-line from your endpoints. If you are using Sysmon, you must have at least version 6.0.4 of the Sysmon TA.
action.escu.full_search_name = ESCU - Unusually Long Command Line
action.escu.mappings = {"mitre_attack": ["Execution"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 8"], "nist": ["PR.PT", "DE.CM"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = Some legitimate applications start with long command-lines.
action.escu.search_type = detection
action.escu.providing_technologies = ["Carbon Black Response", "CrowdStrike Falcon", "Sysmon", "Tanium", "Ziften"]
action.escu.analytic_story = ["Ransomware", "Suspicious Command-Line Executions", "Unusual Processes"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest,user,cmdline
alert.suppress.period = 28800s
cron_schedule = 0 * * * *
description = Command-lines that are extremely long can be indicative of malicious activity on your hosts.
dispatch.earliest_time = -7d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = (sourcetype=XmlWinEventLog:Microsoft-Windows-Sysmon/Operational OR tag=process) | stats count min(_time) as firstTime max(_time) as lastTime by dest, user, process, cmdline | `ctime(firstTime)`| `ctime(lastTime)` | eval cmdlen=len(cmdline) | eventstats stdev(cmdlen) as stdev, avg(cmdlen) as avg by dest | stats max(cmdlen) as maxlen, values(stdev) as stdevperhost, values(avg) as avgperhost by dest, process | where maxlen > ((10*stdevperhost) + avgperhost)

[ESCU - Baseline of blocked outbound traffic from AWS]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-04-26
action.escu.modification_date = 2018-05-07
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = high
action.escu.eli5 = Use this search to create a baseline of blocked outbound network connections by each source IP in your AWS environment. This search returns all log events that correspond to a blocked outbound network connection, extracts the source IP from where the outbound connection was initiated, and collects the events in one-hour groupings. Next, it calculates the number of outbound connections blocked per hour. For each source IP, it calculates the average and standard deviation of this count on a per-hour basis.  It also includes the number of data points each source IP had. This table is then stored in a lookup file.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS version (4.4.0 or later), then configure your <code>VPC flow logs.</code>.
action.escu.full_search_name = ESCU - Baseline of blocked outbound traffic from AWS
action.escu.mappings = {"cis20": ["CIS 16"], "nist": ["PR.AC", "PR.DS", "DE.AE"]}
action.escu.search_type = support
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Network ACL Activity", "Suspicious AWS Traffic"]
description = This search establishes, on a per-hour basis, the average and the standard deviation of the number of outbound connections blocked in your VPC flow logs by each source IP address (IP address of your EC2 instances). Also recorded is the number of data points for each source IP. This table outputs to a lookup file to allow the detection search to operate quickly.
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
disabled=true
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudwatchlogs:vpcflow action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16) | bucket _time span=1h | stats count as numberOfBlockedConnections by _time, src_ip | stats count(numberOfBlockedConnections) as numDataPoints, latest(numberOfBlockedConnections) as latestCount, avg(numberOfBlockedConnections) as avgBlockedConnections, stdev(numberOfBlockedConnections) as stdevBlockedConnections by src_ip | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections| outputlookup baseline_blocked_outbound_connections

[ESCU - Count of Unique IPs Connecting to Ports]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-24
action.escu.modification_date = 2017-09-13
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = For each port being accessed on the network, this search gives the total number of connections observed, and the number of unique IP addresses making those connections.
action.escu.how_to_implement = To successfully implement this search, you must be ingesting network traffic, and populating the Network_Traffic data model.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Count of Unique IPs Connecting to Ports
action.escu.mappings = {"cis20": ["CIS 9"]}
action.escu.search_complexity_score = 3
action.escu.search_type = support
action.escu.providing_technologies = ["Splunk Stream", "Bro"]
action.escu.analytic_story = ["Prohibited Traffic Allowed or Protocol Mismatch"]
action.escu.fields_required = ["src", "dest_port"]
description = The search counts the number of times a connection was observed to each destination port, and the number of unique source IPs connecting to them.
dispatch.earliest_time = now
dispatch.latest_time = -30d@d
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats `summariesonly` count dc(All_Traffic.src) as numberOfUniqueHosts from datamodel=Network_Traffic by All_Traffic.dest_port | `drop_dm_object_name("All_Traffic")` | sort - count

[ESCU - EC2 Instance Started With Previously Unseen Instance Type - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2018-03-12
action.escu.modification_date = 2018-03-12
action.escu.asset_at_risk = AWS Instance
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = The subsearch returns the instance types of all successful EC2 instance launches within the last hour and then appends the historical data in the lookup file to those results.  It then recalculates the earliest seen time field for each instance type and returns only those instance types that has first been seen in the past hour.  This is combined with the main search to return the time, user, and instance id of those systems.
action.escu.how_to_implement = You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudTrail inputs. This search works best when you run the "Previously Seen EC2 Instance Types" support search once to create a history of previously seen instance types.
action.escu.full_search_name = ESCU - EC2 Instance Started With Previously Unseen Instance Type
action.escu.mappings = {"cis20": ["CIS 1"], "nist": ["ID.AM"]}
action.escu.known_false_positives = It is possible that an admin will create a new system using a new instance type never used before. Verify with the creator that they intended to create the system with the new instance type.
action.escu.search_type = detection
action.escu.providing_technologies = ["AWS"]
action.escu.analytic_story = ["AWS Cryptomining"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = dest
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 30
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = dest
alert.suppress.period = 14400s
cron_schedule = 0 * * * *
description = This search looks for EC2 instances being created with previously unseen instance types.
dispatch.earliest_time = -65m@m
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = sourcetype=aws:cloudtrail eventName=RunInstances [search sourcetype=aws:cloudtrail eventName=RunInstances errorCode=success | fillnull value="m1.small" requestParameters.instanceType | stats earliest(_time) as earliest latest(_time) as latest by requestParameters.instanceType | rename requestParameters.instanceType as instanceType | inputlookup append=t previously_seen_ec2_instance_types.csv | stats min(earliest) as earliest max(latest) as latest by instanceType | outputlookup previously_seen_ec2_instance_types.csv | eval newType=if(earliest >= relative_time(now(), "-65m@m"), 1, 0) | convert ctime(earliest) ctime(latest) | where newType=1 | rename instanceType as requestParameters.instanceType | table requestParameters.instanceType] | spath output=user userIdentity.arn | rename requestParameters.instanceType as instanceType, responseElements.instancesSet.items{}.instanceId as dest | table _time, user, dest, instanceType

[ESCU - Get Risk Modifiers For Endpoint]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-10-14
action.escu.modification_date = 2017-10-19
action.escu.channel = ESCU
action.escu.how_to_implement = Enable the correlation searches included in Splunk Enterprise Security that include Risk Analysis alert actions by leveraging the Risk Analysis Framework
action.escu.data_models = ["Risk"]
action.escu.full_search_name = ESCU - Get Risk Modifiers For Endpoint
action.escu.search_type = contextual
action.escu.providing_technologies = ["Splunk Enterprise Security"]
action.escu.analytic_story = ["Monitor for Updates", "Router & Infrastructure Security", "Windows Log Manipulation", "Monitor Backup Solution", "Host Redirection", "Windows Privilege Escalation", "Malicious PowerShell", "Lateral Movement", "JBoss Vulnerability", "Asset Tracking", "Monitor for Unauthorized Software", "Prohibited Traffic Allowed or Protocol Mismatch", "DNS Amplification Attacks", "Collection and Staging", "Spectre And Meltdown Vulnerabilities", "DHS Report TA18-074A", "Windows File Extension and Association Abuse", "Suspicious DNS Traffic", "Suspicious Emails", "Windows Persistence Techniques", "Account Monitoring and Controls", "Use of Cleartext Protocols", "Disabling Security Tools", "Splunk Enterprise Vulnerability", "SQL Injection", "Data Protection", "Dynamic DNS", "Ransomware", "Brand Monitoring", "Apache Struts Vulnerability", "Suspicious WMI Use", "Netsh Abuse", "Unusual Processes", "Windows Service Abuse"]
action.escu.fields_required = ["dest"]
action.escu.earliest_time_offset = 604800
action.escu.latest_time_offset = 0
description = For the last 7 days, the search will query the Risk data model in Splunk Enterprise Security and calculate the count, sum of the risk_scores, names of the correlation searches that contributed to create a risk score for a specific endpoint(machine_name) 
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | from datamodel:Risk.All_Risk | search risk_object_type=system risk_object={dest} | stats count sum(risk_score) as risk_score values(search_name)  min(_time) as firstTime max(_time) as lastTime by risk_object | `ctime(firstTime)` | `ctime(lastTime)`

[ESCU - Hosts receiving high volume of network traffic from email server - Rule]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-12-20
action.escu.modification_date = 2017-12-20
action.escu.asset_at_risk = Endpoint
action.escu.channel = ESCU
action.escu.confidence = medium
action.escu.eli5 = This search may look complex, but it's a neat representation of how statistics can help you understand your dataset to bubble up events that are not normal compared to its behavior. The search consists of three parts. The first part of the SPL fetches the data you want to work on. In this search, we calculate the sum of bytes sent and bytes_out from systems categorized as email_server to each host. We then calculate the average and standard deviation for the bytes sent to all the hosts combined and on a per-host basis. Then we set threshold values to deviation_threshold and minimum_data_samples using eval statements. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.  We then check for byte transfers that are statistically significantly higher than normal. The search then gives IP address of the host, the time of the increased byte transfer, how much data was transferred, and the average amount of data transfer the email server normally sends to all hosts and to this specific host. Finally, it includes the number of standard deviations away the byte count was from these averages.
action.escu.how_to_implement = This search requires you to be ingesting your network traffic and populating the Network_Traffic data model.  Your email servers must be categorized as "email_server" for the search to work, as well. You may need to adjust the deviation_threshold and minimum_data_samples values based on the network traffic in your environment. The "deviation_threshold" field is a multiplying factor to control how much variation you're willing to tolerate. The "minimum_data_samples" field is the minimum number of connections of data samples required for the statistic to be valid.
action.escu.data_models = ["Network_Traffic"]
action.escu.full_search_name = ESCU - Hosts receiving high volume of network traffic from email server
action.escu.mappings = {"mitre_attack": ["Collection", "Commonly Used Port"], "kill_chain_phases": ["Actions on Objectives"], "cis20": ["CIS 7"], "nist": ["PR.PT", "DE.CM", "DE.AE"]}
action.escu.kill_chain_phases = ["Actions on Objectives"]
action.escu.known_false_positives = The false-positive rate will vary based on how you set the deviation_threshold and data_samples values. Our recommendation is to adjust these values based on your network traffic to and from your email servers.
action.escu.search_type = detection
action.escu.providing_technologies = ["Bro", "Splunk Stream"]
action.escu.analytic_story = ["Collection and Staging"]
action.notable = 1
action.risk = 1
action.risk.param._risk_object = src_ip
action.risk.param._risk_object_type = system
action.risk.param._risk_score = 50
action.risk.param.verbose = 0
alert.digest_mode = 1
alert.suppress = 1
alert.suppress.fields = src_ip
alert.suppress.period = 86400s
cron_schedule = 0 0 * * *
description = This search looks for an increase of data transfers from your email server to your clients. This could be indicative of a malicious actor collecting data using your email server.
dispatch.earliest_time = -30d@d
dispatch.latest_time = -5m@m
disabled=true
enableSched = 1
counttype = number of events
relation = greater than
quantity = 0
realtime_schedule = 0
schedule_window = auto
search = | tstats summariesonly=t allow_old_summaries=t sum(All_Traffic.bytes_in) as bytes_in from datamodel=Network_Traffic where All_Traffic.dest_category=email_server by All_Traffic.src_ip _time span=1d | `drop_dm_object_name("All_Traffic")` | eventstats avg(bytes_in) as avg_bytes_in stdev(bytes_in) as stdev_bytes_in | eventstats count as num_data_samples avg(eval(if(_time < relative_time(now(), "@d"), bytes_in, null))) as per_source_avg_bytes_in stdev(eval(if(_time < relative_time(now(), "@d"), bytes_in, null))) as per_source_stdev_bytes_in by src_ip | eval minimum_data_samples = 4, deviation_threshold = 3 | where num_data_samples >= minimum_data_samples AND bytes_in > (avg_bytes_in + (deviation_threshold * stdev_bytes_in)) AND bytes_in > (per_source_avg_bytes_in + (deviation_threshold * per_source_stdev_bytes_in)) AND _time >= relative_time(now(), "@d") | eval num_standard_deviations_away_from_server_average = round(abs(bytes_in - avg_bytes_in) / stdev_bytes_in, 2), num_standard_deviations_away_from_client_average = round(abs(bytes_in - per_source_avg_bytes_in) / per_source_stdev_bytes_in, 2) | table src_ip, _time, bytes_in, avg_bytes_in, per_source_avg_bytes_in, num_standard_deviations_away_from_server_average, num_standard_deviations_away_from_client_average

[ESCU - Get First Occurence and Last Occurrence of a MAC Address]
action.escu = 0
action.escu.enabled = 1
action.escu.creation_date = 2017-06-14
action.escu.modification_date = 2017-09-13
action.escu.channel = ESCU
action.escu.how_to_implement = To successfully implement this search, you must be ingesting the logs from your DHCP server.
action.escu.data_models = ["Network_Sessions"]
action.escu.full_search_name = ESCU - Get First Occurence and Last Occurrence of a MAC Address
action.escu.search_type = contextual
action.escu.providing_technologies = ["Splunk Stream", "Bro", "Microsoft Windows"]
action.escu.analytic_story = ["Asset Tracking"]
action.escu.fields_required = ["src_mac"]
action.escu.earliest_time_offset = 864000
action.escu.latest_time_offset = 86400
description = This search allows you to gather more context around a notable which has detected a new device connecting to your network. Use this search to determine the first and last occurrences of the suspicious device attempting to connect with your network.
disabled=true
realtime_schedule = 0
schedule_window = auto
search = | tstats allow_old_summaries=true count min(_time) as firstTime max(_time) as lastTime from datamodel=Network_Sessions where nodename=All_Sessions.DHCP All_Sessions.signature=DHCPREQUEST All_Sessions.All_Sessions.src_mac= {src_mac} by All_Sessions.src_ip All_Sessions.user | `ctime(lastTime)` | `ctime(firstTime)`

####################################################################

[escu-metrics-usage]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
dispatchAs = user
search = index=_audit sourcetype="audittrail" \
"ESCU - "\
`comment("Find all the search names in the audittrail.")`\
| stats count(search) by search savedsearch_name user\
| eval usage=(if(savedsearch_name="","Adhoc","Scheduled")) \
`comment("If the savedsearch_name field in the audittrail is empty, the search was run adhoc. Otherwise it was run as a scheduled search")`\
| rex field=search "\"(?<savedsearch_name>.*)\""\
`comment("Extract the name of the search from the search string")`\
| table savedsearch_name count(search) usage user | join savedsearch_name max=0 type=left [search sourcetype="manifests" | spath searches{} | mvexpand searches{} | spath input=searches{} | table category search_name | rename search_name as savedsearch_name | dedup savedsearch_name] | search category=*

[escu-metrics-search]
action.email.useNSSubject = 1
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = index=_audit action=search | transaction search_id maxspan=3m | search ESCU | stats sum(total_run_time) avg(total_run_time) max(total_run_time) sum(result_count)

[escu-metrics-search-events]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = [search index=_audit sourcetype="audittrail" \"ESCU NOT "index=_audit" | where search !="" | dedup search_id | rex field=search "\"(?<search_name>.*)\"" | rex field=_raw "user=(?<user>[a-zA-Z0-9_\-]+)"| eval usage=(if(savedsearch_name="","adhoc","scheduled"))| eval savedsearch_name=if(savedsearch_name !="", savedsearch_name, search_name) | table savedsearch_name search_id user _time usage| outputlookup escu_search_id.csv | table search_id] index=_audit total_run_time event_count result_count NOT "index=_audit" | lookup escu_search_id.csv search_id | stats count(savedsearch_name) AS search_count avg(total_run_time) AS search_avg_run_time sum(total_run_time) AS search_total_run_time sum(result_count) AS search_total_results earliest(_time) AS firsts latest(_time) AS lasts by savedsearch_name user usage| eval first_run=strftime(firsts, "%B %d %Y") | eval last_run=strftime(lasts, "%B %d %Y")

[escu-metrics-search-longest-runtime]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
disabled = 1
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
search = index=_* ESCU [search index=_* action=search latest=-2h earliest=-1d| transaction search_id maxspan=3m | search ESCU | stats values(total_run_time) AS run by search_id | sort -run | head 1| table search_id] | table search search_id

[escu-metrics-usage-search]
action.email.useNSSubject = 1
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
dispatch.earliest_time = -4h@h
dispatch.latest_time = -1h@h
dispatchAs = user
search = index=_audit sourcetype="audittrail" \
"ESCU - "\
`comment("Find all the search names in the audittrail. Ignore the last few minutes so we can exclude this search's text from the result.")`\
| stats count(search) by search savedsearch_name user\
| eval usage=(if(savedsearch_name="","Adhoc","Scheduled")) \
`comment("If the savedsearch_name field in the audittrail is empty, the search was run adhoc. Otherwise it was run as a scheduled search")`\
| rex field=search "\"(?<savedsearch_name>.*)\""\
`comment("Extract the name of the search from the search string")`\
| table savedsearch_name count(search) usage user | join savedsearch_name max=0 type=left [search sourcetype="manifests" | spath searches{} | mvexpand searches{} | spath input=searches{} | table category search_name | rename search_name as savedsearch_name | dedup savedsearch_name] | search category=*
